{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">>> Embeddings a evaluar:\n  > _fasttext_sbwc.vec\n  > _fasttext_suc_L.vec\n  > _fasttext_suc_M.vec\n  > _fasttext_suc_NL.vec\n  > _fasttext_wiki.vec\n  > _glove_sbwc.vec\n  > _rand_embedding.vec\n  > _w2v_sbwc.txt\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models.keyedvectors import KeyedVectors, BaseKeyedVectors\n",
    "\n",
    "import Constant\n",
    "\n",
    "# Path a carpeta principal\n",
    "MAIN_FOLDER = Constant.MAIN_FOLDER\n",
    "\n",
    "# Path a carpeta con los embeddings\n",
    "EMBEDDING_FOLDER = Constant.EMBEDDING_FOLDER\n",
    "\n",
    "# Lista con los nombres de los archivos de los embeddings\n",
    "embedding_name_list = os.listdir(EMBEDDING_FOLDER)\n",
    "\n",
    "print(\">>> Embeddings a evaluar:\")\n",
    "for embedding in embedding_name_list:\n",
    "    print(\"  > \" + embedding)\n",
    "    \n",
    "def get_wordvector(file, cant=None):\n",
    "    wordvector_file = EMBEDDING_FOLDER / file\n",
    "\n",
    "    return KeyedVectors.load_word2vec_format(wordvector_file, limit=cant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import AnalogyTest\n",
    "import SimilarityTest\n",
    "import OutlierDetectionTest\n",
    "\n",
    "import ConstitucionClasificacionMeanVector\n",
    "import torch\n",
    "\n",
    "word_embedding = get_wordvector(\"_rand_embedding.vec\")\n",
    "\n",
    "class Embedding:\n",
    "    def __init__(self, embedding):\n",
    "        self._embedding = embedding\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        return self._embedding[item]\n",
    "    \n",
    "    def __contains__(self, item):\n",
    "        return (item in self._embedding)\n",
    "    \n",
    "    # Entrega tamaño de los vectores dentro del embedding\n",
    "    def vectorSize(self):\n",
    "        return self._embedding.vector_size\n",
    "    \n",
    "    # Entrega lista de todas las palabras en el vocabulario del embedding. \n",
    "    # Las palabras estan en el mismo orden que la lista de vectores\n",
    "    def getWordList(self):\n",
    "        return self._embedding.index2word\n",
    "    \n",
    "    # Entrega lista de todos los vectores en el embedding.\n",
    "    # Los vectores estan en el mismo orden que la lista de palabras\n",
    "    def getVectors(self):\n",
    "        word_embedding.init_sims()\n",
    "        return word_embedding.vectors_norm\n",
    "    \n",
    "emb = Embedding(word_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">>> Test de Clasificacion de textos (vector promedio) <<<\n>>> Evaluando embedding  _rand_embedding\n",
      " > Tamaño del dataset: 205357\n > Conceptos de gobierno",
      "\nTopico 1 => cantidad de conceptos:  37\nTopico 2 => cantidad de conceptos:  44\nTopico 3 => cantidad de conceptos:  12\nTopico 4 => cantidad de conceptos:  21\n > Conceptos abiertos:\nTopico 1 => cantidad de conceptos:  55\nTopico 2 => cantidad de conceptos:  60\nTopico 3 => cantidad de conceptos:  21\nTopico 4 => cantidad de conceptos:  35\n > Conceptos abiertos eliminado\nTopico 1 => cantidad de conceptos eliminado:  18\nTopico 2 => cantidad de conceptos eliminado:  16\nTopico 3 => cantidad de conceptos eliminado:  9\nTopico 4 => cantidad de conceptos eliminado:  14\n > Cantidad de argumentos para conceptos de gobierno: 183342\n > Cantidad de argumentos para conceptos abiertos: 22015\n\nTask A\nTopico 1 => cantidad de conceptos: 37\nTopico 2 => cantidad de conceptos: 44\nTopico 3 => cantidad de conceptos: 12\nTopico 4 => cantidad de conceptos: 21\nTopico 1  => concepto: Justicia => cantidad de argumentos: 4199\n",
      "Topico 1  => concepto: Democracia => cantidad de argumentos: 4037\n",
      "Topico 1  => concepto: Respeto / Conservación de la naturaleza o medio ambiente => cantidad de argumentos: 3930\n",
      "Topico 1  => concepto: Autonomía / Libertad => cantidad de argumentos: 1862\n",
      "Topico 1  => concepto: Estado de Derecho => cantidad de argumentos: 1608\nTopico 1  => concepto: Igualdad => cantidad de argumentos: 3960\n",
      "Topico 1  => concepto: Participación => cantidad de argumentos: 1253\n",
      "Topico 1  => concepto: Unidad => cantidad de argumentos: 124\nTopico 1  => concepto: Respeto => cantidad de argumentos: 2643\n",
      "Topico 1  => concepto: Descentralización => cantidad de argumentos: 3213\n",
      "Topico 1  => concepto: Identidad cultural => cantidad de argumentos: 587\nTopico 1  => concepto: Estado laico => cantidad de argumentos: 1587\n",
      "Topico 1  => concepto: Equidad de género => cantidad de argumentos: 1775\nTopico 1  => concepto: Subsidiaridad => cantidad de argumentos: 381\nTopico",
      " 1  => concepto: Probidad => cantidad de argumentos: 1059\nTopico 1  => concepto: República => cantidad de argumentos: 211\nTopico 1  => concepto: Diversidad => cantidad de argumentos: 774\n",
      "Topico 1  => concepto: Dignidad => cantidad de argumentos: 2047\nTopico",
      " 1  => concepto: Transparencia y publicidad => cantidad de argumentos: 949\nTopico 1  => concepto: Desarrollo => cantidad de argumentos: 556\nTopico 1  => concepto: Innovación / Creatividad => cantidad de argumentos: 218\nTopico 1  => concepto: Bien Común / Comunidad => cantidad de argumentos: 2892\n",
      "Topico 1  => concepto: Multiculturalidad => cantidad de argumentos: 915\nTopico 1  => concepto: Inclusión => cantidad de argumentos: 1285\n",
      "Topico 1  => concepto: Seguridad => cantidad de argumentos: 1337\nTopico 1  => concepto: Emprendimiento libre => cantidad de argumentos: 273\nTopico 1  => concepto: Soberanía => cantidad de argumentos: 589\nTopico 1  => concepto: Integración => cantidad de argumentos: 312\nTopico",
      " 1  => concepto: Pluralismo => cantidad de argumentos: 190\nTopico 1  => concepto: Amistad cívica => cantidad de argumentos: 280\nTopico 1  => concepto: Plurinacionalismo => cantidad de argumentos: 724\nTopico 1  => concepto: Tolerancia => cantidad de argumentos: 687\n",
      "Topico 1  => concepto: Responsabilidad => cantidad de argumentos: 518\nTopico 1  => concepto: Paz / Convivencia pacífica => cantidad de argumentos: 543\nTopico 1  => concepto: Solidaridad => cantidad de argumentos: 1348\nTopico",
      " 1  => concepto: Patriotismo => cantidad de argumentos: 103\nTopico 1  => concepto: Ciudadanía => cantidad de argumentos: 186\n > Topico 1 => Argumentos totales:  49155 - Argumentos usables:  48721\nTopico 2  => concepto: Igualdad ante la ley => cantidad de argumentos: 2890\n",
      "Topico 2  => concepto: Proteccion judicial de los derechos => cantidad de argumentos: 571\nTopico 2  => concepto: Libertad de expresión => cantidad de argumentos: 2085\nTopico",
      " 2  => concepto: A la seguridad social => cantidad de argumentos: 2029\n",
      "Topico 2  => concepto: A la vivienda digna => cantidad de argumentos: 2426\nTopico",
      " 2  => concepto: A la educación => cantidad de argumentos: 5487\n",
      "Topico 2  => concepto: Derechos del niño, niña y adolecente => cantidad de argumentos: 1104\nTopico",
      " 2  => concepto: A la participación => cantidad de argumentos: 1232\nTopico 2  => concepto: Libertad de conciencia => cantidad de argumentos: 559\nTopico",
      " 2  => concepto: A la vida => cantidad de argumentos: 2660\n",
      "Topico 2  => concepto: Respeto a la naturaleza / Medio ambiente => cantidad de argumentos: 1873\nTopico 2  => concepto: A la integridad física y psíquica => cantidad de argumentos: 646\n",
      "Topico 2  => concepto: A la salud => cantidad de argumentos: 5723\n",
      "Topico 2  => concepto: Igualdad => cantidad de argumentos: 1304\n",
      "Topico 2  => concepto: A la integración de discapacidad => cantidad de argumentos: 652\nTopico 2  => concepto: A la información => cantidad de argumentos: 781\nTopico 2  => concepto: A sindicalizarse y a la negociación colectiva => cantidad de argumentos: 989\nTopico",
      " 2  => concepto: De los pueblos indígenas => cantidad de argumentos: 981\nTopico 2  => concepto: Al salario equitativo => cantidad de argumentos: 1833\n",
      "Topico 2  => concepto: Libertad personal => cantidad de argumentos: 668\nTopico 2  => concepto: Al trabajo => cantidad de argumentos: 1134\nTopico 2  => concepto: A la seguridad / Vida sin violencia => cantidad de argumentos: 1283\n",
      "Topico 2  => concepto: De propiedad => cantidad de argumentos: 664\nTopico 2  => concepto: Igualdad de acceso a la justicia / Debido proceso => cantidad de argumentos: 593\n",
      "Topico 2  => concepto: No discriminación => cantidad de argumentos: 1183\nTopico 2  => concepto: A huelga => cantidad de argumentos: 370\nTopico 2  => concepto: A sufragio / Votar => cantidad de argumentos: 1009\nTopico",
      " 2  => concepto: De petición ante las autoridades => cantidad de argumentos: 66\nTopico 2  => concepto: Igualdad ante los tributos => cantidad de argumentos: 111\nTopico 2  => concepto: Ser elegido en cargos públicos => cantidad de argumentos: 160\nTopico 2  => concepto: Acceso a información pública => cantidad de argumentos: 281\nTopico 2  => concepto: Libertad de trabajo => cantidad de argumentos: 264\nTopico 2  => concepto: Libertad de enseñanza => cantidad de argumentos: 476\nTopico 2  => concepto: A la identidad cultural => cantidad de argumentos: 337\n",
      "Topico 2  => concepto: Igualdad de género => cantidad de argumentos: 980\nTopico 2  => concepto: Libre iniciativa económica / Libre empresa => cantidad de argumentos: 242\nTopico 2  => concepto: A la honra / Al honor => cantidad de argumentos: 65\nTopico 2  => concepto: Acceso a la cultura => cantidad de argumentos: 372\nTopico 2  => concepto: Derecho de asociación => cantidad de argumentos: 232\nTopico",
      " 2  => concepto: A la nacionalidad => cantidad de argumentos: 150\nTopico 2  => concepto: Privacidad e intimidad => cantidad de argumentos: 268\nTopico 2  => concepto: Reunión pacífica => cantidad de argumentos: 66\nTopico 2  => concepto: Igualdad ante las cargas públicas => cantidad de argumentos: 31\nTopico 2  => concepto: Libertad ambulatoria => cantidad de argumentos: 57\n > Topico 2 => Argumentos totales:  46887 - Argumentos usables:  46380\nTopico 3  => concepto: Respeto por la constitución => cantidad de argumentos: 4839\n",
      "Topico 3  => concepto: Servicio a la comunidad => cantidad de argumentos: 3119\n",
      "Topico 3  => concepto: De protección y conservación de patrimonio histórico y cultural => cantidad de argumentos: 4821\n",
      "Topico 3  => concepto: Responsabilidad => cantidad de argumentos: 2604\n",
      "Topico 3  => concepto: Deberes de protección de conservación de la naturaleza => cantidad de argumentos: 5998\n",
      "Topico 3  => concepto: Protección, promoción y respeto de los derechos humanos y fundamentales => cantidad de argumentos: 6256\n",
      "Topico 3  => concepto: Respeto de derechos de otros => cantidad de argumentos: 4614\n",
      "Topico 3  => concepto: Cumplimiento de las leyes y normas => cantidad de argumentos: 4092\n",
      "Topico 3  => concepto: De satisfacer cargas públicas => cantidad de argumentos: 454\nTopico 3  => concepto: Cumplimiento de obligaciones fiscales => cantidad de argumentos: 1742\nTopico 3  => concepto: Cumplimiento de tratados y obligaciones internacionales => cantidad de argumentos: 1762\n",
      "Topico 3  => concepto: Ejercicio legítimo y no abusivo de los derechos => cantidad de argumentos: 3861\n",
      " > Topico 3 => Argumentos totales:  44162 - Argumentos usables:  43326\nTopico 4  => concepto: Defensor del Pueblo / Ciudadano => cantidad de argumentos: 3599\n",
      "Topico 4  => concepto: Cambio o reforma constitucional => cantidad de argumentos: 2666\nTopico",
      " 4  => concepto: Plebiscitos, referendos y consultas => cantidad de argumentos: 5310\n",
      "Topico 4  => concepto: Contraloría general / Tribunales de cuentas => cantidad de argumentos: 2206\n",
      "Topico 4  => concepto: Fuerzas Armadas => cantidad de argumentos: 2886\n",
      "Topico 4  => concepto: Forma de Estado => cantidad de argumentos: 2224\n",
      "Topico 4  => concepto: Justicia constitucional => cantidad de argumentos: 1106\nTopico 4  => concepto: Poder judicial (estructura y funciones) => cantidad de argumentos: 3101\n",
      "Topico 4  => concepto: Gobierno local / Municipal => cantidad de argumentos: 2546\n",
      "Topico 4  => concepto: Régimen de gobierno presidencial /Semi-presidencial / Parlamentario => cantidad de argumentos: 2648\nTopico",
      " 4  => concepto: Gobierno regional => cantidad de argumentos: 2855\n",
      "Topico 4  => concepto: Presidencia de la República => cantidad de argumentos: 2181\nTopico 4  => concepto: Congreso o parlamento => cantidad de argumentos: 3888\n",
      "Topico 4  => concepto: División territorial => cantidad de argumentos: 688\nTopico 4  => concepto: Gobierno provincial => cantidad de argumentos: 583\nTopico 4  => concepto: Juicio político /acusación constitucional => cantidad de argumentos: 1420\n",
      "Topico 4  => concepto: Justicia electoral => cantidad de argumentos: 715\nTopico 4  => concepto: Ministerio Público / Defensoría Pública => cantidad de argumentos: 981\nTopico 4  => concepto: Jefatura de gobierno => cantidad de argumentos: 234\nTopico 4  => concepto: Estado de excepción => cantidad de argumentos: 468\nTopico 4  => concepto: Gobierno nacional (estructura y funciones) => cantidad de argumentos: 833\n",
      " > Topico 4 => Argumentos totales:  43138 - Argumentos usables:  42397\n>>> Clasificacion\nTopico 1: cantidad de vectores 48721\n",
      " > top1_correct 12,top5_correct 27\n",
      " > top1_correct 393,top5_correct 1441\n",
      " > top1_correct 1087,top5_correct 4282\n",
      " > top1_correct 1282,top5_correct 5180\n",
      " > top1_correct 1452,top5_correct 6310\n",
      " > top1_correct 1494,top5_correct 6865\n",
      " > top1_correct 1601,top5_correct 7979\n",
      " > top1_correct 1659,top5_correct 8696\n",
      " > top1_correct 1676,top5_correct 8885\n",
      " > top1_correct 1910,top5_correct 9443\n>>> Resultados => top1:  0.03920280782414154  top5:  0.1938178608813448\nTopico 2: cantidad de vectores 46380\n",
      " > top1_correct 220,top5_correct 724\n",
      " > top1_correct 238,top5_correct 832\n",
      " > top1_correct 244,top5_correct 890\n",
      " > top1_correct 263,top5_correct 1091\n",
      " > top1_correct 305,top5_correct 1825\n",
      " > top1_correct 313,top5_correct 1900\n",
      " > top1_correct 707,top5_correct 2668\n",
      " > top1_correct 824,top5_correct 3675\n",
      " > top1_correct 920,top5_correct 4314\n",
      " > top1_correct 1022,top5_correct 5129\n>>> Resultados => top1:  0.022035360068995258  top5:  0.11058645968089693\nTopico 3: cantidad de vectores 43326\n",
      " > top1_correct 334,top5_correct 2004\n",
      " > top1_correct 676,top5_correct 3826\n",
      " > top1_correct 1365,top5_correct 7361\n",
      " > top1_correct 1432,top5_correct 8318\n",
      " > top1_correct 1874,top5_correct 10454\n",
      " > top1_correct 4331,top5_correct 14536\n",
      " > top1_correct 5056,top5_correct 15975\n",
      " > top1_correct 5277,top5_correct 17242\n",
      " > top1_correct 5467,top5_correct 18897\n",
      " > top1_correct 6834,top5_correct 22966\n>>> Resultados => top1:  0.15782670913539215  top5:  0.5302358860730277\nTopico 4: cantidad de vectores 42397\n",
      " > top1_correct 1156,top5_correct 3216\n",
      " > top1_correct 1189,top5_correct 3377\n",
      " > top1_correct 1228,top5_correct 3592\n",
      " > top1_correct 1266,top5_correct 4226\n",
      " > top1_correct 1583,top5_correct 5746\n",
      " > top1_correct 1886,top5_correct 7094\n",
      " > top1_correct 2321,top5_correct 8715\n",
      " > top1_correct 3096,top5_correct 10705\n",
      " > top1_correct 3151,top5_correct 10885\n",
      " > top1_correct 3295,top5_correct 11887\n>>> Resultados => top1:  0.07771776304927236  top5:  0.2804207844894686\n\nTask B\nTopico 1 => cantidad de conceptos: 37\nTopico 2 => cantidad de conceptos: 44\nTopico 3 => cantidad de conceptos: 12\nTopico 4 => cantidad de conceptos: 21\nTopico 1  => concepto: Multiculturalidad => cantidad de argumentos: 94\nTopico 1  => concepto: Probidad => cantidad de argumentos: 109\nTopico 1  => concepto: Bien Común / Comunidad => cantidad de argumentos: 152\nTopico 1  => concepto: Transparencia y publicidad => cantidad de argumentos: 67\nTopico 1  => concepto: Respeto => cantidad de argumentos: 84\nTopico 1  => concepto: Participación => cantidad de argumentos: 41\nTopico 1  => concepto: Justicia => cantidad de argumentos: 58\nTopico 1  => concepto: Integración => cantidad de argumentos: 13\nTopico 1  => concepto: Responsabilidad => cantidad de argumentos: 21\nTopico 1  => concepto: Respeto / Conservación de la naturaleza o medio ambiente => cantidad de argumentos: 221\nTopico 1  => concepto: Amistad cívica => cantidad de argumentos: 103\nTopico 1  => concepto: Solidaridad => cantidad de argumentos: 84\nTopico 1  => concepto: Paz / Convivencia pacífica => cantidad de argumentos: 27\nTopico 1  => concepto: Subsidiaridad => cantidad de argumentos: 77\nTopico 1  => concepto: Plurinacionalismo => cantidad de argumentos: 51\nTopico 1  => concepto: Estado laico => cantidad de argumentos: 72\nTopico 1  => concepto: Inclusión => cantidad de argumentos: 43\nTopico 1  => concepto: Estado de Derecho => cantidad de argumentos: 59\nTopico 1  => concepto: Equidad de género => cantidad de argumentos: 60\nTopico 1  => concepto: Igualdad => cantidad de argumentos: 132\nTopico 1  => concepto: Identidad cultural => cantidad de argumentos: 47\nTopico 1  => concepto: Descentralización => cantidad de argumentos: 12\nTopico 1  => concepto: Seguridad => cantidad de argumentos: 25\nTopico 1  => concepto: Diversidad => cantidad de argumentos: 44\nTopico 1  => concepto: Ciudadanía => cantidad de argumentos: 14\nTopico 1  => concepto: Tolerancia => cantidad de argumentos: 18\nTopico 1  => concepto: Soberanía => cantidad de argumentos: 12\nTopico 1  => concepto: Dignidad => cantidad de argumentos: 63\nTopico 1  => concepto: Autonomía / Libertad => cantidad de argumentos: 68\nTopico 1  => concepto: República => cantidad de argumentos: 15\nTopico 1  => concepto: Unidad => cantidad de argumentos: 18\nTopico 1  => concepto: Desarrollo => cantidad de argumentos: 11\nTopico 1  => concepto: Innovación / Creatividad => cantidad de argumentos: 25\nTopico 1  => concepto: Democracia => cantidad de argumentos: 7\nTopico 1  => concepto: Pluralismo => cantidad de argumentos: 8\nTopico 1  => concepto: Emprendimiento libre => cantidad de argumentos: 7\nTopico 1  => concepto: Patriotismo => cantidad de argumentos: 2\n > Topico 1 => Conceptos abiertos totales: 1964 - Conceptos abiertos usables: 1801\nTopico 2  => concepto: A sindicalizarse y a la negociación colectiva => cantidad de argumentos: 74\nTopico 2  => concepto: Igualdad => cantidad de argumentos: 162\nTopico 2  => concepto: Igualdad de género => cantidad de argumentos: 61\nTopico 2  => concepto: A la seguridad social => cantidad de argumentos: 317\nTopico 2  => concepto: Respeto a la naturaleza / Medio ambiente => cantidad de argumentos: 346\nTopico 2  => concepto: A la vida => cantidad de argumentos: 78\nTopico 2  => concepto: A la educación => cantidad de argumentos: 374\nTopico 2  => concepto: Libertad de conciencia => cantidad de argumentos: 86\nTopico 2  => concepto: A la información => cantidad de argumentos: 74\nTopico 2  => concepto: Libre iniciativa económica / Libre empresa => cantidad de argumentos: 18\nTopico 2  => concepto: Libertad de trabajo => cantidad de argumentos: 11\nTopico 2  => concepto: A la seguridad / Vida sin violencia => cantidad de argumentos: 119\nTopico",
      " 2  => concepto: Al trabajo => cantidad de argumentos: 31\nTopico 2  => concepto: Proteccion judicial de los derechos => cantidad de argumentos: 17\nTopico 2  => concepto: A la participación => cantidad de argumentos: 207\nTopico 2  => concepto: Acceso a la cultura => cantidad de argumentos: 58\nTopico 2  => concepto: De propiedad => cantidad de argumentos: 48\nTopico 2  => concepto: A la vivienda digna => cantidad de argumentos: 86\nTopico 2  => concepto: A la salud => cantidad de argumentos: 89\nTopico 2  => concepto: A la integridad física y psíquica => cantidad de argumentos: 121\nTopico 2  => concepto: No discriminación => cantidad de argumentos: 149\nTopico 2  => concepto: Al salario equitativo => cantidad de argumentos: 41\nTopico 2  => concepto: A sufragio / Votar => cantidad de argumentos: 22\nTopico 2  => concepto: A la identidad cultural => cantidad de argumentos: 46\nTopico 2  => concepto: Ser elegido en cargos públicos => cantidad de argumentos: 34\nTopico 2  => concepto: A la integración de discapacidad => cantidad de argumentos: 28\nTopico 2  => concepto: Libertad de expresión => cantidad de argumentos: 60\nTopico 2  => concepto: Privacidad e intimidad => cantidad de argumentos: 22\nTopico 2  => concepto: Igualdad de acceso a la justicia / Debido proceso => cantidad de argumentos: 101\nTopico 2  => concepto: A la honra / Al honor => cantidad de argumentos: 37\nTopico 2  => concepto: Igualdad ante la ley => cantidad de argumentos: 56\nTopico 2  => concepto: Derechos del niño, niña y adolecente => cantidad de argumentos: 68\nTopico 2  => concepto: Acceso a información pública => cantidad de argumentos: 41\nTopico 2  => concepto: Libertad de enseñanza => cantidad de argumentos: 61\nTopico 2  => concepto: De los pueblos indígenas => cantidad de argumentos: 42\nTopico 2  => concepto: A huelga => cantidad de argumentos: 13\nTopico 2  => concepto: Libertad personal => cantidad de argumentos: 61\nTopico 2  => concepto: Derecho de asociación => cantidad de argumentos: 31\nTopico 2  => concepto: Igualdad ante las cargas públicas => cantidad de argumentos: 3\nTopico 2  => concepto: Igualdad ante los tributos => cantidad de argumentos: 30\nTopico 2  => concepto: Libertad ambulatoria => cantidad de argumentos: 13\nTopico 2  => concepto: A la nacionalidad => cantidad de argumentos: 5\nTopico 2  => concepto: De petición ante las autoridades => cantidad de argumentos: 7\nTopico 2  => concepto: Reunión pacífica => cantidad de argumentos: 8\n > Topico 2 => Conceptos abiertos totales: 3356 - Conceptos abiertos usables: 3148\nTopico 3  => concepto: Cumplimiento de obligaciones fiscales => cantidad de argumentos: 102\nTopico 3  => concepto: Cumplimiento de las leyes y normas => cantidad de argumentos: 94\nTopico 3  => concepto: Responsabilidad => cantidad de argumentos: 310\nTopico 3  => concepto: Deberes de protección de conservación de la naturaleza => cantidad de argumentos: 442\nTopico 3  => concepto: Servicio a la comunidad => cantidad de argumentos: 249\nTopico 3  => concepto: De satisfacer cargas públicas => cantidad de argumentos: 28\nTopico 3  => concepto: Ejercicio legítimo y no abusivo de los derechos => cantidad de argumentos: 92\nTopico 3  => concepto: De protección y conservación de patrimonio histórico y cultural => cantidad de argumentos: 245\nTopico 3  => concepto: Protección, promoción y respeto de los derechos humanos y fundamentales => cantidad de argumentos: 191\nTopico 3  => concepto: Cumplimiento de tratados y obligaciones internacionales => cantidad de argumentos: 52\nTopico 3  => concepto: Respeto de derechos de otros => cantidad de argumentos: 3\nTopico 3  => concepto: Respeto por la constitución => cantidad de argumentos: 12\n > Topico 3 => Conceptos abiertos totales: 1820 - Conceptos abiertos usables: 1684\nTopico 4  => concepto: Fuerzas Armadas => cantidad de argumentos: 248\nTopico 4  => concepto: Gobierno local / Municipal => cantidad de argumentos: 102\nTopico 4  => concepto: Gobierno nacional (estructura y funciones) => cantidad de argumentos: 1100\nTopico",
      " 4  => concepto: Plebiscitos, referendos y consultas => cantidad de argumentos: 223\nTopico 4  => concepto: Justicia electoral => cantidad de argumentos: 70\nTopico 4  => concepto: Cambio o reforma constitucional => cantidad de argumentos: 112\nTopico 4  => concepto: Forma de Estado => cantidad de argumentos: 262\nTopico 4  => concepto: Presidencia de la República => cantidad de argumentos: 24\nTopico 4  => concepto: Congreso o parlamento => cantidad de argumentos: 134\nTopico 4  => concepto: Régimen de gobierno presidencial /Semi-presidencial / Parlamentario => cantidad de argumentos: 215\nTopico 4  => concepto: División territorial => cantidad de argumentos: 38\nTopico 4  => concepto: Contraloría general / Tribunales de cuentas => cantidad de argumentos: 103\nTopico 4  => concepto: Juicio político /acusación constitucional => cantidad de argumentos: 113\nTopico 4  => concepto: Justicia constitucional => cantidad de argumentos: 34\nTopico 4  => concepto: Defensor del Pueblo / Ciudadano => cantidad de argumentos: 85\nTopico 4  => concepto: Ministerio Público / Defensoría Pública => cantidad de argumentos: 69\nTopico 4  => concepto: Gobierno regional => cantidad de argumentos: 4\nTopico 4  => concepto: Poder judicial (estructura y funciones) => cantidad de argumentos: 124\nTopico 4  => concepto: Estado de excepción => cantidad de argumentos: 15\nTopico 4  => concepto: Jefatura de gobierno => cantidad de argumentos: 1\nTopico 4  => concepto: Gobierno provincial => cantidad de argumentos: 8\n > Topico 4 => Conceptos abiertos totales: 3084 - Conceptos abiertos usables: 2798\n>>> Clasificacion\nTopico 1: cantidad de vectores 1801\n > top1_correct 7,top5_correct 7\n > top1_correct 45,top5_correct 117",
      "\n > top1_correct 86,top5_correct 207\n > top1_correct 181,top5_correct 350\n > top1_correct 233,top5_correct 429\n > top1_correct 265,top5_correct 482",
      "\n > top1_correct 355,top5_correct 606\n > top1_correct 404,top5_correct 698\n > top1_correct 442,top5_correct 748\n > top1_correct 499,top5_correct 832\n>>> Resultados => top1:  0.277623542476402  top5:  0.4625208217656857\nTopico 2: cantidad de vectores 3148\n",
      " > top1_correct 42,top5_correct 92\n > top1_correct 92,top5_correct 177\n > top1_correct 149,top5_correct 332\n",
      " > top1_correct 172,top5_correct 404\n > top1_correct 202,top5_correct 539\n",
      " > top1_correct 271,top5_correct 690\n > top1_correct 327,top5_correct 831\n > top1_correct 396,top5_correct 937\n",
      " > top1_correct 490,top5_correct 1116\n > top1_correct 575,top5_correct 1253\n>>> Resultados => top1:  0.18297331639135958  top5:  0.3983481575603558\nTopico 3: cantidad de vectores 1684\n > top1_correct 42,top5_correct 106",
      "\n > top1_correct 81,top5_correct 156\n > top1_correct 112,top5_correct 206\n > top1_correct 129,top5_correct 284\n > top1_correct 148,top5_correct 358\n",
      " > top1_correct 179,top5_correct 438\n > top1_correct 229,top5_correct 518\n > top1_correct 299,top5_correct 673\n > top1_correct 383,top5_correct 827\n > top1_correct 492,top5_correct 986",
      "\n>>> Resultados => top1:  0.29513064133016625  top5:  0.588479809976247\nTopico 4: cantidad de vectores 2798\n > top1_correct 41,top5_correct 105\n > top1_correct 47,top5_correct 173\n > top1_correct 54,top5_correct 253",
      "\n > top1_correct 60,top5_correct 338\n > top1_correct 84,top5_correct 437\n",
      " > top1_correct 137,top5_correct 532\n > top1_correct 194,top5_correct 644\n > top1_correct 278,top5_correct 821\n > top1_correct 328,top5_correct 912",
      "\n > top1_correct 449,top5_correct 1111\n>>> Resultados => top1:  0.16047176554681916  top5:  0.39814152966404576\n>>> Guardando resultados en:\n     D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Resultados\\Constitucion\\mean_vector__rand_embedding.txt\n{'1': [0.03920280782414154, 0.1938178608813448], '2': [0.022035360068995258, 0.11058645968089693], '3': [0.15782670913539215, 0.5302358860730277], '4': [0.07771776304927236, 0.2804207844894686]}\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "({'1': [0.03920280782414154, 0.1938178608813448],\n  '2': [0.022035360068995258, 0.11058645968089693],\n  '3': [0.15782670913539215, 0.5302358860730277],\n  '4': [0.07771776304927236, 0.2804207844894686]},\n {'1': [0.277623542476402, 0.4625208217656857],\n  '2': [0.18297331639135958, 0.3983481575603558],\n  '3': [0.29513064133016625, 0.588479809976247],\n  '4': [0.16047176554681916, 0.39814152966404576]})"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "test_const_mean = ConstitucionClasificacionMeanVector.ConstitucionTestClass()\n",
    "test_const_mean.MeanVectorEvaluation(\"_rand_embedding\", emb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">>> Test de Similaridad <<<\n>>> Copiando dataset original para realizar interseccion\n    MC30_Barzegar_ES.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    MC30_Hassan_ES.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    MultiSimLex_ES.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    RG65_Barzegar_ES.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    RG65_Collado_ES.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    semeval17_es.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    SIMLEX999_Barzegar_ES.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    WS353_Barzegar_ES.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    WS353_Hassan_ES.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n>>> Intersectando datasets con vocabulario de embedding...\n > Revision de archivos en dataset\n   Revisando MC30_Barzegar_ES.txt\n   > Lineas eliminadas: 0 de 29\n   Revisando MC30_Hassan_ES.txt\n   > Lineas eliminadas: 2 de 30\n   Revisando MultiSimLex_ES.txt\n   > Lineas eliminadas: 51 de 1790\n   Revisando RG65_Barzegar_ES.txt\n   > Lineas eliminadas: 0 de 65\n   Revisando RG65_Collado_ES.txt\n   > Lineas eliminadas: 0 de 65\n   Revisando semeval17_es.txt\n   > Lineas eliminadas: 17 de 376\n   Revisando SIMLEX999_Barzegar_ES.txt\n   > Lineas eliminadas: 4 de 983\n   Revisando WS353_Barzegar_ES.txt\n   > Lineas eliminadas: 31 de 351\n   Revisando WS353_Hassan_ES.txt\n   > Lineas eliminadas: 31 de 350\n > Archivos a eliminar: 0\n\n>>> Evaluando embedding  _rand_embedding\n > Obteniendo nombre de archivos de test desde: D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_SimilarityDataset\n > Evaluacion con dataset  MC30_Barzegar_ES.txt\n > Extraccion de dataset\n    Pares repetidos: 1\n    Pares de palabras eliminadas: 0\n    Palabras no encontradas: 0\n     []\n > Evaluacion con dataset  MC30_Hassan_ES.txt\n > Extraccion de dataset\n    Pares repetidos: 0\n    Pares de palabras eliminadas: 0\n    Palabras no encontradas: 0\n     []\n > Evaluacion con dataset  MultiSimLex_ES.txt\n > Extraccion de dataset\n    Pares repetidos: 11\n    Pares de palabras eliminadas: 0\n    Palabras no encontradas: 0\n     []\n > Evaluacion con dataset  RG65_Barzegar_ES.txt\n > Extraccion de dataset\n    Pares repetidos: 1\n    Pares de palabras eliminadas: 0\n    Palabras no encontradas: 0\n     []\n > Evaluacion con dataset  RG65_Collado_ES.txt\n > Extraccion de dataset\n    Pares repetidos: 0\n    Pares de palabras eliminadas: 0\n    Palabras no encontradas: 0\n     []\n > Evaluacion con dataset  semeval17_es.txt\n > Extraccion de dataset\n    Pares repetidos: 0\n    Pares de palabras eliminadas: 0\n    Palabras no encontradas: 0\n     []\n > Evaluacion con dataset  SIMLEX999_Barzegar_ES.txt\n > Extraccion de dataset\n    Pares repetidos:",
      " 24\n    Pares de palabras eliminadas: 0\n    Palabras no encontradas: 0\n     []\n > Evaluacion con dataset  WS353_Barzegar_ES.txt\n > Extraccion de dataset\n    Pares repetidos: 2\n    Pares de palabras eliminadas: 0\n    Palabras no encontradas: 0\n     []\n > Evaluacion con dataset  WS353_Hassan_ES.txt\n > Extraccion de dataset\n    Pares repetidos: 1\n    Pares de palabras eliminadas: 0\n    Palabras no encontradas: 0\n     []\n>>> Guardando resultados en:\n     D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Resultados\\_intersection_Similarity\\_rand_embedding.txt\n>>> Resultados\n[['MC30_Barzegar_ES.txt'], ['pearson', 0.13230868074401764], ['spearman', 0.04490690706271923], ['kendall', 0.005319224186026076], ['not_found_pairs', 0], ['not_found_words', 0], ['size_data', 29]]\n[['MC30_Hassan_ES.txt'], ['pearson', 0.10303619534777798], ['spearman', 0.027378510180097567], ['kendall', 0.023904572186687872], ['not_found_pairs', 0], ['not_found_words', 0], ['size_data', 28]]\n[['MultiSimLex_ES.txt'], ['pearson', -0.030600232108730974], ['spearman', -0.025048227924378122], ['kendall', -0.01720395933706458], ['not_found_pairs', 0], ['not_found_words', 0], ['size_data', 1739]]\n[['RG65_Barzegar_ES.txt'], ['pearson', 0.4778346587711863], ['spearman', 0.16394269667701947], ['kendall', 0.10032496023657175], ['not_found_pairs', 0], ['not_found_words', 0], ['size_data', 65]]\n[['RG65_Collado_ES.txt'], ['pearson', 0.09662843467010031], ['spearman', 0.023437587758091717], ['kendall', 0.004360580271373718], ['not_found_pairs', 0], ['not_found_words', 0], ['size_data', 65]]\n[['semeval17_es.txt'], ['pearson', 0.015608620495764737], ['spearman', 0.020332484237995916], ['kendall', 0.011651694290109366], ['not_found_pairs', 0], ['not_found_words', 0], ['size_data', 359]]\n[['SIMLEX999_Barzegar_ES.txt'], ['pearson', 0.08582854625817216], ['spearman', 0.006880786357942537], ['kendall', 0.003844602986343015], ['not_found_pairs', 0], ['not_found_words', 0], ['size_data', 979]]\n[['WS353_Barzegar_ES.txt'], ['pearson', -0.010413176876336465], ['spearman', -0.0680539042695278], ['kendall', -0.04605241219323082], ['not_found_pairs', 0], ['not_found_words', 0], ['size_data', 320]]\n[['WS353_Hassan_ES.txt'], ['pearson', -0.013046257047490233], ['spearman', -0.0682361001832552], ['kendall', -0.04621089096926722], ['not_found_pairs', 0], ['not_found_words', 0], ['size_data', 319]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_sim = SimilarityTest.SimilarityTestClass(use_intersect_dataset=True)\n",
    "test_sim.intersectDataset(emb)\n",
    "res = test_sim.evaluateWordVector(\"_rand_embedding\", emb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">>> Test de Outlier Detection <<<\n>>> Copiando dataset original para realizar interseccion\n    Q101352.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q104157.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q10417670.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q105000.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1052743.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1053630.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1061151.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1065118.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1066984.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1070990.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q10742.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q10943.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q11004.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q11032.txt  no se encuentra en dataset de interseccion, copiando\n    Q1107.txt  no se encuentra en dataset de interseccion, copiando\n    Q1107679.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q11086742.txt  no se encuentra en dataset de interseccion, copiando\n    Q11303.txt  no se encuentra en dataset de interseccion, copiando\n    Q1130645.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1131296.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1134686.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q11348.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1137109.txt  no se encuentra en dataset de interseccion, copiando\n    Q1137468.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1137833.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1138494.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1140046.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1143635.txt  no se encuentra en dataset de interseccion, copiando\n    Q11446.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1145012.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1145276.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1146429.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1147395.txt  no se encuentra en dataset de interseccion, copiando\n    Q1149652.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1153376.txt  no se encuentra en dataset de interseccion, copiando\n    Q1154710.txt  no se encuentra en dataset de interseccion, copiando\n    Q1155404.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q11666901.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q11732217.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q11773926.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1180262.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1187811.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q11879590.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1190554.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1197685.txt  no se encuentra en dataset de interseccion, copiando\n    Q1210300.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q12131624.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q12131640.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q12143.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q12308941.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q123266.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1234255.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q123705.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q124734.txt  no se encuentra en dataset de interseccion, copiando\n    Q125191.txt  no se encuentra en dataset de interseccion, copiando\n    Q1259759.txt  no se encuentra en dataset de interseccion, copiando\n    Q1266818.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q12737077.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q127448.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q12800.txt  no se encuentra en dataset de interseccion, copiando\n    Q12813115.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1302471.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q13025342.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1307214.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q131093.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1311958.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q131212.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q131299.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q131436.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q131669.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q13218690.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q13219666.txt  no se encuentra en dataset de interseccion, copiando\n    Q132364.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1330336.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q13366104.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q134161.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1344.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q134556.txt  no se encuentra en dataset de interseccion, copiando\n    Q134626.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1349648.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1353952.txt  no se encuentra en dataset de interseccion, copiando\n    Q13539802.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1357964.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1368898.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1371562.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1382893.txt  no se encuentra en dataset de interseccion, copiando\n    Q1388421.txt  no se encuentra en dataset de interseccion, copiando\n    Q1401585.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1402592.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1420.txt  no se encuentra en dataset de interseccion, copiando\n    Q142714.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1437459.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1439691.txt  no se encuentra en dataset de interseccion, copiando\n    Q14514600.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q14623646.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q14756018.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q14770218.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q14784328.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1480166.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1497375.txt  no se encuentra en dataset de interseccion, copiando\n    Q15063611.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15068450.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15079663.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15091377.txt  no se encuentra en dataset de interseccion, copiando\n    Q15092344.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15105893.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15127012.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15141632.txt  no se encuentra en dataset de interseccion, copiando\n    Q15169167.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1518096.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15221310.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15221370.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15221373.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q152732.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15298259.txt  no se encuentra en dataset de interseccion, copiando\n    Q15303838.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q153562.txt  no se encuentra en dataset de interseccion, copiando\n    Q154038.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15416.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1547289.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1549591.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15584664.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15633582.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15647906.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15702752.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15707583.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15720625.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15732355.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15832079.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15836568.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15841920.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15978299.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q15979307.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q160091.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q16103215.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q161161.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1615742.txt  no se encuentra en dataset de interseccion, copiando\n    Q1621322.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q162620.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q162875.txt  no se encuentra en dataset de interseccion, copiando\n    Q16335296.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1637706.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1639634.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q16514343.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1665984.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q16858213.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q16970.txt  no se encuentra en dataset de interseccion, copiando\n    Q171263.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q171318.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q171441.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q17156793.txt  no se encuentra en dataset de interseccion, copiando\n    Q17205.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q17305127.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q173600.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q17412916.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q17447455.txt  no se encuentra en dataset de interseccion, copiando\n    Q1749269.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1752939.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q176165.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1762059.txt  no se encuentra en dataset de interseccion, copiando\n    Q177691.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1777138.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1780506.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q178550.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q179049.txt  no se encuentra en dataset de interseccion, copiando\n    Q17910379.txt  no se encuentra en dataset de interseccion, copiando\n    Q179461.txt  no se encuentra en dataset de interseccion, copiando\n    Q179805.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1798622.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1799072.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q17991810.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1802801.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q180673.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q18089617.txt  no se encuentra en dataset de interseccion, copiando\n    Q1810858.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q181175.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n   ",
      " Q181322.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q18142.txt  no se encuentra en dataset de interseccion, copiando\n    Q182406.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q182531.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q182547.txt  no se encuentra en dataset de interseccion, copiando\n    Q18343316.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1840161.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q184932.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q185086.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q18509232.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q18511725.txt  no se encuentra en dataset de interseccion, copiando\n    Q185217.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1852859.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q185357.txt  no se encuentra en dataset de interseccion, copiando\n    Q18564289.txt  no se encuentra en dataset de interseccion, copiando\n    Q18602249.txt  no se encuentra en dataset de interseccion, copiando\n    Q18703581.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q187931.txt  no se encuentra en dataset de interseccion, copiando\n    Q188509.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q188860.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q189533.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q190915.txt  no se encuentra en dataset de interseccion, copiando\n    Q1914636.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q192287.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q19335303.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q193556.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1952852.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1978718.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q1989278.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2001305.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q200141.txt  no se encuentra en dataset de interseccion, copiando\n    Q2001676.txt  no se encuentra en dataset de interseccion, copiando\n    Q200250.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2008050.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q202435.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q202595.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q202866.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q203904.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2039348.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q205020.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q20638319.txt  no se encuentra en dataset de interseccion, copiando\n    Q20643324.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q20653563.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q20667187.txt  no se encuentra en dataset de interseccion, copiando\n    Q207170.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q20724701.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q20738676.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q20738811.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q20738945.txt  no se encuentra en dataset de interseccion, copiando\n    Q2074737.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q20825628.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q208469.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2087181.txt  no se encuentra en dataset de interseccion, copiando\n    Q209939.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q21010817.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q21011318.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q210337.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q21125433.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q21188110.txt  no se encuentra en dataset de interseccion, copiando\n    Q21191019.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q212057.txt  no se encuentra en dataset de interseccion, copiando\n    Q212434.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2139.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q214070.txt  no se encuentra en dataset de interseccion, copiando\n    Q21507383.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q21583365.txt  no se encuentra en dataset de interseccion, copiando\n    Q21583366.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q216048.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q21605492.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q216337.txt  no se encuentra en dataset de interseccion, copiando\n    Q216712.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2198855.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q222405.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q22302160.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2235308.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2264924.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q226730.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2267870.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q22865.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2301325.txt  no se encuentra en dataset de interseccion, copiando\n    Q2327515.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q23413.txt  no se encuentra en dataset de interseccion, copiando\n    Q23442.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2351962.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q235557.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q23691.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q23745.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2387050.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q23905105.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q24354.txt  no se encuentra en dataset de interseccion, copiando\n    Q2465832.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q247073.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2472587.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q24764.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q24862.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q24869.txt  no se encuentra en dataset de interseccion, copiando\n    Q250811.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q253019.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q253030.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2537.txt  no se encuentra en dataset de interseccion, copiando\n    Q2537537.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2555896.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2572794.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q257978.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2590445.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2590631.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2607197.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2616791.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q262166.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q262882.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q263639.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q264965.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2672914.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2706302.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q271669.txt  no se encuentra en dataset de interseccion, copiando\n    Q271680.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q273120.txt  no se encuentra en dataset de interseccion, copiando\n    Q2743.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q274586.txt  no se encuentra en dataset de interseccion, copiando\n    Q2755753.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q27686.txt  no se encuentra en dataset de interseccion, copiando\n    Q2775969.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q28640.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q290378.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2911266.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2912397.txt  no se encuentra en dataset de interseccion, copiando\n    Q2915955.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2916980.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2919801.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q29380.txt  no se encuentra en dataset de interseccion, copiando\n    Q2989398.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2989454.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q2989470.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q299191.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3062294.txt  no se encuentra en dataset de interseccion, copiando\n    Q3077461.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q308891.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q312457.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q31629.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q317548.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3184121.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3192808.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3199141.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q320018.txt  no se encuentra en dataset de interseccion, copiando\n    Q3220391.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3249551.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3257686.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q33215.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3326717.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3327873.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3333265.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3387041.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3389302.txt  no se encuentra en dataset de interseccion, copiando\n    Q34049.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q34442.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q34763.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q349.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3516833.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3550873.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q355567.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3556889.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q35666.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3647172.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q36534.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3685462.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q37484.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q375011.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q382927.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3863.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3884033.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3932296.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3947.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q3966183.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q40056.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q4022.txt  no se encuentra en dataset de interseccion, copiando\n    Q40540.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q4057820.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q41156.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q41298.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q41425.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q4164871.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n   ",
      " Q4178140.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q42032.txt  no se encuentra en dataset de interseccion, copiando\n    Q422062.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q4220920.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q42523.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q431289.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q448801.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q45776.txt  no se encuentra en dataset de interseccion, copiando\n    Q462778.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q4632675.txt  no se encuentra en dataset de interseccion, copiando\n    Q46395.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q467511.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q46831.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q46970.txt  no se encuentra en dataset de interseccion, copiando\n    Q473972.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q476028.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q477248.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q483110.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q484170.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q484641.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q4892352.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q493522.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q4946461.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q494721.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q49773.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q50053.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5009242.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q50256.txt  no se encuentra en dataset de interseccion, copiando\n    Q5055981.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q506240.txt  no se encuentra en dataset de interseccion, copiando\n    Q506883.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5084.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q509686.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5107.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5119.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5123999.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5153359.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5185279.txt  no se encuentra en dataset de interseccion, copiando\n    Q5200157.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5283559.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5393308.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q54050.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q55488.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5569988.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q55833.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q558330.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q559618.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5633421.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q57058.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q57318.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q5737899.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q57831.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q581714.txt  no se encuentra en dataset de interseccion, copiando\n    Q5891.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q612229.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q6154783.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q62049.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q620615.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q6368.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q640262.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q641066.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q6456916.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q6465.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q6498903.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q655697.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q6593035.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q66016.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q667509.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q674928.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q676050.txt  no se encuentra en dataset de interseccion, copiando\n    Q677678.txt  no se encuentra en dataset de interseccion, copiando\n    Q681277.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q692680.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q6979593.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q699.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q70208.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q707813.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q7094076.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q719419.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q720711.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q7268568.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q7270.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q7309443.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q735.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q7365.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q7366.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q738570.txt  no se encuentra en dataset de interseccion, copiando\n    Q747074.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q747381.txt  no se encuentra en dataset de interseccion, copiando\n    Q748149.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q751705.txt  no se encuentra en dataset de interseccion, copiando\n    Q751708.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q75520.txt  no se encuentra en dataset de interseccion, copiando\n    Q755707.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q768855.txt  no se encuentra en dataset de interseccion, copiando\n    Q769603.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q777120.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q7830213.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q788104.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q7889.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q79007.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q8072.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q8148.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q816829.txt  no se encuentra en dataset de interseccion, copiando\n    Q8192.txt  no se encuentra en dataset de interseccion, copiando\n    Q821435.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q82414.txt  no se encuentra en dataset de interseccion, copiando\n    Q83116.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q831663.txt  no se encuentra en dataset de interseccion, copiando\n    Q83267.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q83620.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q8366.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q838296.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q842100.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q8432.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q843886.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q850450.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q8514.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q851830.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q852151.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q862597.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q871419.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q876730.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q878367.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q898771.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q898786.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q899523.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q9143.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q917092.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q9174.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q920890.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q925381.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q928830.txt  no se encuentra en dataset de interseccion, copiando\n    Q933394.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q937876.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q941036.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q9415.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q94951.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q954007.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q955655.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q971831.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q989255.txt  ya ha se encuentra en dataset de interseccion, reutilizando\n    Q990488.txt  no se encuentra en dataset de interseccion, copiando\n>>> Intersectando datasets con vocabulario de embedding...\n > Revision de archivos en dataset\n   Revisando Q101352.txt\n   > Lineas eliminadas: 4 de 8\n   Revisando Q104157.txt\n   > Lineas eliminadas: 4 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q10417670.txt\n   > Lineas eliminadas: 9 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q105000.txt\n   > Lineas eliminadas: 6 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1052743.txt\n   > Lineas eliminadas: 1 de 4\n   Revisando Q1053630.txt\n   > Lineas eliminadas: 2 de 6\n   Revisando Q1061151.txt\n   > Lineas eliminadas: 3 de 6\n   Revisando Q1065118.txt\n   > Lineas eliminadas: 6 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1066984.txt\n   > Lineas eliminadas: 2 de 9\n   Revisando Q1070990.txt\n   > Lineas eliminadas: 10 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q10742.txt\n   > Lineas eliminadas: 1 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q10943.txt\n   > Lineas eliminadas: 6 de 12\n   Revisando Q11004.txt\n   > Lineas eliminadas: 1 de 5\n   Revisando Q11032.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1107.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1107679.txt\n   > Lineas eliminadas: 3 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q11086742.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q11303.txt\n   > Lineas eliminadas: 11 de 11\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1130645.txt\n   > Lineas eliminadas: 5 de 11\n   Revisando Q1131296.txt\n   > Lineas eliminadas: 4 de 7\n   Revisando Q1134686.txt\n   > Lineas eliminadas: 5 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q11348.txt\n   > Lineas eliminadas: 3 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1137109.txt\n   > Lineas eliminadas: 9 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1137468.txt\n   > Lineas eliminadas: 1 de 3\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1137833.txt\n   > Lineas eliminadas: 4 de 12\n   Revisando Q1138494.txt\n   > Lineas eliminadas: 1 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1140046.txt\n   > Lineas eliminadas: 4 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1143635.txt\n   > Lineas eliminadas: 11 de 11\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q11446.txt\n   > Lineas eliminadas: 2 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1145012.txt\n   > Lineas eliminadas: 7 de 12\n   Revisando Q1145276.txt\n   > Lineas eliminadas: 4 de 11\n   Revisando Q1146429.txt\n   > Lineas eliminadas: 6 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1147395.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1149652.txt\n   > Lineas eliminadas: 10 de 13\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1153376.txt\n   > Lineas eliminadas:",
      " 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1154710.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1155404.txt\n   > Lineas eliminadas: 4 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q11666901.txt\n   > Lineas eliminadas: 1 de 9\n   Revisando Q11732217.txt\n   > Lineas eliminadas: 5 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q11773926.txt\n   > Lineas eliminadas: 3 de 9\n   Revisando Q1180262.txt\n   > Lineas eliminadas: 0 de 10\n   Revisando Q1187811.txt\n   > Lineas eliminadas: 0 de 8\n   Revisando Q11879590.txt\n   > Lineas eliminadas: 2 de 13\n   Revisando Q1190554.txt\n   > Lineas eliminadas: 0 de 6\n   Revisando Q1197685.txt\n   > Lineas eliminadas: 11 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1210300.txt\n   > Lineas eliminadas: 4 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q12131624.txt\n   > Lineas eliminadas: 6 de 10\n   Revisando Q12131640.txt\n   > Lineas eliminadas: 7 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q12143.txt\n   > Lineas eliminadas: 1 de 5\n   Revisando Q12308941.txt\n   > Lineas eliminadas: 2 de 11\n   Revisando Q123266.txt\n   > Lineas eliminadas: 8 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1234255.txt\n   > Lineas eliminadas: 4 de 9\n   Revisando Q123705.txt\n   > Lineas eliminadas: 5 de 8\n   Revisando Q124734.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q125191.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1259759.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1266818.txt\n   > Lineas eliminadas: 0 de 8\n   Revisando Q12737077.txt\n   > Lineas eliminadas: 0 de 9\n   Revisando Q127448.txt\n   > Lineas eliminadas: 9 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q12800.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q12813115.txt\n   > Lineas eliminadas: 7 de 12\n   Revisando Q1302471.txt\n   > Lineas eliminadas: 2 de 9\n   Revisando Q13025342.txt\n   > Lineas eliminadas: 8 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1307214.txt\n   > Lineas eliminadas: 2 de 6\n   Revisando Q131093.txt\n   > Lineas eliminadas: 6 de 12\n   Revisando Q1311958.txt\n   > Lineas eliminadas: 6 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q131212.txt\n   > Lineas eliminadas: 3 de 10\n   Revisando Q131299.txt\n   > Lineas eliminadas: 2 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q131436.txt\n   > Lineas eliminadas: 2 de 8\n   Revisando Q131669.txt\n   > Lineas eliminadas: 5 de 9\n   Revisando Q13218690.txt\n   > Lineas eliminadas: 6 de 10\n   Revisando Q13219666.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q132364.txt\n   > Lineas eliminadas: 5 de 9\n   Revisando Q1330336.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q13366104.txt\n   > Lineas eliminadas: 0 de 9\n   Revisando Q134161.txt\n   > Lineas eliminadas: 4 de 9\n   Revisando Q1344.txt\n   > Lineas eliminadas: 1 de 7\n   Revisando Q134556.txt\n   > Lineas eliminadas: 10 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q134626.txt\n   > Lineas eliminadas: 3 de 11\n   Revisando Q1349648.txt\n   > Lineas eliminadas: 4 de 9\n   Revisando Q1353952.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q13539802.txt\n   > Lineas eliminadas: 1 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1357964.txt\n   > Lineas eliminadas: 4 de 13\n   Revisando Q1368898.txt\n   > Lineas eliminadas: 4 de 10\n   Revisando Q1371562.txt\n   > Lineas eliminadas: 1 de 8\n   Revisando Q1382893.txt\n   > Lineas eliminadas: 9 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1388421.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1401585.txt\n   > Lineas eliminadas: 7 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1402592.txt\n   > Lineas eliminadas: 2 de 6\n   Revisando Q1420.txt\n   > Lineas eliminadas: 12 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q142714.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q1437459.txt\n   > Lineas eliminadas: 2 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1439691.txt\n   > Lineas eliminadas: 10 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q14514600.txt\n   > Lineas eliminadas: 3 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q14623646.txt\n   > Lineas eliminadas: 1 de 4\n   Revisando Q14756018.txt\n   > Lineas eliminadas: 4 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q14770218.txt\n   > Lineas eliminadas: 4 de 11\n   Revisando Q14784328.txt\n   > Lineas eliminadas: 1 de 13\n   Revisando Q1480166.txt\n   > Lineas eliminadas: 0 de 10\n   Revisando Q1497375.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15063611.txt\n   > Lineas eliminadas: 1 de 9\n   Revisando Q15068450.txt\n   > Lineas eliminadas: 8 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15079663.txt\n   > Lineas eliminadas: 1 de 7\n   Revisando Q15091377.txt\n   > Lineas eliminadas:",
      " 12 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15092344.txt\n   > Lineas eliminadas: 10 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15105893.txt\n   > Lineas eliminadas: 3 de 13\n   Revisando Q15127012.txt\n   > Lineas eliminadas: 3 de 9\n   Revisando Q15141632.txt\n   > Lineas eliminadas: 10 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15169167.txt\n   > Lineas eliminadas: 1 de 7\n   Revisando Q1518096.txt\n   > Lineas eliminadas: 6 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15221310.txt\n   > Lineas eliminadas: 3 de 11\n   Revisando Q15221370.txt\n   > Lineas eliminadas: 4 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15221373.txt\n   > Lineas eliminadas: 5 de 9\n   Revisando Q152732.txt\n   > Lineas eliminadas: 5 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15298259.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15303838.txt\n   > Lineas eliminadas: 8 de 11\n   Revisando Q153562.txt\n   > Lineas eliminadas: 13 de 13\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q154038.txt\n   > Lineas eliminadas: 4 de 9\n   Revisando Q15416.txt\n   > Lineas eliminadas: 3 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1547289.txt\n   > Lineas eliminadas: 0 de 12\n   Revisando Q1549591.txt\n   > Lineas eliminadas: 0 de 10\n   Revisando Q15584664.txt\n   > Lineas eliminadas: 8 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15633582.txt\n   > Lineas eliminadas: 7 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15647906.txt\n   > Lineas eliminadas: 2 de 12\n   Revisando Q15702752.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q15707583.txt\n   > Lineas eliminadas: 3 de 12\n   Revisando Q15720625.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q15732355.txt\n   > Lineas eliminadas: 8 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q15832079.txt\n   > Lineas eliminadas: 6 de 12\n   Revisando Q15836568.txt\n   > Lineas eliminadas: 1 de 9\n   Revisando Q15841920.txt\n   > Lineas eliminadas: 0 de 3\n   Revisando Q15978299.txt\n   > Lineas eliminadas: 0 de 8\n   Revisando Q15979307.txt\n   > Lineas eliminadas: 6 de 10\n   Revisando Q160091.txt\n   > Lineas eliminadas: 2 de 6\n   Revisando Q16103215.txt\n   > Lineas eliminadas: 4 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q161161.txt\n   > Lineas eliminadas: 5 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1615742.txt\n   > Lineas eliminadas: 7 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1621322.txt\n   > Lineas eliminadas: 1 de 10\n   Revisando Q162620.txt\n   > Lineas eliminadas: 2 de 6\n   Revisando Q162875.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q16335296.txt\n   > Lineas eliminadas: 3 de 11\n   Revisando Q1637706.txt\n   > Lineas eliminadas: 0 de 10\n   Revisando Q1639634.txt\n   > Lineas eliminadas: 5 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q16514343.txt\n   > Lineas eliminadas: 11 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1665984.txt\n   > Lineas eliminadas: 1 de 9\n   Revisando Q16858213.txt\n   > Lineas eliminadas: 8 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q16970.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q171263.txt\n   > Lineas eliminadas: 0 de 11\n   Revisando Q171318.txt\n   > Lineas eliminadas: 3 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q171441.txt\n   > Lineas eliminadas: 2 de 6\n   Revisando Q17156793.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q17205.txt\n   > Lineas eliminadas: 4 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q17305127.txt\n   > Lineas eliminadas: 2 de 7\n   Revisando Q173600.txt\n   > Lineas eliminadas: 6 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q17412916.txt\n   > Lineas eliminadas: 8 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q17447455.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1749269.txt\n   > Lineas eliminadas: 1 de 11\n   Revisando Q1752939.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q176165.txt\n   > Lineas eliminadas: 9 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1762059.txt\n   > Lineas eliminadas: 9 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q177691.txt\n   > Lineas eliminadas: 4 de 10\n   Revisando Q1777138.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q1780506.txt\n   > Lineas eliminadas: 5 de 8\n   Revisando Q178550.txt\n   > Lineas eliminadas: 2 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q179049.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q17910379.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q179461.txt\n   > Lineas eliminadas: 7 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q179805.txt\n   > Lineas eliminadas: 2 de 10\n   Revisando Q1798622.txt\n   > Lineas eliminadas: 2 de 6\n   Revisando Q1799072.txt\n   > Lineas eliminadas: 1 de 6\n   Revisando Q17991810.txt\n   > Lineas eliminadas: 2 de 11\n   Revisando Q1802801.txt\n   > Lineas eliminadas: 8 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q180673.txt\n   > Lineas eliminadas: 3 de 11\n   Revisando Q18089617.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1810858.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q181175.txt\n   > Lineas eliminadas: 1 de 6\n   Revisando Q181322.txt\n   > Lineas eliminadas: 5 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q18142.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q182406.txt\n   > Lineas eliminadas: 5 de 11\n   Revisando Q182531.txt\n   > Lineas eliminadas: 2 de 5\n   Revisando Q182547.txt\n   > Lineas eliminadas: 8 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q18343316.txt\n   > Lineas eliminadas: 7 de 11\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1840161.txt\n   > Lineas eliminadas: 1 de 7\n   Revisando Q184932.txt\n   > Lineas eliminadas: 3 de 11\n   Revisando Q185086.txt\n   > Lineas eliminadas: 4 de 8",
      "\n   Revisando Q18509232.txt\n   > Lineas eliminadas: 1 de 4\n   Revisando Q18511725.txt\n   > Lineas eliminadas: 9 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q185217.txt\n   > Lineas eliminadas: 6 de 12\n   Revisando Q1852859.txt\n   > Lineas eliminadas: 1 de 11\n   Revisando Q185357.txt\n   > Lineas eliminadas: 6 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q18564289.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q18602249.txt\n   > Lineas eliminadas: 4 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q18703581.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q187931.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q188509.txt\n   > Lineas eliminadas: 6 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q188860.txt\n   > Lineas eliminadas: 5 de 9\n   Revisando Q189533.txt\n   > Lineas eliminadas: 2 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q190915.txt\n   > Lineas eliminadas: 9 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q1914636.txt\n   > Lineas eliminadas: 1 de 9\n   Revisando Q192287.txt\n   > Lineas eliminadas: 2 de 8\n   Revisando Q19335303.txt\n   > Lineas eliminadas: 1 de 4\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q193556.txt\n   > Lineas eliminadas: 6 de 11\n   Revisando Q1952852.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q1978718.txt\n   > Lineas eliminadas: 1 de 8\n   Revisando Q1989278.txt\n   > Lineas eliminadas: 4 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2001305.txt\n   > Lineas eliminadas: 0 de 5\n   Revisando Q200141.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2001676.txt\n   > Lineas eliminadas: 12 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q200250.txt\n   > Lineas eliminadas: 1 de 11\n   Revisando Q2008050.txt\n   > Lineas eliminadas: 11 de 11\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q202435.txt\n   > Lineas eliminadas: 0 de 10\n   Revisando Q202595.txt\n   > Lineas eliminadas: 4 de 11\n   Revisando Q202866.txt\n   > Lineas eliminadas: 3 de 7\n   Revisando Q203904.txt\n   > Lineas eliminadas: 6 de 10\n   Revisando Q2039348.txt\n   > Lineas eliminadas: 3 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q205020.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q20638319.txt\n   > Lineas eliminadas: 10 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q20643324.txt\n   > Lineas eliminadas: 2 de 8\n   Revisando Q20653563.txt\n   > Lineas eliminadas: 2 de 5\n   Revisando Q20667187.txt\n   > Lineas eliminadas: 10 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q207170.txt\n   > Lineas eliminadas: 5 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q20724701.txt\n   > Lineas eliminadas: 7 de 11\n   Revisando Q20738676.txt\n   > Lineas eliminadas: 5 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q20738811.txt\n   > Lineas eliminadas: 6 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q20738945.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2074737.txt\n   > Lineas eliminadas: 3 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q20825628.txt\n   > Lineas eliminadas: 2 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q208469.txt\n   > Lineas eliminadas: 1 de 6\n   Revisando Q2087181.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q209939.txt\n   > Lineas eliminadas: 2 de 6\n   Revisando Q21010817.txt\n   > Lineas eliminadas: 0 de 9\n   Revisando Q21011318.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q210337.txt\n   > Lineas eliminadas: 6 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q21125433.txt\n   > Lineas eliminadas: 9 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q21188110.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q21191019.txt\n   > Lineas eliminadas: 2 de 5\n   Revisando Q212057.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q212434.txt\n   > Lineas eliminadas: 1 de 5\n   Revisando Q2139.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q214070.txt\n   > Lineas eliminadas: 13 de 13\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q21507383.txt\n   > Lineas eliminadas: 2 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q21583365.txt\n   > Lineas eliminadas: 7 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q21583366.txt\n   > Lineas eliminadas: 10 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q216048.txt\n   > Lineas eliminadas: 0 de 8\n   Revisando Q21605492.txt\n   > Lineas eliminadas: 0 de 6\n   Revisando Q216337.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q216712.txt\n   > Lineas eliminadas: 5 de 8\n   Revisando Q2198855.txt\n   > Lineas eliminadas: 2 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q222405.txt\n   > Lineas eliminadas: 2 de 11\n   Revisando Q22302160.txt\n   > Lineas eliminadas: 1 de 12\n   Revisando Q2235308.txt\n   > Lineas eliminadas: 1 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2264924.txt\n   > Lineas eliminadas: 0 de 10\n   Revisando Q226730.txt\n   > Lineas eliminadas: 1 de 3\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2267870.txt\n   > Lineas eliminadas: 8 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q22865.txt\n   > Lineas eliminadas: 1 de 11\n   Revisando Q2301325.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2327515.txt\n   > Lineas eliminadas: 2 de 9\n   Revisando Q23413.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q23442.txt\n   > Lineas eliminadas: 1 de 8\n   Revisando Q2351962.txt\n   > Lineas eliminadas: 5 de 8\n   Revisando Q235557.txt\n   > Lineas eliminadas: 3 de 12\n   Revisando Q23691.txt\n   > Lineas eliminadas: 2 de 3\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q23745.txt\n   > Lineas eliminadas: 2 de 4\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2387050.txt\n   > Lineas eliminadas: 3 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q23905105.txt\n   > Lineas eliminadas: 1 de 12\n   Revisando Q24354.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2465832.txt\n   > Lineas eliminadas: 1 de 10\n   Revisando Q247073.txt\n   > Lineas eliminadas: 7 de 10\n   Revisando Q2472587.txt\n   > Lineas eliminadas: 1 de 11\n   Revisando Q24764.txt\n   > Lineas eliminadas: 7 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q24862.txt\n   > Lineas eliminadas: 3 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q24869.txt\n",
      "   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q250811.txt\n   > Lineas eliminadas: 4 de 12\n   Revisando Q253019.txt\n   > Lineas eliminadas: 3 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q253030.txt\n   > Lineas eliminadas: 0 de 9\n   Revisando Q2537.txt\n   > Lineas eliminadas: 9 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2537537.txt\n   > Lineas eliminadas: 8 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2555896.txt\n   > Lineas eliminadas: 1 de 8\n   Revisando Q2572794.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q257978.txt\n   > Lineas eliminadas: 1 de 11\n   Revisando Q2590445.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q2590631.txt\n   > Lineas eliminadas: 7 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2607197.txt\n   > Lineas eliminadas: 2 de 12\n   Revisando Q2616791.txt\n   > Lineas eliminadas: 6 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q262166.txt\n   > Lineas eliminadas: 1 de 10\n   Revisando Q262882.txt\n   > Lineas eliminadas: 3 de 9\n   Revisando Q263639.txt\n   > Lineas eliminadas: 3 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q264965.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q2672914.txt\n   > Lineas eliminadas: 0 de 4\n   Revisando Q2706302.txt\n   > Lineas eliminadas: 6 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q271669.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q271680.txt\n   > Lineas eliminadas: 3 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q273120.txt\n   > Lineas eliminadas: 10 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2743.txt\n   > Lineas eliminadas: 1 de 6\n   Revisando Q274586.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2755753.txt\n   > Lineas eliminadas: 0 de 7\n   Revisando Q27686.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2775969.txt\n   > Lineas eliminadas: 2 de 11\n   Revisando Q28640.txt\n   > Lineas eliminadas: 0 de 13\n   Revisando Q290378.txt\n   > Lineas eliminadas: 1 de 11\n   Revisando Q2911266.txt\n   > Lineas eliminadas: 3 de 7\n   Revisando Q2912397.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2915955.txt\n   > Lineas eliminadas: 3 de 11\n   Revisando Q2916980.txt\n   > Lineas eliminadas: 3 de 7\n   Revisando Q2919801.txt\n   > Lineas eliminadas: 7 de 10\n   Revisando Q29380.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2989398.txt\n   > Lineas eliminadas: 7 de 10\n   Revisando Q2989454.txt\n   > Lineas eliminadas: 9 de 11\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q2989470.txt\n   > Lineas eliminadas: 7 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q299191.txt\n   > Lineas eliminadas: 4 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q3062294.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q3077461.txt\n   > Lineas eliminadas: 0 de 8\n   Revisando Q308891.txt\n   > Lineas eliminadas: 5 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q312457.txt\n   > Lineas eliminadas: 4 de 10\n   Revisando Q31629.txt\n   > Lineas eliminadas: 2 de 12\n   Revisando Q317548.txt\n   > Lineas eliminadas: 7 de 10\n   Revisando Q3184121.txt\n   > Lineas eliminadas: 4 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q3192808.txt\n   > Lineas eliminadas: 8 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q3199141.txt\n   > Lineas eliminadas: 8 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q320018.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q3220391.txt\n   > Lineas eliminadas: 2 de 10\n   Revisando Q3249551.txt\n   > Lineas eliminadas: 1 de 7\n   Revisando Q3257686.txt\n   > Lineas eliminadas: 5 de 11\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q33215.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q3326717.txt\n   > Lineas eliminadas: 1 de 9\n   Revisando Q3327873.txt\n   > Lineas eliminadas: 7 de 11\n   Revisando Q3333265.txt\n   > Lineas eliminadas: 7 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q3387041.txt\n   > Lineas eliminadas: 1 de 8\n   Revisando Q3389302.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q34049.txt\n   > Lineas eliminadas: 6 de 12\n   Revisando Q34442.txt\n   > Lineas eliminadas: 2 de 5\n   Revisando Q34763.txt\n   > Lineas eliminadas: 1 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q349.txt\n   > Lineas eliminadas: 2 de 9\n   Revisando Q3516833.txt\n   > Lineas eliminadas: 4 de 4\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q3550873.txt\n   > Lineas eliminadas: 4 de 10\n   Revisando Q355567.txt\n   > Lineas eliminadas: 0 de 9\n   Revisando Q3556889.txt\n   > Lineas eliminadas: 7 de 10\n   Revisando Q35666.txt\n   > Lineas eliminadas: 5 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q3647172.txt\n   > Lineas eliminadas: 0 de 8\n   Revisando Q36534.txt\n   > Lineas eliminadas: 2 de 8\n   Revisando Q3685462.txt\n   > Lineas eliminadas: 4 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q37484.txt\n   > Lineas eliminadas: 2 de 8\n   Revisando Q375011.txt\n   > Lineas eliminadas: 2 de 7\n   Revisando Q382927.txt\n   > Lineas eliminadas: 3 de 3\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q3863.txt\n   > Lineas eliminadas: 4 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q3884033.txt\n   > Lineas eliminadas: 0 de 3\n   Revisando Q3932296.txt\n   > Lineas eliminadas: 5 de 9\n   Revisando Q3947.txt\n   > Lineas eliminadas: 2 de 3\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q3966183.txt\n   > Lineas eliminadas: 7 de 11\n   Revisando Q40056.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q4022.txt\n   > Lineas eliminadas: 9 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q40540.txt\n   > Lineas eliminadas: 2 de 11\n   Revisando Q4057820.txt\n   > Lineas eliminadas: 3 de 7\n   Revisando Q41156.txt\n   > Lineas eliminadas: 8 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q41298.txt\n   > Lineas eliminadas: 1 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q41425.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q4164871.txt\n   > Lineas eliminadas: 0 de 10\n   Revisando Q4178140.txt\n   > Lineas eliminadas: 3 de 9\n   Revisando Q42032.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q422062.txt\n   > Lineas eliminadas: 1 de 7\n   Revisando Q4220920.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q42523.txt\n   > Lineas eliminadas: 5 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q431289.txt\n   > Lineas eliminadas: 1 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q448801.txt\n   > Lineas eliminadas: 5 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q45776.txt\n   > Lineas eliminadas: 12 de 13\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q462778.txt\n   > Lineas eliminadas: 0 de 5\n   Revisando Q4632675.txt\n   > Lineas eliminadas: 10 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q46395.txt\n   > Lineas eliminadas: 1 de 8\n   Revisando Q467511.txt\n   > Lineas eliminadas: 0 de 10\n   Revisando Q46831.txt\n   > Lineas eliminadas: 0 de 7\n   Revisando Q46970.txt\n   > Lineas eliminadas: 9 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q473972.txt\n   > Lineas eliminadas: 3 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q476028.txt\n   > Lineas eliminadas: 1 de 6\n   Revisando Q477248.txt\n   > Lineas eliminadas: 8 ",
      "de 11\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q483110.txt\n   > Lineas eliminadas: 2 de 3\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q484170.txt\n   > Lineas eliminadas: 0 de 10\n   Revisando Q484641.txt\n   > Lineas eliminadas: 1 de 4\n   Revisando Q4892352.txt\n   > Lineas eliminadas: 5 de 8\n   Revisando Q493522.txt\n   > Lineas eliminadas: 2 de 10\n   Revisando Q4946461.txt\n   > Lineas eliminadas: 3 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q494721.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q49773.txt\n   > Lineas eliminadas: 1 de 5\n   Revisando Q50053.txt\n   > Lineas eliminadas: 5 de 9\n   Revisando Q5009242.txt\n   > Lineas eliminadas: 2 de 9\n   Revisando Q50256.txt\n   > Lineas eliminadas: 11 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q5055981.txt\n   > Lineas eliminadas: 4 de 11\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q506240.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q506883.txt\n   > Lineas eliminadas: 5 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q5084.txt\n   > Lineas eliminadas: 5 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q509686.txt\n   > Lineas eliminadas: 1 de 6\n   Revisando Q5107.txt\n   > Lineas eliminadas: 2 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q5119.txt\n   > Lineas eliminadas: 0 de 11\n   Revisando Q5123999.txt\n   > Lineas eliminadas: 9 de 11\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q5153359.txt\n   > Lineas eliminadas: 2 de 9\n   Revisando Q5185279.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q5200157.txt\n   > Lineas eliminadas: 6 de 11\n   Revisando Q5283559.txt\n   > Lineas eliminadas: 5 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q5393308.txt\n   > Lineas eliminadas: 3 de 3\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q54050.txt\n   > Lineas eliminadas: 5 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q55488.txt\n   > Lineas eliminadas: 2 de 4\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q5569988.txt\n   > Lineas eliminadas: 0 de 9\n   Revisando Q55833.txt\n   > Lineas eliminadas: 6 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q558330.txt\n   > Lineas eliminadas: 4 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q559618.txt\n   > Lineas eliminadas: 5 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q5633421.txt\n   > Lineas eliminadas: 0 de 5\n   Revisando Q57058.txt\n   > Lineas eliminadas: 8 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q57318.txt\n   > Lineas eliminadas: 4 de 9\n   Revisando Q5737899.txt\n   > Lineas eliminadas: 0 de 4\n   Revisando Q57831.txt\n   > Lineas eliminadas: 5 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q581714.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q5891.txt\n   > Lineas eliminadas: 3 de 9\n   Revisando Q612229.txt\n   > Lineas eliminadas: 7 de 10\n   Revisando Q6154783.txt\n   > Lineas eliminadas: 2 de 5\n   Revisando Q62049.txt\n   > Lineas eliminadas: 3 de 12\n   Revisando Q620615.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q6368.txt\n   > Lineas eliminadas: 5 de 9\n   Revisando Q640262.txt\n   > Lineas eliminadas: 6 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q641066.txt\n   > Lineas eliminadas: 5 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q6456916.txt\n   > Lineas eliminadas: 1 de 8\n   Revisando Q6465.txt\n   > Lineas eliminadas: 0 de 7\n   Revisando Q6498903.txt\n   > Lineas eliminadas: 0 de 6\n   Revisando Q655697.txt\n   > Lineas eliminadas: 6 de 10\n   Revisando Q6593035.txt\n   > Lineas eliminadas: 5 de 12\n   Revisando Q66016.txt\n   > Lineas eliminadas: 10 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q667509.txt\n   > Lineas eliminadas: 4 de 10\n   Revisando Q674928.txt\n   > Lineas eliminadas: 0 de 8\n   Revisando Q676050.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q677678.txt\n   > Lineas eliminadas: 8 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q681277.txt\n   > Lineas eliminadas: 7 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q692680.txt\n   > Lineas eliminadas: 8 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q6979593.txt\n   > Lineas eliminadas: 0 de 9\n   Revisando Q699.txt\n   > Lineas eliminadas: 3 de 7\n   Revisando Q70208.txt\n   > Lineas eliminadas: 4 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q707813.txt\n   > Lineas eliminadas: 3 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q7094076.txt\n   > Lineas eliminadas: 7 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q719419.txt\n   > Lineas eliminadas: 2 de 3\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q720711.txt\n   > Lineas eliminadas: 5 de 9\n   Revisando Q7268568.txt\n   > Lineas eliminadas: 6 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q7270.txt\n   > Lineas eliminadas: 2 de 10\n   Revisando Q7309443.txt\n   > Lineas eliminadas: 3 de 9\n   Revisando Q735.txt\n   > Lineas eliminadas: 1 de 8\n   Revisando Q7365.txt\n   > Lineas eliminadas: 3 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q7366.txt\n   > Lineas eliminadas: 3 de 5\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q738570.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q747074.txt\n   > Lineas eliminadas: 3 de 12\n   Revisando Q747381.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q748149.txt\n   > Lineas eliminadas: 7 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q751705.txt\n   > Lineas eliminadas: 14 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q751708.txt\n   > Lineas eliminadas: 3 de 10\n   Revisando Q75520.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q755707.txt\n   > Lineas eliminadas: 3 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q768855.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q769603.txt\n   > Lineas eliminadas: 1 de 11\n   Revisando Q777120.txt\n   > Lineas eliminadas: 5 de 10\n   Revisando Q7830213.txt\n   > Lineas eliminadas: 4 de 9\n   Revisando Q788104.txt\n   > Lineas eliminadas: 11 de 11\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q7889.txt\n   > Lineas eliminadas: 5 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q79007.txt\n   > Lineas eliminadas: 1 de 4\n   Revisando Q8072.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q8148.txt\n   > Lineas eliminadas: 1 de 9\n   Revisando Q816829.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q8192.txt\n   > Lineas eliminadas: 11 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q821435.txt",
      "\n   > Lineas eliminadas: 6 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q82414.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q83116.txt\n   > Lineas eliminadas: 1 de 5\n   Revisando Q831663.txt\n   > Lineas eliminadas: 13 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q83267.txt\n   > Lineas eliminadas: 0 de 8\n   Revisando Q83620.txt\n   > Lineas eliminadas: 2 de 4\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q8366.txt\n   > Lineas eliminadas: 2 de 4\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q838296.txt\n   > Lineas eliminadas: 5 de 11\n   Revisando Q842100.txt\n   > Lineas eliminadas: 10 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q8432.txt\n   > Lineas eliminadas: 3 de 10\n   Revisando Q843886.txt\n   > Lineas eliminadas: 3 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q850450.txt\n   > Lineas eliminadas: 6 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q8514.txt\n   > Lineas eliminadas: 3 de 7\n   Revisando Q851830.txt\n   > Lineas eliminadas: 6 de 6\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q852151.txt\n   > Lineas eliminadas: 8 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q862597.txt\n   > Lineas eliminadas: 1 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q871419.txt\n   > Lineas eliminadas: 2 de 8\n   Revisando Q876730.txt\n   > Lineas eliminadas: 6 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q878367.txt\n   > Lineas eliminadas: 7 de 9\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q898771.txt\n   > Lineas eliminadas: 2 de 6\n   Revisando Q898786.txt\n   > Lineas eliminadas: 4 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q899523.txt\n   > Lineas eliminadas: 2 de 9\n   Revisando Q9143.txt\n   > Lineas eliminadas: 2 de 11\n   Revisando Q917092.txt\n   > Lineas eliminadas: 1 de 7\n   Revisando Q9174.txt\n   > Lineas eliminadas: 3 de 10\n   Revisando Q920890.txt\n   > Lineas eliminadas: 5 de 11\n   Revisando Q925381.txt\n   > Lineas eliminadas: 2 de 10\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q928830.txt\n   > Lineas eliminadas: 12 de 14\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q933394.txt\n   > Lineas eliminadas: 3 de 8\n   Revisando Q937876.txt\n   > Lineas eliminadas: 2 de 5\n   Revisando Q941036.txt\n   > Lineas eliminadas: 6 de 11\n   Revisando Q9415.txt\n   > Lineas eliminadas: 0 de 10\n   Revisando Q94951.txt\n   > Lineas eliminadas: 4 de 8\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q954007.txt\n   > Lineas eliminadas: 1 de 9\n   Revisando Q955655.txt\n   > Lineas eliminadas: 8 de 11\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q971831.txt\n   > Lineas eliminadas: 4 de 7\n   > Conjunto principal u outlier vacios, se procede a eliminar\n   Revisando Q989255.txt\n   > Lineas eliminadas: 1 de 10\n   Revisando Q990488.txt\n   > Lineas eliminadas: 12 de 12\n   > Conjunto principal u outlier vacios, se procede a eliminar\n > Archivos a eliminar: 245\n\n>>> Evaluando embedding  _rand_embedding\n > Extraccion de datasets\n > Obteniendo nombre de archivos de test desde: D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_OutlierDetectionDataset\n",
      " > Test 1 de 255\n   > Sets originales:\n     ['bernoulli', 'strauss']\n     ['sinonimia', 'mario']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['bernoulli', 'strauss'] - oov words: 0 de 2\n     ['sinonimia', 'mario'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 2 de 255\n   > Sets originales:\n     ['volta', 'ashanti']\n     ['viterbo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['volta', 'ashanti'] - oov words: 0 de 2\n     ['viterbo'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 3 de 255\n   > Sets originales:\n     ['oro', 'central']\n     ['raión', 'sarek']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['oro', 'central'] - oov words: 0 de 2\n     ['raión', 'sarek'] - oov words: 0 de 2\n > OP: [2, 2]\n > OD: [1, 1]\n > Test 4 de 255\n   > Sets originales:\n     ['kilimanjaro', 'dolomitas']\n     ['stack']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['kilimanjaro', 'dolomitas'] - oov words: 0 de 2\n     ['stack'] - oov words: 0 de 1\n > OP: [2]\n > OD: [1]\n > Test 5 de 255\n   > Sets originales:\n     ['manhattan', 'londres', 'múnich', 'stuttgart', 'daca']\n     ['raión', 'voivodato']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['manhattan', 'londres', 'múnich', 'stuttgart', 'daca'] - oov words: 0 de 5\n     ['raión', 'voivodato'] - oov words: 0 de 2\n > OP: [5, 3]\n > OD: [1, 0]\n > Test 6 de 255\n   > Sets originales:\n     ['gouda', 'parmesano', 'camembert', 'roquefort']\n     ['muffin', 'fanta']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['gouda', 'parmesano', 'camembert', 'roquefort'] - oov words: 0 de 4\n     ['muffin', 'fanta'] - oov words: 0 de 2\n > OP: [4, 1]\n > OD: [1, 0]\n > Test 7 de 255\n   > Sets originales:\n     ['achicoria', 'hinojo', 'espinaca']\n     ['caña']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['achicoria', 'hinojo', 'espinaca'] - oov words: 0 de 3\n     ['caña'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 8 de 255\n   > Sets originales:\n     ['wordpress', 'mysql', 'freebsd']\n     ['cortina', 'pañuelo', 'túnez']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['wordpress', 'mysql', 'freebsd'] - oov words: 0 de 3\n     ['cortina', 'pañuelo', 'túnez'] - oov words: 0 de 3\n > OP: [3, 2, 1]\n > OD: [1, 0, 0]\n > Test 9 de 255\n   > Sets originales:\n     ['barrancos', 'fátima']\n     ['departamento']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['barrancos', 'fátima'] - oov words: 0 de 2\n     ['departamento'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 10 de 255\n   > Sets originales:\n     ['nara', 'kagoshima', 'nagano', 'akita', 'nagasaki']\n     ['manga', 'alva', 'trujillo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['nara', 'kagoshima', 'nagano', 'akita', 'nagasaki'] - oov words: 0 de 5\n     ['manga', 'alva', 'trujillo'] - oov words: 0 de 3\n > OP: [2, 5, 0]\n > OD: [0, 1, 0]\n > Test 11 de 255\n   > Sets originales:\n     ['mito', 'matsumoto', 'yamagata']\n     ['manga', 'bitinia']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['mito', 'matsumoto', 'yamagata'] - oov words: 0 de 3\n     ['manga', 'bitinia'] - oov words: 0 de 2\n > OP: [1, 3]\n > OD: [0, 1]\n > Test 12 de 255\n   > Sets originales:\n     ['mordor', 'rohan', 'comarca', 'gondor', 'númenor']\n     ['pete', 'mario']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['mordor', 'rohan', 'comarca', 'gondor', 'númenor'] - oov words: 0 de 5\n     ['pete', 'mario'] - oov words: 0 de 2\n > OP: [2, 3]\n > OD: [0, 0]\n > Test 13 de 255\n   > Sets originales:\n     ['hijastra', 'hermanastra', 'hijastro', 'hermanastro', 'madrastra', 'padrastro']\n     ['abuelo', 'tío']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['hijastra', 'hermanastra', 'hijastro', 'hermanastro', 'madrastra', 'padrastro'] - oov words: 0 de 6\n     ['abuelo', 'tío'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 14 de 255\n   > Sets originales:\n     ['metropolitano', 'arzobispo', 'obispo', 'preboste']\n     ['sicario', 'magnate']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['metropolitano', 'arzobispo', 'obispo', 'preboste'] - oov words: 0 de 4\n     ['sicario', 'magnate'] - oov words: 0 de 2\n > OP: [2, 3]\n > OD: [0, 0]\n > Test 15 de 255\n   > Sets originales:\n     ['bonn', 'kassel', 'múnich', 'darmstadt', 'heidelberg', 'mannheim', 'wiesbaden', 'schwerin']\n     ['capitolio', 'reichstag']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['bonn', 'kassel', 'múnich', 'darmstadt', 'heidelberg', 'mannheim', 'wiesbaden', 'schwerin'] - oov words: 0 de 8\n     ['capitolio', 'reichstag'] - oov words: 0 de 2\n > OP: [4, 5]\n > OD: [0, 0]\n > Test 16 de 255\n   > Sets originales:\n     ['berna', 'edimburgo', 'ginebra', 'bonn', 'hannover', 'múnich', 'zúrich']\n     ['voivodato']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['berna', 'edimburgo', 'ginebra', 'bonn', 'hannover', 'múnich', 'zúrich'] - oov words: 0 de 7\n     ['voivodato'] - oov words: 0 de 1\n > OP: [6]\n > OD: [0]\n > Test 17 de 255\n   > Sets originales:\n     ['anna', 'laura', 'olga', 'barbara', 'melissa', 'sara', 'eva', 'maria']\n     ['jan', 'abraham', 'kraus']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['anna', 'laura', 'olga', 'barbara', 'melissa', 'sara', 'eva', 'maria'] - oov words: 0 de 8\n     ['jan', 'abraham', 'kraus'] - oov words: 0 de 3\n > OP: [5, 7, 1]\n > OD: [0, 0, 0]\n > Test 18 de 255\n   > Sets originales:\n     ['gol', 'contrarreforma', 'precipitaciones', 'cruzadas', 'tormenta']\n     ['reconstrucción']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['gol', 'contrarreforma', 'precipitaciones', 'cruzadas', 'tormenta'] - oov words: 0 de 5\n     ['reconstrucción'] - oov words: 0 de 1\n > OP: [4]\n > OD: [0]\n > Test 19 de 255\n   > Sets originales:\n     ['odesa', 'reni']\n     ['somme', 'departamento']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['odesa', 'reni'] - oov words: 0 de 2\n     ['somme', 'departamento'] - oov words: 0 de 2\n > OP: [1, 1]\n > OD: [0, 0]\n > Test 20 de 255\n   > Sets originales:\n     ['cet', 'gmt', 'et']\n     ['salford']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['cet', 'gmt', 'et'] - oov words: 0 de 3\n     ['salford'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 21 de 255\n   > Sets originales:\n     ['adam', 'albert', 'dani', 'ivan', 'emil', 'gabriel']\n     ['andrea', 'apellido', 'bernoulli']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['adam', 'albert', 'dani', 'ivan', 'emil', 'gabriel'] - oov words: 0 de 6\n     ['andrea', 'apellido', 'bernoulli'] - oov words: 0 de 3\n > OP: [3, 6, 5]\n > OD: [0, 1, 0]\n > Test 22 de 255\n   > Sets originales:\n     ['laconia', 'acaya', 'andros', 'beocia']\n     ['larisa']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['laconia', 'acaya', 'andros', 'beocia'] - oov words: 0 de 4\n     ['larisa'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 23 de 255\n   > Sets originales:\n     ['hollywood', 'harlem']\n     ['mozilla']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['hollywood', 'harlem'] - oov words: 0 de 2\n     ['mozilla'] - oov words: 0 de 1\n > OP: [2]\n > OD: [1]\n > Test 24 de 255\n   > Sets originales:\n     ['baltimore', 'richmond', 'alexandria', 'norfolk', 'chesapeake']\n     ['grenada', 'hamburg', 'milan']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['baltimore', 'richmond', 'alexandria', 'norfolk', 'chesapeake'] - oov words: 0 de 5\n     ['grenada', 'hamburg', 'milan'] - oov words: 0 de 3\n > OP: [5, 5, 5]\n > OD: [1, 1, 1]\n > Test 25 de 255\n   > Sets originales:\n     ['caballero', 'estudiante', 'dramaturgo', 'profeta', 'apicultura', 'samurái', 'autor']\n     ['satsuma', 'realidad']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['caballero', 'estudiante', 'dramaturgo', 'profeta', 'apicultura', 'samurái', 'autor'] - oov words: 0 de 7\n     ['satsuma', 'realidad'] - oov words: 0 de 2\n > OP: [7, 0]\n > OD: [1, 0]\n > Test 26 de 255\n   > Sets originales:\n     ['kalmar', 'gotemburgo', 'lund', 'visby']\n     ['este']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['kalmar', 'gotemburgo', 'lund', 'visby'] - oov words: 0 de 4\n     ['este'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 27 de 255\n   > Sets originales:\n     ['barriles', 'galones', 'pinta', 'l', 'cc', 'arqueo']\n     ['magnitud']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['barriles', 'galones', 'pinta', 'l', 'cc', 'arqueo'] - oov words: 0 de 6\n     ['magnitud'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 28 de 255\n   > Sets originales:\n     ['califato', 'teocracia', 'dictadura']\n     ['autocracia']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['califato', 'teocracia', 'dictadura'] - oov words: 0 de 3\n     ['autocracia'] - oov words: 0 de 1\n > OP: [3]\n > OD: [1]\n > Test 29 de 255\n   > Sets originales:\n     ['wordpress', 'mambo']\n     ['sábana', 'mantel', 'carbohidratos', 'túnez']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['wordpress', 'mambo'] - oov words: 0 de 2\n     ['sábana', 'mantel', 'carbohidratos', 'túnez'] - oov words: 0 de 4\n > OP: [2, 2, 1, 1]\n > OD: [1, 1, 0, 0]\n > Test 30 de 255\n   > Sets originales:\n     ['sed', 'nano', 'vi', 'kate', 'emacs']\n     ['maxima', 'latex']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['sed', 'nano', 'vi', 'kate', 'emacs'] - oov words: 0 de 5\n     ['maxima', 'latex'] - oov words: 0 de 2\n > OP: [5, 1]\n > OD: [1, 0]\n > Test 31 de 255\n   > Sets originales:\n     ['ajedrez', 'go', 'backgammon', 'monopoly', 'damas']\n     ['pañuelo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ajedrez', 'go', 'backgammon', 'monopoly', 'damas'] - oov words: 0 de 5\n     ['pañuelo'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 32 de 255\n   > Sets originales:\n     ['ubuntu', 'debian', 'fedora']\n     ['distribución']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ubuntu', 'debian', 'fedora'] - oov words: 0 de 3\n     ['distribución'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 33 de 255\n   > Sets originales:\n     ['debrecen', 'szeged']\n     ['sirte', 'intramuros']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['debrecen', 'szeged'] - oov words: 0 de 2\n     ['sirte', 'intramuros'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 34 de 255\n   > Sets originales:\n     ['hdmi', 'can']\n     ['olimpiadas', 'gmt']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['hdmi', 'can'] - oov words: 0 de 2\n     ['olimpiadas', 'gmt'] - oov words: 0 de 2\n > OP: [1, 2]\n > OD: [0, 1]\n > Test 35 de 255\n   > Sets originales:\n     ['django', 'asp']\n     ['unity', 'pong', 'allmusic']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['django', 'asp'] - oov words: 0 de 2\n     ['unity', 'pong', 'allmusic'] - oov words: 0 de 3\n > OP: [1, 2, 2]\n > OD: [0, 1, 1]\n > Test 36 de 255\n   > Sets originales:\n     ['cien', 'cuatro', 'doce', 'xiv', 'dos', 'diez', '8', 'seis']\n     ['docena']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['cien', 'cuatro', 'doce', 'xiv', 'dos', 'diez', '8', 'seis'] - oov words: 0 de 8\n     ['docena'] - oov words: 0 de 1\n > OP: [7]\n > OD: [0]\n > Test 37 de 255\n   > Sets originales:\n     ['svt', 'ibm', 'juventus', 'commodore']\n     ['virgin']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['svt', 'ibm', 'juventus', 'commodore'] - oov words: 0 de 4\n     ['virgin'] - oov words: 0 de 1\n > OP: [4]\n > OD: [1]\n > Test 38 de 255\n   > Sets originales:\n     ['carmen', 'rigoletto', 'aida']\n     ['reggaeton', 'satsuma', 'realidad']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['carmen', 'rigoletto', 'aida'] - oov words: 0 de 3\n     ['reggaeton', 'satsuma', 'realidad'] - oov words: 0 de 3\n > OP: [3, 3, 2]\n > OD: [1, 1, 0]\n > Test 39 de 255\n   > Sets originales:\n     ['gotinga', 'marburgo', 'fulda', 'greifswald', 'luneburgo']\n     ['somme', 'departamento', 'país']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['gotinga', 'marburgo', 'fulda', 'greifswald', 'luneburgo'] - oov words: 0 de 5\n     ['somme', 'departamento', 'país'] - oov words: 0 de 3\n > OP: [4, 1, 3]\n > OD: [0, 0, 0]\n > Test 40 de 255\n   > Sets originales:\n     ['larisa', 'egina', 'volos', 'rodas']\n     ['i']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['larisa', 'egina', 'volos', 'rodas'] - oov words: 0 de 4\n     ['i'] - oov words: 0 de 1\n > OP: [3]\n > OD: [0]\n > Test 41 de 255\n   > Sets originales:\n     ['nottingham', 'cambridge', 'york', 'leicester', 'exeter', 'norwich', 'oxford', 'derby']\n     ['põlva']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['nottingham', 'cambridge', 'york', 'leicester', 'exeter', 'norwich', 'oxford', 'derby'] - oov words: 0 de 8\n     ['põlva'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 42 de 255\n   > Sets originales:\n     ['dardos', 'mikado', 'petanca', 'taba']\n     ['villancico', 'ajedrez']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['dardos', 'mikado', 'petanca', 'taba'] - oov words: 0 de 4\n     ['villancico', 'ajedrez'] - oov words: 0 de 2\n > OP: [4, 3]\n > OD: [1, 0]\n > Test 43 de 255\n   > Sets originales:\n     ['barn', 'ha', 'acres', 'áreas']\n     ['cinco', 'seis', 'magnitud']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['barn', 'ha', 'acres', 'áreas'] - oov words: 0 de 4\n     ['cinco', 'seis', 'magnitud'] - oov words: 0 de 3\n > OP: [3, 3, 0]\n > OD: [0, 0, 0]\n > Test 44 de 255\n   > Sets originales:\n     ['tokelau', 'molucas', 'bermudas']\n     ['highlands']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['tokelau', 'molucas', 'bermudas'] - oov words: 0 de 3\n     ['highlands'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 45 de 255\n   > Sets originales:\n     ['uno', 'canasta', 'blackjack']\n     ['damas', 'pañuelo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['uno', 'canasta', 'blackjack'] - oov words: 0 de 3\n     ['damas', 'pañuelo'] - oov words: 0 de 2\n > OP: [2, 1]\n > OD: [0, 0]\n > Test 46 de 255\n   > Sets originales:\n     ['akatsuki', 'jedi']\n     ['mario']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['akatsuki', 'jedi'] - oov words: 0 de 2\n     ['mario'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 47 de 255\n   > Sets originales:\n     ['berna', 'ginebra', 'basilea', 'lausana', 'zúrich']\n     ['merrill', 'alva']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['berna', 'ginebra', 'basilea', 'lausana', 'zúrich'] - oov words: 0 de 5\n     ['merrill', 'alva'] - oov words: 0 de 2\n > OP: [0, 5]\n > OD: [0, 1]\n > Test 48 de 255\n   > Sets originales:\n     ['düsseldorf', 'maguncia', 'dresde', 'hannover', 'múnich', 'stuttgart', 'erfurt', 'wiesbaden']\n     ['cheyenne', 'haarlem', 'tiflis', 'põlva']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['düsseldorf', 'maguncia', 'dresde', 'hannover', 'múnich', 'stuttgart', 'erfurt', 'wiesbaden'] - oov words: 0 de 8\n     ['cheyenne', 'haarlem', 'tiflis', 'põlva'] - oov words: 0 de 4\n > OP: [3, 3, 8, 0]\n > OD: [0, 0, 1, 0]\n > Test 49 de 255\n   > Sets originales:\n     ['nissan', 'panasonic', 'honda', 'mazda', 'konami', 'yamaha', 'namco']\n     ['virgin', 'michelin', 'benelux']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['nissan', 'panasonic', 'honda', 'mazda', 'konami', 'yamaha', 'namco'] - oov words: 0 de 7\n     ['virgin', 'michelin', 'benelux'] - oov words: 0 de 3\n > OP: [3, 2, 2]\n > OD: [0, 0, 0]\n > Test 50 de 255\n   > Sets originales:\n     ['troy', 'schenectady', 'yonkers', 'binghamton', 'siracusa', 'buffalo']\n     ['grenada', 'hamburg']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['troy', 'schenectady', 'yonkers', 'binghamton', 'siracusa', 'buffalo'] - oov words: 0 de 6\n     ['grenada', 'hamburg'] - oov words: 0 de 2\n > OP: [2, 6]\n > OD: [0, 1]\n > Test 51 de 255\n   > Sets originales:\n     ['victoria', 'metropolitan', 'central', 'district', 'circle']\n     ['amstel']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['victoria', 'metropolitan', 'central', 'district', 'circle'] - oov words: 0 de 5\n     ['amstel'] - oov words: 0 de 1\n > OP: [5]\n > OD: [1]\n > Test 52 de 255\n   > Sets originales:\n     ['rijeka', 'dubrovnik', 'zagreb', 'zadar', 'osijek', 'split']\n     ['departamento', 'tarn', 'voivodato', 'país']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['rijeka', 'dubrovnik', 'zagreb', 'zadar', 'osijek', 'split'] - oov words: 0 de 6\n     ['departamento', 'tarn', 'voivodato', 'país'] - oov words: 0 de 4\n > OP: [5, 3, 4, 4]\n > OD: [0, 0, 0, 0]\n > Test 53 de 255\n   > Sets originales:\n     ['tiburón', 'plymouth', 'vail', 'concord', 'gilbert']\n     ['tarn']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['tiburón', 'plymouth', 'vail', 'concord', 'gilbert'] - oov words: 0 de 5\n     ['tarn'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 54 de 255\n   > Sets originales:\n     ['ahorcamiento', 'guillotina', 'fusilamiento', 'decapitación', 'lapidación']\n     ['desmembramiento']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ahorcamiento', 'guillotina', 'fusilamiento', 'decapitación', 'lapidación'] - oov words: 0 de 5\n     ['desmembramiento'] - oov words: 0 de 1\n > OP: [5]\n > OD: [1]\n > Test 55 de 255\n   > Sets originales:\n     ['madison', 'racine', 'appleton']\n     ['colby', 'augusta', 'friendship', 'livingston', 'este']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['madison', 'racine', 'appleton'] - oov words: 0 de 3\n     ['colby', 'augusta', 'friendship', 'livingston', 'este'] - oov words: 0 de 5\n > OP: [0, 1, 0, 1, 0]\n > OD: [0, 0, 0, 0, 0]\n > Test 56 de 255\n   > Sets originales:\n     ['alma', 'portage', 'ashland']\n     ['friendship']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['alma', 'portage', 'ashland'] - oov words: 0 de 3\n     ['friendship'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 57 de 255\n   > Sets originales:\n     ['montana', 'lom']\n     ['reading']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['montana', 'lom'] - oov words: 0 de 2\n     ['reading'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 58 de 255\n   > Sets originales:\n     ['wok', 'caldero', 'freidora', 'pava']\n     ['exprimidor']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['wok', 'caldero', 'freidora', 'pava'] - oov words: 0 de 4\n     ['exprimidor'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 59 de 255\n   > Sets originales:\n     ['magdeburgo', 'worms', 'augsburgo', 'eisenach', 'marburgo', 'erfurt', 'heidelberg', 'halle']\n     ['somme', 'departamento', 'país', 'voivodato']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['magdeburgo', 'worms', 'augsburgo', 'eisenach', 'marburgo', 'erfurt', 'heidelberg', 'halle'] - oov words: 0 de 8\n     ['somme', 'departamento', 'país', 'voivodato'] - oov words: 0 de 4\n > OP:",
      " [2, 3, 1, 0]\n > OD: [0, 0, 0, 0]\n > Test 60 de 255\n   > Sets originales:\n     ['lisboa', 'washington', 'parís', 'shanghái', 'estocolmo', 'ámsterdam', 'estambul']\n     ['departamento', 'tarn', 'voivodato']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['lisboa', 'washington', 'parís', 'shanghái', 'estocolmo', 'ámsterdam', 'estambul'] - oov words: 0 de 7\n     ['departamento', 'tarn', 'voivodato'] - oov words: 0 de 3\n > OP: [4, 2, 1]\n > OD: [0, 0, 0]\n > Test 61 de 255\n   > Sets originales:\n     ['tomar', 'viseu', 'évora', 'aveiro', 'braga']\n     ['manga', 'alva', 'somme', 'raión', 'voivodato']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['tomar', 'viseu', 'évora', 'aveiro', 'braga'] - oov words: 0 de 5\n     ['manga', 'alva', 'somme', 'raión', 'voivodato'] - oov words: 0 de 5\n > OP: [3, 5, 4, 5, 2]\n > OD: [0, 1, 0, 1, 0]\n > Test 62 de 255\n   > Sets originales:\n     ['dragón', 'águilas']\n     ['predator', 'dalek', 'enterprise']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['dragón', 'águilas'] - oov words: 0 de 2\n     ['predator', 'dalek', 'enterprise'] - oov words: 0 de 3\n > OP: [2, 2, 2]\n > OD: [1, 1, 1]\n > Test 63 de 255\n   > Sets originales:\n     ['hada', 'dragón', 'gnomo', 'centauro', 'unicornio', 'cíclope', 'minotauro']\n     ['enterprise', 'mario']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['hada', 'dragón', 'gnomo', 'centauro', 'unicornio', 'cíclope', 'minotauro'] - oov words: 0 de 7\n     ['enterprise', 'mario'] - oov words: 0 de 2\n > OP: [1, 4]\n > OD: [0, 0]\n > Test 64 de 255\n   > Sets originales:\n     ['cerbero', 'goofy', 'snoopy', 'pluto']\n     ['silvestre']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['cerbero', 'goofy', 'snoopy', 'pluto'] - oov words: 0 de 4\n     ['silvestre'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 65 de 255\n   > Sets originales:\n     ['roc', 'quetzalcóatl', 'arpía']\n     ['yggdrasil', 'ents', 'warp']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['roc', 'quetzalcóatl', 'arpía'] - oov words: 0 de 3\n     ['yggdrasil', 'ents', 'warp'] - oov words: 0 de 3\n > OP: [2, 2, 2]\n > OD: [0, 0, 0]\n > Test 66 de 255\n   > Sets originales:\n     ['ftp', 'tcp', 'udp', 'http', 'ip', 'irc', 'dns']\n     ['can']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ftp', 'tcp', 'udp', 'http', 'ip', 'irc', 'dns'] - oov words: 0 de 7\n     ['can'] - oov words: 0 de 1\n > OP: [7]\n > OD: [1]\n > Test 67 de 255\n   > Sets originales:\n     ['diy', 'rip']\n     ['coartada']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['diy', 'rip'] - oov words: 0 de 2\n     ['coartada'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 68 de 255\n   > Sets originales:\n     ['liberec', 'pardubice', 'pilsen', 'olomouc', 'ostrava', 'brno']\n     ['departamento', 'tarn']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['liberec', 'pardubice', 'pilsen', 'olomouc', 'ostrava', 'brno'] - oov words: 0 de 6\n     ['departamento', 'tarn'] - oov words: 0 de 2\n > OP: [3, 5]\n > OD: [0, 0]\n > Test 69 de 255\n   > Sets originales:\n     ['gwynedd', 'powys', 'anglesey']\n     ['gibraltar']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['gwynedd', 'powys', 'anglesey'] - oov words: 0 de 3\n     ['gibraltar'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 70 de 255\n   > Sets originales:\n     ['pantanal', 'chaco', 'eslavonia']\n     ['stack']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['pantanal', 'chaco', 'eslavonia'] - oov words: 0 de 3\n     ['stack'] - oov words: 0 de 1\n > OP: [3]\n > OD: [1]\n > Test 71 de 255\n   > Sets originales:\n     ['éowyn', 'boromir', 'faramir', 'aragorn', 'théoden', 'isildur']\n     ['gremlin', 'warp', 'skynet']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['éowyn', 'boromir', 'faramir', 'aragorn', 'théoden', 'isildur'] - oov words: 0 de 6\n     ['gremlin', 'warp', 'skynet'] - oov words: 0 de 3\n > OP: [2, 2, 4]\n > OD: [0, 0, 0]\n > Test 72 de 255\n   > Sets originales:\n     ['asturias', 'navarra', 'cantabria']\n     ['põlva']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['asturias', 'navarra', 'cantabria'] - oov words: 0 de 3\n     ['põlva'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 73 de 255\n   > Sets originales:\n     ['gladiador', 'centurión', 'druida', 'trovador', 'bardo']\n     ['párroco', 'guitarrista', 'mensajero']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['gladiador', 'centurión', 'druida', 'trovador', 'bardo'] - oov words: 0 de 5\n     ['párroco', 'guitarrista', 'mensajero'] - oov words: 0 de 3\n > OP: [2, 4, 1]\n > OD: [0, 0, 0]\n > Test 74 de 255\n   > Sets originales:\n     ['pekín', 'atenas', 'curitiba', 'londres', 'madrid', 'varsovia', 'estambul']\n     ['manga', 'país', 'voivodato']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['pekín', 'atenas', 'curitiba', 'londres', 'madrid', 'varsovia', 'estambul'] - oov words: 0 de 7\n     ['manga', 'país', 'voivodato'] - oov words: 0 de 3\n > OP: [2, 3, 5]\n > OD: [0, 0, 0]\n > Test 75 de 255\n   > Sets originales:\n     ['electroquímica', 'farmacia', 'biotecnología', 'bioquímica', 'climatología']\n     ['criptografía', 'bandeirantes', 'cultura']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['electroquímica', 'farmacia', 'biotecnología', 'bioquímica', 'climatología'] - oov words: 0 de 5\n     ['criptografía', 'bandeirantes', 'cultura'] - oov words: 0 de 3\n > OP: [0, 0, 0]\n > OD: [0, 0, 0]\n > Test 76 de 255\n   > Sets originales:\n     ['húngaro', 'estonio', 'turco', 'suajili', 'georgiano', 'esperanto', 'euskera', 'finés']\n     ['mari', 'clarividencia', 'maleza']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['húngaro', 'estonio', 'turco', 'suajili', 'georgiano', 'esperanto', 'euskera', 'finés'] - oov words: 0 de 8\n     ['mari', 'clarividencia', 'maleza'] - oov words: 0 de 3\n > OP: [1, 0, 0]\n > OD: [0, 0, 0]\n > Test 77 de 255\n   > Sets originales:\n     ['vaticano', 'lesoto']\n     ['voivodato', 'departamento']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['vaticano', 'lesoto'] - oov words: 0 de 2\n     ['voivodato', 'departamento'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 78 de 255\n   > Sets originales:\n     ['superhéroe', 'mago', 'supervillano']\n     ['pete', 'sindarin']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['superhéroe', 'mago', 'supervillano'] - oov words: 0 de 3\n     ['pete', 'sindarin'] - oov words: 0 de 2\n > OP: [2, 1]\n > OD: [0, 0]\n > Test 79 de 255\n   > Sets originales:\n     ['nagoya', 'sapporo', 'kioto', 'yokohama', 'hiroshima', 'osaka', 'fukuoka']\n     ['tsushima', 'alva', 'bitinia']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['nagoya', 'sapporo', 'kioto', 'yokohama', 'hiroshima', 'osaka', 'fukuoka'] - oov words: 0 de 7\n     ['tsushima', 'alva', 'bitinia'] - oov words: 0 de 3\n > OP: [0, 6, 7]\n > OD: [0, 0, 1]\n > Test 80 de 255\n   > Sets originales:\n     ['ntsb', 'nasa', 'usaid', 'cia']\n     ['usda']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ntsb', 'nasa', 'usaid', 'cia'] - oov words: 0 de 4\n     ['usda'] - oov words: 0 de 1\n > OP: [3]\n > OD: [0]\n > Test 81 de 255\n   > Sets originales:\n     ['psd', 'futuro', 'presente']\n     ['imperativo', 'calidad', 'com']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['psd', 'futuro', 'presente'] - oov words: 0 de 3\n     ['imperativo', 'calidad', 'com'] - oov words: 0 de 3\n > OP: [2, 3, 0]\n > OD: [0, 1, 0]\n > Test 82 de 255\n   > Sets originales:\n     ['spa', 'nürburgring', 'imola', 'chn']\n     ['lupa']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['spa', 'nürburgring', 'imola', 'chn'] - oov words: 0 de 4\n     ['lupa'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 83 de 255\n   > Sets originales:\n     ['kandi', 'cotonú']\n     ['x']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['kandi', 'cotonú'] - oov words: 0 de 2\n     ['x'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 84 de 255\n   > Sets originales:\n     ['legitimidad', 'colectivismo', 'pluralismo', 'liberalismo', 'conservador']\n     ['ética', 'pereza', 'aeronáutica']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['legitimidad', 'colectivismo', 'pluralismo', 'liberalismo', 'conservador'] - oov words: 0 de 5\n     ['ética', 'pereza', 'aeronáutica'] - oov words: 0 de 3\n > OP: [4, 4, 2]\n > OD: [0, 0, 0]\n > Test 85 de 255\n   > Sets originales:\n     ['asuán', 'alejandría', 'guiza']\n     ['departamento']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['asuán', 'alejandría', 'guiza'] - oov words: 0 de 3\n     ['departamento'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 86 de 255\n   > Sets originales:\n     ['adivinación', 'pintor', 'escultor']\n     ['experimento', 'respiración']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['adivinación', 'pintor', 'escultor'] - oov words: 0 de 3\n     ['experimento', 'respiración'] - oov words: 0 de 2\n > OP: [2, 0]\n > OD: [0, 0]\n > Test 87 de 255\n   > Sets originales:\n     ['coo', 'vicepresidente', 'cfo', 'cto', 'ceo']\n     ['mago', 'apellido', 'strauss', 'bernoulli']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['coo', 'vicepresidente', 'cfo', 'cto', 'ceo'] - oov words: 0 de 5\n     ['mago', 'apellido', 'strauss', 'bernoulli'] - oov words: 0 de 4\n > OP: [2, 3, 5, 2]\n > OD: [0, 0, 1, 0]\n > Test 88 de 255\n   > Sets originales:\n     ['cumbria', 'essex', 'hampshire', 'cornualles', 'kent', 'surrey', 'devon']\n     ['condados']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['cumbria', 'essex', 'hampshire', 'cornualles', 'kent', 'surrey', 'devon'] - oov words: 0 de 7\n     ['condados'] - oov words: 0 de 1\n > OP: [3]\n > OD: [0]\n > Test 89 de 255\n   > Sets originales:\n     ['tumblr', 'blogger', 'wordpress']\n     ['eclipse', 'compilador']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['tumblr', 'blogger', 'wordpress'] - oov words: 0 de 3\n     ['eclipse', 'compilador'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 90 de 255\n   > Sets originales:\n     ['tiempo', 'presión', 'masa', 'resistencia']\n     ['extensión']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['tiempo', 'presión', 'masa', 'resistencia'] - oov words: 0 de 4\n     ['extensión'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 91 de 255\n   > Sets originales:\n     ['némesis', 'europa', 'calipso', 'arpía']\n     ['éter', 'caos']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['némesis', 'europa', 'calipso', 'arpía'] - oov words: 0 de 4\n     ['éter', 'caos'] - oov words: 0 de 2\n > OP: [2, 4]\n > OD: [0, 1]\n > Test 92 de 255\n   > Sets originales:\n     ['musashi', 'hms']\n     ['género']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['musashi', 'hms'] - oov words: 0 de 2\n     ['género'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 93 de 255\n   > Sets originales:\n     ['valparaíso', 'iquique', 'concepción', 'antofagasta', 'temuco']\n     ['sirte']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['valparaíso', 'iquique', 'concepción', 'antofagasta', 'temuco'] - oov words: 0 de 5\n     ['sirte'] - oov words: 0 de 1\n > OP: [3]\n > OD: [0]\n > Test 94 de 255\n   > Sets originales:\n     ['infinitivo', 'participio', 'optativo', 'indicativo', 'imperativo', 'condicional', 'subjuntivo']\n     ['com']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['infinitivo', 'participio', 'optativo', 'indicativo', 'imperativo', 'condicional', 'subjuntivo'] - oov words: 0 de 7\n     ['com'] - oov words: 0 de 1\n > OP: [3]\n > OD: [0]\n > Test 95 de 255\n   > Sets originales:\n     ['sark', 'guernsey', 'jersey']\n     ['somme']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['sark', 'guernsey', 'jersey'] - oov words: 0 de 3\n     ['somme'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 96 de 255\n   > Sets originales:\n     ['kfc', 'subway']\n     ['fila']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['kfc', 'subway'] - oov words: 0 de 2\n     ['fila'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 97 de 255\n   > Sets originales:\n     ['yogur', 'queso', 'caseína', 'nata']\n     ['toalla', 'pañuelo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['yogur', 'queso', 'caseína', 'nata'] - oov words: 0 de 4\n     ['toalla', 'pañuelo'] - oov words: 0 de 2\n > OP: [3, 2]\n > OD: [0, 0]\n > Test 98 de 255\n   > Sets originales:\n     ['maastricht', 'utrecht', 'arnhem', 'haarlem', 'groninga', 'ámsterdam', 'róterdam']\n     ['borghi', 'raión', 'voivodato']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['maastricht', 'utrecht', 'arnhem', 'haarlem', 'groninga', 'ámsterdam', 'róterdam'] - oov words: 0 de 7\n     ['borghi', 'raión', 'voivodato'] - oov words: 0 de 3\n > OP: [5, 7, 7]\n > OD: [0, 1, 1]\n > Test 99 de 255\n   > Sets originales:\n     ['scrabble', 'go', 'hex']\n     ['damas', 'bingo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['scrabble', 'go', 'hex'] - oov words: 0 de 3\n     ['damas', 'bingo'] - oov words: 0 de 2\n > OP: [2, 1]\n > OD: [0, 0]\n > Test 100 de 255\n   > Sets originales:\n     ['jquery', 'opengl', 'sdl']\n     ['depurador']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['jquery', 'opengl', 'sdl'] - oov words: 0 de 3\n     ['depurador'] - oov words: 0 de 1\n > OP: [3]\n > OD: [1]\n > Test 101 de 255\n   > Sets originales:\n     ['ciclista', 'ascetismo', 'pesca', 'dopaje', 'gastronomía', 'caza']\n     ['locura', 'imitar']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ciclista', 'ascetismo', 'pesca', 'dopaje', 'gastronomía', 'caza'] - oov words: 0 de 6\n     ['locura', 'imitar'] - oov words: 0 de 2\n > OP: [3, 5]\n > OD: [0, 0]\n > Test 102 de 255\n   > Sets originales:\n     ['sochi', 'kaliningrado', 'novosibirsk', 'volgogrado', 'vladivostok']\n     ['viterbo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['sochi', 'kaliningrado', 'novosibirsk', 'volgogrado', 'vladivostok'] - oov words: 0 de 5\n     ['viterbo'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 103 de 255\n   > Sets originales:\n     ['escania', 'gotland']\n     ['bitinia', 'raión', 'sarek']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['escania', 'gotland'] - oov words: 0 de 2\n     ['bitinia', 'raión', 'sarek'] - oov words: 0 de 3\n > OP: [2, 2, 1]\n > OD: [1, 1, 0]\n > Test 104 de 255\n   > Sets originales:\n     ['cozumel', 'ecatepec', 'naucalpan']\n     ['condados', 'i']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['cozumel', 'ecatepec', 'naucalpan'] - oov words: 0 de 3\n     ['condados', 'i'] - oov words: 0 de 2\n > OP: [2, 3]\n > OD: [0, 1]\n > Test 105 de 255\n   > Sets originales:\n     ['km', 'pies', 'mi', 'ua', 'm', 'pulgada']\n     ['cent']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['km', 'pies', 'mi', 'ua', 'm', 'pulgada'] - oov words: 0 de 6",
      "\n     ['cent'] - oov words: 0 de 1\n > OP: [4]\n > OD: [0]\n > Test 106 de 255\n   > Sets originales:\n     ['rts', 'dr', 'tf1']\n     ['digestión', 'fotosíntesis']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['rts', 'dr', 'tf1'] - oov words: 0 de 3\n     ['digestión', 'fotosíntesis'] - oov words: 0 de 2\n > OP: [1, 1]\n > OD: [0, 0]\n > Test 107 de 255\n   > Sets originales:\n     ['karachi', 'londres', 'múnich', 'colonia', 'hyderabad', 'sídney', 'daca']\n     ['alhambra', 'voivodato', 'departamento']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['karachi', 'londres', 'múnich', 'colonia', 'hyderabad', 'sídney', 'daca'] - oov words: 0 de 7\n     ['alhambra', 'voivodato', 'departamento'] - oov words: 0 de 3\n > OP: [0, 3, 5]\n > OD: [0, 0, 0]\n > Test 108 de 255\n   > Sets originales:\n     ['angus', 'fife', 'orcadas', 'edimburgo', 'glasgow', 'shetland', 'aberdeen']\n     ['powys', 'anglesey', 'sarek']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['angus', 'fife', 'orcadas', 'edimburgo', 'glasgow', 'shetland', 'aberdeen'] - oov words: 0 de 7\n     ['powys', 'anglesey', 'sarek'] - oov words: 0 de 3\n > OP: [7, 0, 7]\n > OD: [1, 0, 1]\n > Test 109 de 255\n   > Sets originales:\n     ['arcadia', 'mesenia', 'beocia', 'eubea']\n     ['veria', 'volos', 'venecia']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['arcadia', 'mesenia', 'beocia', 'eubea'] - oov words: 0 de 4\n     ['veria', 'volos', 'venecia'] - oov words: 0 de 3\n > OP: [0, 1, 0]\n > OD: [0, 0, 0]\n > Test 110 de 255\n   > Sets originales:\n     ['bambi', 'dumbo', 'avatar']\n     ['electrostática']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['bambi', 'dumbo', 'avatar'] - oov words: 0 de 3\n     ['electrostática'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 111 de 255\n   > Sets originales:\n     ['galadriel', 'legolas']\n     ['saruman', 'gandalf']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['galadriel', 'legolas'] - oov words: 0 de 2\n     ['saruman', 'gandalf'] - oov words: 0 de 2\n > OP: [2, 2]\n > OD: [1, 1]\n > Test 112 de 255\n   > Sets originales:\n     ['gnome', 'cde', 'mate', 'cinnamon']\n     ['twitch']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['gnome', 'cde', 'mate', 'cinnamon'] - oov words: 0 de 4\n     ['twitch'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 113 de 255\n   > Sets originales:\n     ['zarzuela', 'opereta']\n     ['dub', 'reggae', 'parcela', 'norma']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['zarzuela', 'opereta'] - oov words: 0 de 2\n     ['dub', 'reggae', 'parcela', 'norma'] - oov words: 0 de 4\n > OP: [0, 1, 1, 0]\n > OD: [0, 0, 0, 0]\n > Test 114 de 255\n   > Sets originales:\n     ['movistar', 'rabobank']\n     ['tas']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['movistar', 'rabobank'] - oov words: 0 de 2\n     ['tas'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 115 de 255\n   > Sets originales:\n     ['armavir', 'ereván']\n     ['sava', 'borne']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['armavir', 'ereván'] - oov words: 0 de 2\n     ['sava', 'borne'] - oov words: 0 de 2\n > OP: [1, 0]\n > OD: [0, 0]\n > Test 116 de 255\n   > Sets originales:\n     ['hz', 'kn', 'j', 'kw']\n     ['ppi']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['hz', 'kn', 'j', 'kw'] - oov words: 0 de 4\n     ['ppi'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 117 de 255\n   > Sets originales:\n     ['s', 'pulse']\n     ['álbum', 'disquete']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['s', 'pulse'] - oov words: 0 de 2\n     ['álbum', 'disquete'] - oov words: 0 de 2\n > OP: [1, 1]\n > OD: [0, 0]\n > Test 118 de 255\n   > Sets originales:\n     ['filadelfia', 'allentown', 'reading', 'bethlehem', 'erie', 'harrisburg', 'pittsburgh', 'scranton']\n     ['carlisle']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['filadelfia', 'allentown', 'reading', 'bethlehem', 'erie', 'harrisburg', 'pittsburgh', 'scranton'] - oov words: 0 de 8\n     ['carlisle'] - oov words: 0 de 1\n > OP: [5]\n > OD: [0]\n > Test 119 de 255\n   > Sets originales:\n     ['uriel', 'metatrón', 'lucifer', 'gabriel']\n     ['duende']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['uriel', 'metatrón', 'lucifer', 'gabriel'] - oov words: 0 de 4\n     ['duende'] - oov words: 0 de 1\n > OP: [4]\n > OD: [1]\n > Test 120 de 255\n   > Sets originales:\n     ['inuyasha', 'naruto']\n     ['dune']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['inuyasha', 'naruto'] - oov words: 0 de 2\n     ['dune'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 121 de 255\n   > Sets originales:\n     ['remo', 'halterofilia', 'grecorromana']\n     ['yoga']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['remo', 'halterofilia', 'grecorromana'] - oov words: 0 de 3\n     ['yoga'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 122 de 255\n   > Sets originales:\n     ['galatea', 'larisa', 'tritón', 'proteo']\n     ['caronte']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['galatea', 'larisa', 'tritón', 'proteo'] - oov words: 0 de 4\n     ['caronte'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 123 de 255\n   > Sets originales:\n     ['balonmano', 'hockey', 'bandy', 'críquet', 'béisbol', 'bobsleigh', 'curling']\n     ['bowls']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['balonmano', 'hockey', 'bandy', 'críquet', 'béisbol', 'bobsleigh', 'curling'] - oov words: 0 de 7\n     ['bowls'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 124 de 255\n   > Sets originales:\n     ['mariner', 'viking', 'ranger', 'voyager', 'gemini']\n     ['mir']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['mariner', 'viking', 'ranger', 'voyager', 'gemini'] - oov words: 0 de 5\n     ['mir'] - oov words: 0 de 1\n > OP: [5]\n > OD: [1]\n > Test 125 de 255\n   > Sets originales:\n     ['canterbury', 'southland']\n     ['viterbo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['canterbury', 'southland'] - oov words: 0 de 2\n     ['viterbo'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 126 de 255\n   > Sets originales:\n     ['bayoneta', 'florete', 'hacha', 'tomahawk', 'machete', 'tridente']\n     ['tamiz', 'sello', 'glock']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['bayoneta', 'florete', 'hacha', 'tomahawk', 'machete', 'tridente'] - oov words: 0 de 6\n     ['tamiz', 'sello', 'glock'] - oov words: 0 de 3\n > OP: [5, 5, 2]\n > OD: [0, 0, 0]\n > Test 127 de 255\n   > Sets originales:\n     ['tren', 'pasajero', 'país', 'acciones', 'aviador', 'vehículo', 'humanos', 'aeronave']\n     ['canoa', 'internet', 'jerarquía']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['tren', 'pasajero', 'país', 'acciones', 'aviador', 'vehículo', 'humanos', 'aeronave'] - oov words: 0 de 8\n     ['canoa', 'internet', 'jerarquía'] - oov words: 0 de 3\n > OP: [1, 1, 3]\n > OD: [0, 0, 0]\n > Test 128 de 255\n   > Sets originales:\n     ['marsella', 'singapur', 'barcelona', 'reikiavik', 'venecia', 'gibraltar', 'ámsterdam']\n     ['departamento', 'país', 'borough']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['marsella', 'singapur', 'barcelona', 'reikiavik', 'venecia', 'gibraltar', 'ámsterdam'] - oov words: 0 de 7\n     ['departamento', 'país', 'borough'] - oov words: 0 de 3\n > OP: [6, 6, 6]\n > OD: [0, 0, 0]\n > Test 129 de 255\n   > Sets originales:\n     ['dresde', 'bonn', 'hannover', 'múnich', 'colonia', 'leipzig', 'wiesbaden']\n     ['aurich', 'londres', 'panamá']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['dresde', 'bonn', 'hannover', 'múnich', 'colonia', 'leipzig', 'wiesbaden'] - oov words: 0 de 7\n     ['aurich', 'londres', 'panamá'] - oov words: 0 de 3\n > OP: [7, 6, 5]\n > OD: [1, 0, 0]\n > Test 130 de 255\n   > Sets originales:\n     ['ulm', 'karlsruhe', 'stuttgart', 'heidelberg', 'mannheim']\n     ['münster', 'colonia']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ulm', 'karlsruhe', 'stuttgart', 'heidelberg', 'mannheim'] - oov words: 0 de 5\n     ['münster', 'colonia'] - oov words: 0 de 2\n > OP: [2, 1]\n > OD: [0, 0]\n > Test 131 de 255\n   > Sets originales:\n     ['java', 'irlanda', 'creta', 'aruba', 'guam', 'madagascar']\n     ['stack']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['java', 'irlanda', 'creta', 'aruba', 'guam', 'madagascar'] - oov words: 0 de 6\n     ['stack'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 132 de 255\n   > Sets originales:\n     ['gimp', 'paint']\n     ['sdl']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['gimp', 'paint'] - oov words: 0 de 2\n     ['sdl'] - oov words: 0 de 1\n > OP: [2]\n > OD: [1]\n > Test 133 de 255\n   > Sets originales:\n     ['pdf', 'gif', 'css', 'xml', 'html', 'sql']\n     ['mp3', 'olimpiadas', 'utc']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['pdf', 'gif', 'css', 'xml', 'html', 'sql'] - oov words: 0 de 6\n     ['mp3', 'olimpiadas', 'utc'] - oov words: 0 de 3\n > OP: [0, 0, 4]\n > OD: [0, 0, 0]\n > Test 134 de 255\n   > Sets originales:\n     ['brasil', 'alemania', 'japón', 'inglaterra', 'suecia', 'china', 'noruega']\n     ['ecuador', 'mónaco', 'yugoslavia', 'letonia']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['brasil', 'alemania', 'japón', 'inglaterra', 'suecia', 'china', 'noruega'] - oov words: 0 de 7\n     ['ecuador', 'mónaco', 'yugoslavia', 'letonia'] - oov words: 0 de 4\n > OP: [0, 1, 2, 3]\n > OD: [0, 0, 0, 0]\n > Test 135 de 255\n   > Sets originales:\n     ['química', 'física', 'fisiología', 'astrofísica', 'matemáticas', 'astronomía', 'zoólogo']\n     ['bandeirantes', 'cultura']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['química', 'física', 'fisiología', 'astrofísica', 'matemáticas', 'astronomía', 'zoólogo'] - oov words: 0 de 7\n     ['bandeirantes', 'cultura'] - oov words: 0 de 2\n > OP: [2, 5]\n > OD: [0, 0]\n > Test 136 de 255\n   > Sets originales:\n     ['varsovia', 'garwolin']\n     ['sava']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['varsovia', 'garwolin'] - oov words: 0 de 2\n     ['sava'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 137 de 255\n   > Sets originales:\n     ['francos', 'vikingo', 'judío', 'italiano', 'esquimal', 'uigur']\n     ['cienciología', 'pared', 'jerarquía', 'pictos']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['francos', 'vikingo', 'judío', 'italiano', 'esquimal', 'uigur'] - oov words: 0 de 6\n     ['cienciología', 'pared', 'jerarquía', 'pictos'] - oov words: 0 de 4\n > OP: [2, 3, 2, 2]\n > OD: [0, 0, 0, 0]\n > Test 138 de 255\n   > Sets originales:\n     ['cantón', 'nankín', 'harbin', 'chengdu', 'wuhan', 'shenzhen', 'hangzhou']\n     ['hainan']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['cantón', 'nankín', 'harbin', 'chengdu', 'wuhan', 'shenzhen', 'hangzhou'] - oov words: 0 de 7\n     ['hainan'] - oov words: 0 de 1\n > OP: [5]\n > OD: [0]\n > Test 139 de 255\n   > Sets originales:\n     ['dresde', 'bonn', 'lübeck', 'dortmund', 'karlsruhe', 'stuttgart', 'erfurt', 'wiesbaden']\n     ['norma']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['dresde', 'bonn', 'lübeck', 'dortmund', 'karlsruhe', 'stuttgart', 'erfurt', 'wiesbaden'] - oov words: 0 de 8\n     ['norma'] - oov words: 0 de 1\n > OP: [6]\n > OD: [0]\n > Test 140 de 255\n   > Sets originales:\n     ['barranquilla', 'cúcuta', 'cali', 'bucaramanga', 'bogotá', 'medellín']\n     ['sirte']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['barranquilla', 'cúcuta', 'cali', 'bucaramanga', 'bogotá', 'medellín'] - oov words: 0 de 6\n     ['sirte'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 141 de 255\n   > Sets originales:\n     ['tanka', 'limerick']\n     ['troika', 'idilio', 'hallelujah']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['tanka', 'limerick'] - oov words: 0 de 2\n     ['troika', 'idilio', 'hallelujah'] - oov words: 0 de 3\n > OP: [1, 0, 2]\n > OD: [0, 0, 1]\n > Test 142 de 255\n   > Sets originales:\n     ['liberec', 'pardubice', 'pilsen', 'olomouc', 'ostrava', 'brno']\n     ['hampton', 'alva', 'condados', 'rota']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['liberec', 'pardubice', 'pilsen', 'olomouc', 'ostrava', 'brno'] - oov words: 0 de 6\n     ['hampton', 'alva', 'condados', 'rota'] - oov words: 0 de 4\n > OP: [4, 6, 4, 3]\n > OD: [0, 1, 0, 0]\n > Test 143 de 255\n   > Sets originales:\n     ['antiguos', 'wookiee', 'borg', 'hutt']\n     ['mario']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['antiguos', 'wookiee', 'borg', 'hutt'] - oov words: 0 de 4\n     ['mario'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 144 de 255\n   > Sets originales:\n     ['elfo', 'ogro', 'asgard', 'orco', 'vampiro', 'wraith']\n     ['centauro', 'dalek', 'enterprise', 'comarca']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['elfo', 'ogro', 'asgard', 'orco', 'vampiro', 'wraith'] - oov words: 0 de 6\n     ['centauro', 'dalek', 'enterprise', 'comarca'] - oov words: 0 de 4\n > OP: [1, 3, 0, 1]\n > OD: [0, 0, 0, 0]\n > Test 145 de 255\n   > Sets originales:\n     ['düsseldorf', 'bonn', 'aquisgrán', 'kiel', 'dortmund', 'stuttgart', 'heidelberg']\n     ['din', 'londres']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['düsseldorf', 'bonn', 'aquisgrán', 'kiel', 'dortmund', 'stuttgart', 'heidelberg'] - oov words: 0 de 7\n     ['din', 'londres'] - oov words: 0 de 2\n > OP:",
      " [3, 6]\n > OD: [0, 0]\n > Test 146 de 255\n   > Sets originales:\n     ['graz', 'salzburgo', 'innsbruck', 'linz', 'klagenfurt']\n     ['sarek']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['graz', 'salzburgo', 'innsbruck', 'linz', 'klagenfurt'] - oov words: 0 de 5\n     ['sarek'] - oov words: 0 de 1\n > OP: [4]\n > OD: [0]\n > Test 147 de 255\n   > Sets originales:\n     ['skinhead', 'lolita', 'hipster']\n     ['pana', 'damasco']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['skinhead', 'lolita', 'hipster'] - oov words: 0 de 3\n     ['pana', 'damasco'] - oov words: 0 de 2\n > OP: [0, 3]\n > OD: [0, 1]\n > Test 148 de 255\n   > Sets originales:\n     ['impulso', 'magnetización', 'velocidad']\n     ['ganancia']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['impulso', 'magnetización', 'velocidad'] - oov words: 0 de 3\n     ['ganancia'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 149 de 255\n   > Sets originales:\n     ['cats', 'hair', 'evita']\n     ['safari', 'excavaciones']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['cats', 'hair', 'evita'] - oov words: 0 de 3\n     ['safari', 'excavaciones'] - oov words: 0 de 2\n > OP: [2, 3]\n > OD: [0, 1]\n > Test 150 de 255\n   > Sets originales:\n     ['westminster', 'wimbledon', 'soho', 'mayfair', 'greenwich']\n     ['chinatown', 'kde']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['westminster', 'wimbledon', 'soho', 'mayfair', 'greenwich'] - oov words: 0 de 5\n     ['chinatown', 'kde'] - oov words: 0 de 2\n > OP: [5, 5]\n > OD: [1, 1]\n > Test 151 de 255\n   > Sets originales:\n     ['alderaan', 'arda', 'naboo', 'hoth', 'tatooine', 'nibiru', 'coruscant']\n     ['atlántida', 'sindarin']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['alderaan', 'arda', 'naboo', 'hoth', 'tatooine', 'nibiru', 'coruscant'] - oov words: 0 de 7\n     ['atlántida', 'sindarin'] - oov words: 0 de 2\n > OP: [5, 4]\n > OD: [0, 0]\n > Test 152 de 255\n   > Sets originales:\n     ['actor', 'escritor', 'astronauta', 'sacerdote', 'poeta', 'científico', 'médico', 'educador']\n     ['central', 'conducción', 'norma', 'roi', 'pana']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['actor', 'escritor', 'astronauta', 'sacerdote', 'poeta', 'científico', 'médico', 'educador'] - oov words: 0 de 8\n     ['central', 'conducción', 'norma', 'roi', 'pana'] - oov words: 0 de 5\n > OP: [0, 3, 6, 8, 2]\n > OD: [0, 0, 0, 1, 0]\n > Test 153 de 255\n   > Sets originales:\n     ['ftp', 'tcp', 'udp', 'smtp', 'telnet', 'ip', 'dns']\n     ['unicode', 'utc', 'año']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ftp', 'tcp', 'udp', 'smtp', 'telnet', 'ip', 'dns'] - oov words: 0 de 7\n     ['unicode', 'utc', 'año'] - oov words: 0 de 3\n > OP: [4, 7, 4]\n > OD: [0, 1, 0]\n > Test 154 de 255\n   > Sets originales:\n     ['princeton', 'westwood']\n     ['bedford', 'lambeth']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['princeton', 'westwood'] - oov words: 0 de 2\n     ['bedford', 'lambeth'] - oov words: 0 de 2\n > OP: [1, 1]\n > OD: [0, 0]\n > Test 155 de 255\n   > Sets originales:\n     ['ilustración', 'confucianismo', 'taoísmo', 'existencialismo']\n     ['escéptico', 'manierista', 'simbolismo', 'origami']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ilustración', 'confucianismo', 'taoísmo', 'existencialismo'] - oov words: 0 de 4\n     ['escéptico', 'manierista', 'simbolismo', 'origami'] - oov words: 0 de 4\n > OP: [3, 0, 2, 0]\n > OD: [0, 0, 0, 0]\n > Test 156 de 255\n   > Sets originales:\n     ['ev', 'caloría', 'j']\n     ['ppi']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ev', 'caloría', 'j'] - oov words: 0 de 3\n     ['ppi'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 157 de 255\n   > Sets originales:\n     ['schengen', 'luxemburgo']\n     ['condados']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['schengen', 'luxemburgo'] - oov words: 0 de 2\n     ['condados'] - oov words: 0 de 1\n > OP: [2]\n > OD: [1]\n > Test 158 de 255\n   > Sets originales:\n     ['constantina', 'orán']\n     ['viterbo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['constantina', 'orán'] - oov words: 0 de 2\n     ['viterbo'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 159 de 255\n   > Sets originales:\n     ['jungla', 'manglar', 'taiga', 'grass', 'bosque', 'estepa']\n     ['cerrado', 'stack']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['jungla', 'manglar', 'taiga', 'grass', 'bosque', 'estepa'] - oov words: 0 de 6\n     ['cerrado', 'stack'] - oov words: 0 de 2\n > OP: [5, 3]\n > OD: [0, 0]\n > Test 160 de 255\n   > Sets originales:\n     ['negra', 'redonda', 'cuadrada', 'blanca']\n     ['cantata', 'ragtime']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['negra', 'redonda', 'cuadrada', 'blanca'] - oov words: 0 de 4\n     ['cantata', 'ragtime'] - oov words: 0 de 2\n > OP: [2, 2]\n > OD: [0, 0]\n > Test 161 de 255\n   > Sets originales:\n     ['esgrima', 'billar', 'fútbol', 'baloncesto', 'lucha', 'esquí']\n     ['bowls', 'excavaciones', 'tenis', 'skate']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['esgrima', 'billar', 'fútbol', 'baloncesto', 'lucha', 'esquí'] - oov words: 0 de 6\n     ['bowls', 'excavaciones', 'tenis', 'skate'] - oov words: 0 de 4\n > OP: [2, 4, 5, 1]\n > OD: [0, 0, 0, 0]\n > Test 162 de 255\n   > Sets originales:\n     ['sochi', 'interlaken']\n     ['borghi']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['sochi', 'interlaken'] - oov words: 0 de 2\n     ['borghi'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 163 de 255\n   > Sets originales:\n     ['flickr', 'linkedin', 'twitter', 'myspace', 'instagram', 'facebook']\n     ['depurador', 'compilador']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['flickr', 'linkedin', 'twitter', 'myspace', 'instagram', 'facebook'] - oov words: 0 de 6\n     ['depurador', 'compilador'] - oov words: 0 de 2\n > OP: [3, 4]\n > OD: [0, 0]\n > Test 164 de 255\n   > Sets originales:\n     ['doblaje', 'radiactividad', 'grabación', 'purgatorio', 'globalización']\n     ['tormenta']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['doblaje', 'radiactividad', 'grabación', 'purgatorio', 'globalización'] - oov words: 0 de 5\n     ['tormenta'] - oov words: 0 de 1\n > OP: [3]\n > OD: [0]\n > Test 165 de 255\n   > Sets originales:\n     ['ido', 'occidental', 'esperanto', 'klingon']\n     ['norma']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ido', 'occidental', 'esperanto', 'klingon'] - oov words: 0 de 4\n     ['norma'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 166 de 255\n   > Sets originales:\n     ['naturalismo', 'futurismo', 'romanticismo', 'existencialismo', 'simbolismo', 'realismo']\n     ['barroco', 'humanista']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['naturalismo', 'futurismo', 'romanticismo', 'existencialismo', 'simbolismo', 'realismo'] - oov words: 0 de 6\n     ['barroco', 'humanista'] - oov words: 0 de 2\n > OP: [0, 1]\n > OD: [0, 0]\n > Test 167 de 255\n   > Sets originales:\n     ['quebec', 'laval', 'montreal']\n     ['cobán']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['quebec', 'laval', 'montreal'] - oov words: 0 de 3\n     ['cobán'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 168 de 255\n   > Sets originales:\n     ['presión', 'densidad', 'concentración', 'velocidad', 'viscosidad']\n     ['estímulo', 'magma']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['presión', 'densidad', 'concentración', 'velocidad', 'viscosidad'] - oov words: 0 de 5\n     ['estímulo', 'magma'] - oov words: 0 de 2\n > OP: [0, 1]\n > OD: [0, 0]\n > Test 169 de 255\n   > Sets originales:\n     ['hebreo', 'fenicio', 'egipcio', 'acadio']\n     ['neerlandés', 'zulú']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['hebreo', 'fenicio', 'egipcio', 'acadio'] - oov words: 0 de 4\n     ['neerlandés', 'zulú'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 170 de 255\n   > Sets originales:\n     ['autopista', 'whitehall']\n     ['bowery']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['autopista', 'whitehall'] - oov words: 0 de 2\n     ['bowery'] - oov words: 0 de 1\n > OP: [2]\n > OD: [1]\n > Test 171 de 255\n   > Sets originales:\n     ['yoga', 'automovilismo', 'parkour', 'gimnasia', 'skate']\n     ['ordeño', 'mutación']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['yoga', 'automovilismo', 'parkour', 'gimnasia', 'skate'] - oov words: 0 de 5\n     ['ordeño', 'mutación'] - oov words: 0 de 2\n > OP: [0, 2]\n > OD: [0, 0]\n > Test 172 de 255\n   > Sets originales:\n     ['mb', 'kb', 'byte', 'gb', 'bit']\n     ['cent']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['mb', 'kb', 'byte', 'gb', 'bit'] - oov words: 0 de 5\n     ['cent'] - oov words: 0 de 1\n > OP: [5]\n > OD: [1]\n > Test 173 de 255\n   > Sets originales:\n     ['caballero', 'rey', 'sultán', 'duque', 'samurái', 'emperador', 'faraón']\n     ['magnate', 'maharajá']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['caballero', 'rey', 'sultán', 'duque', 'samurái', 'emperador', 'faraón'] - oov words: 0 de 7\n     ['magnate', 'maharajá'] - oov words: 0 de 2\n > OP: [4, 3]\n > OD: [0, 0]\n > Test 174 de 255\n   > Sets originales:\n     ['chalatenango', 'sonsonate']\n     ['asunción']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['chalatenango', 'sonsonate'] - oov words: 0 de 2\n     ['asunción'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 175 de 255\n   > Sets originales:\n     ['ev', 'onza', 'g', 'kda', 'kg', 'libras']\n     ['ppi', 'magnitud']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ev', 'onza', 'g', 'kda', 'kg', 'libras'] - oov words: 0 de 6\n     ['ppi', 'magnitud'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 176 de 255\n   > Sets originales:\n     ['cataliza', 'oxidación', 'neutralización']\n     ['benchmarking', 'mutación', 'respiración']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['cataliza', 'oxidación', 'neutralización'] - oov words: 0 de 3\n     ['benchmarking', 'mutación', 'respiración'] - oov words: 0 de 3\n > OP: [2, 1, 1]\n > OD: [0, 0, 0]\n > Test 177 de 255\n   > Sets originales:\n     ['eneida', 'ilíada', 'odisea', 'beowulf']\n     ['olimpiadas', 'utc']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['eneida', 'ilíada', 'odisea', 'beowulf'] - oov words: 0 de 4\n     ['olimpiadas', 'utc'] - oov words: 0 de 2\n > OP: [4, 4]\n > OD: [1, 1]\n > Test 178 de 255\n   > Sets originales:\n     ['pentecostés', 'epifanía', 'pascua']\n     ['varsovia', 'lyon']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['pentecostés', 'epifanía', 'pascua'] - oov words: 0 de 3\n     ['varsovia', 'lyon'] - oov words: 0 de 2\n > OP: [2, 1]\n > OD: [0, 0]\n > Test 179 de 255\n   > Sets originales:\n     ['potencia', 'complemento']\n     ['radicación']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['potencia', 'complemento'] - oov words: 0 de 2\n     ['radicación'] - oov words: 0 de 1\n > OP: [2]\n > OD: [1]\n > Test 180 de 255\n   > Sets originales:\n     ['mysql', 'sql', 'oracle']\n     ['nero']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['mysql', 'sql', 'oracle'] - oov words: 0 de 3\n     ['nero'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 181 de 255\n   > Sets originales:\n     ['pikachu', 'mew']\n     ['águilas', 'predator']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['pikachu', 'mew'] - oov words: 0 de 2\n     ['águilas', 'predator'] - oov words: 0 de 2\n > OP: [2, 2]\n > OD: [1, 1]\n > Test 182 de 255\n   > Sets originales:\n     ['sed', 'malware', 'controladores']\n     ['norma', 'arcaico']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['sed', 'malware', 'controladores'] - oov words: 0 de 3\n     ['norma', 'arcaico'] - oov words: 0 de 2\n > OP: [2, 0]\n > OD: [0, 0]\n > Test 183 de 255\n   > Sets originales:\n     ['escorpio', 'libra', 'cáncer', 'tauro', 'sagitario', 'virgo', 'aries', 'géminis']\n     ['bliss']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['escorpio', 'libra', 'cáncer', 'tauro', 'sagitario', 'virgo', 'aries', 'géminis'] - oov words: 0 de 8\n     ['bliss'] - oov words: 0 de 1\n > OP: [8]\n > OD: [1]\n > Test 184 de 255\n   > Sets originales:\n     ['suroeste', 'oeste', 'sur']\n     ['trastevere']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['suroeste', 'oeste', 'sur'] - oov words: 0 de 3\n     ['trastevere'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 185 de 255\n   > Sets originales:\n     ['giselle', 'bolero']\n     ['swing', 'programación', 'entendimiento']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['giselle', 'bolero'] - oov words: 0 de 2\n     ['swing', 'programación', 'entendimiento'] - oov words: 0 de 3\n > OP: [2, 1, 2]\n > OD: [1, 0, 1]\n > Test 186 de 255\n   > Sets originales:\n     ['rey', 'papa', 'alcalde', 'obispo', 'zar', 'presidente']\n     ['conducción', 'gunas', 'satsuma', 'damasco']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['rey', 'papa', 'alcalde', 'obispo', 'zar', 'presidente'] - oov words: 0 de 6\n     ['conducción', 'gunas', 'satsuma', 'damasco'] - oov words: 0 de 4\n > OP: [1, 0, 4, 4]\n > OD: [0, 0, 0, 0]\n > Test 187 de 255\n   > Sets originales:\n     ['shōnen', 'shōjo', 'harem', 'yuri', 'mecha']\n     ['origin']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['shōnen', 'shōjo', 'harem', 'yuri', 'mecha'] - oov words: 0 de 5\n     ['origin'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 188 de 255\n   > Sets originales:\n     ['audi', 'porsche', 'siemens']\n     ['virgin', 'michelin', 'benelux']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['audi', 'porsche', 'siemens'] - oov words: 0 de 3\n     ['virgin', 'michelin', 'benelux'] - oov words: 0 de 3\n > OP: [0, 2, 3]\n > OD: [0, 0, 1]\n > Test 189 de 255\n   > Sets originales:\n     ['camarógrafo', 'script']\n     ['filósofo', 'guitarrista', 'conducción']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['camarógrafo', 'script'] - oov words: 0 de 2\n     ['filósofo', 'guitarrista', 'conducción'] - oov words: 0 de 3\n > OP: [1, 0, 1]\n > OD: [0, 0, 0]\n > Test 190 de 255\n   > Sets originales:\n     ['midway', 'guam']\n     ['tasmania', 'país', 'borough']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['midway', 'guam'] - oov words: 0 de 2\n     ['tasmania', 'país', 'borough'] - oov words: 0 de 3\n > OP: [0, 0, 1]\n > OD: [0, 0, 0]\n > Test 191 de 255\n   > Sets originales:\n     ['pitcairn', 'montserrat', 'gibraltar', 'bermudas', 'anguila']\n     ['somme', 'tarn']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:",
      "\n     ['pitcairn', 'montserrat', 'gibraltar', 'bermudas', 'anguila'] - oov words: 0 de 5\n     ['somme', 'tarn'] - oov words: 0 de 2\n > OP: [3, 3]\n > OD: [0, 0]\n > Test 192 de 255\n   > Sets originales:\n     ['veinticinco', 'cuatro', 'veintidós', 'xiv', 'diez', '9', 'xxi', 'veintisiete']\n     ['89', 'dos']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['veinticinco', 'cuatro', 'veintidós', 'xiv', 'diez', '9', 'xxi', 'veintisiete'] - oov words: 0 de 8\n     ['89', 'dos'] - oov words: 0 de 2\n > OP: [4, 4]\n > OD: [0, 0]\n > Test 193 de 255\n   > Sets originales:\n     ['atlas', 'alpes', 'pirineos', 'urales', 'cárpatos', 'himalaya']\n     ['guayana']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['atlas', 'alpes', 'pirineos', 'urales', 'cárpatos', 'himalaya'] - oov words: 0 de 6\n     ['guayana'] - oov words: 0 de 1\n > OP: [4]\n > OD: [0]\n > Test 194 de 255\n   > Sets originales:\n     ['liverpool', 'juventus', 'arsenal', 'chelsea']\n     ['argentina']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['liverpool', 'juventus', 'arsenal', 'chelsea'] - oov words: 0 de 4\n     ['argentina'] - oov words: 0 de 1\n > OP: [4]\n > OD: [1]\n > Test 195 de 255\n   > Sets originales:\n     ['montpellier', 'nantes', 'burdeos', 'niza', 'estrasburgo', 'ruan', 'toulouse', 'grenoble']\n     ['somme', 'tarn']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['montpellier', 'nantes', 'burdeos', 'niza', 'estrasburgo', 'ruan', 'toulouse', 'grenoble'] - oov words: 0 de 8\n     ['somme', 'tarn'] - oov words: 0 de 2\n > OP: [3, 5]\n > OD: [0, 0]\n > Test 196 de 255\n   > Sets originales:\n     ['mcfly', 'blur']\n     ['flamenco']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['mcfly', 'blur'] - oov words: 0 de 2\n     ['flamenco'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 197 de 255\n   > Sets originales:\n     ['skype', 'whatsapp']\n     ['cortina']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['skype', 'whatsapp'] - oov words: 0 de 2\n     ['cortina'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 198 de 255\n   > Sets originales:\n     ['gante', 'mons', 'charleroi', 'bruselas', 'brujas', 'lieja', 'namur']\n     ['maputo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['gante', 'mons', 'charleroi', 'bruselas', 'brujas', 'lieja', 'namur'] - oov words: 0 de 7\n     ['maputo'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 199 de 255\n   > Sets originales:\n     ['tsu', 'yamaguchi', 'fukushima', 'kamakura']\n     ['borough']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['tsu', 'yamaguchi', 'fukushima', 'kamakura'] - oov words: 0 de 4\n     ['borough'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 200 de 255\n   > Sets originales:\n     ['anonymous', 'abolicionista']\n     ['manierista', 'simbolismo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['anonymous', 'abolicionista'] - oov words: 0 de 2\n     ['manierista', 'simbolismo'] - oov words: 0 de 2\n > OP: [1, 0]\n > OD: [0, 0]\n > Test 201 de 255\n   > Sets originales:\n     ['sirio', 'aldebarán', 'polaris']\n     ['rigel']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['sirio', 'aldebarán', 'polaris'] - oov words: 0 de 3\n     ['rigel'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 202 de 255\n   > Sets originales:\n     ['fx', 'tnt', 'espn', 'mtv', 'showtime', 'syfy']\n     ['sbs']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['fx', 'tnt', 'espn', 'mtv', 'showtime', 'syfy'] - oov words: 0 de 6\n     ['sbs'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 203 de 255\n   > Sets originales:\n     ['chachapoyas', 'abancay', 'nazca', 'huaraz']\n     ['raión']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['chachapoyas', 'abancay', 'nazca', 'huaraz'] - oov words: 0 de 4\n     ['raión'] - oov words: 0 de 1\n > OP: [4]\n > OD: [1]\n > Test 204 de 255\n   > Sets originales:\n     ['pekín', 'washington', 'parís', 'roma', 'londres', 'madrid', 'varsovia', 'jerusalén']\n     ['departamento', 'tarn', 'borough']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['pekín', 'washington', 'parís', 'roma', 'londres', 'madrid', 'varsovia', 'jerusalén'] - oov words: 0 de 8\n     ['departamento', 'tarn', 'borough'] - oov words: 0 de 3\n > OP: [2, 6, 8]\n > OD: [0, 0, 1]\n > Test 205 de 255\n   > Sets originales:\n     ['liberec', 'pardubice', 'pilsen', 'olomouc', 'ostrava', 'brno']\n     ['apure']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['liberec', 'pardubice', 'pilsen', 'olomouc', 'ostrava', 'brno'] - oov words: 0 de 6\n     ['apure'] - oov words: 0 de 1\n > OP: [6]\n > OD: [1]\n > Test 206 de 255\n   > Sets originales:\n     ['mazapán', 'churro']\n     ['sábana', 'pañuelo', 'plastilina']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['mazapán', 'churro'] - oov words: 0 de 2\n     ['sábana', 'pañuelo', 'plastilina'] - oov words: 0 de 3\n > OP: [2, 1, 2]\n > OD: [1, 0, 1]\n > Test 207 de 255\n   > Sets originales:\n     ['reforma', 'bien', 'socialista', 'revolución', 'valentía', 'felicidad', 'esperanza', 'totalitarismo']\n     ['centroderecha']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['reforma', 'bien', 'socialista', 'revolución', 'valentía', 'felicidad', 'esperanza', 'totalitarismo'] - oov words: 0 de 8\n     ['centroderecha'] - oov words: 0 de 1\n > OP: [8]\n > OD: [1]\n > Test 208 de 255\n   > Sets originales:\n     ['nature', 'science']\n     ['fanzine', 'televisión', 'fax']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['nature', 'science'] - oov words: 0 de 2\n     ['fanzine', 'televisión', 'fax'] - oov words: 0 de 3\n > OP: [1, 0, 1]\n > OD: [0, 0, 0]\n > Test 209 de 255\n   > Sets originales:\n     ['aquisgrán', 'núremberg', 'ratisbona']\n     ['departamento', 'borough']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['aquisgrán', 'núremberg', 'ratisbona'] - oov words: 0 de 3\n     ['departamento', 'borough'] - oov words: 0 de 2\n > OP: [1, 1]\n > OD: [0, 0]\n > Test 210 de 255\n   > Sets originales:\n     ['cohen', 'baronet']\n     ['landgrave', 'maharajá']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['cohen', 'baronet'] - oov words: 0 de 2\n     ['landgrave', 'maharajá'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 211 de 255\n   > Sets originales:\n     ['ateísmo', 'deontología', 'hedonismo']\n     ['aeronáutica', 'mensajero', 'magnate']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ateísmo', 'deontología', 'hedonismo'] - oov words: 0 de 3\n     ['aeronáutica', 'mensajero', 'magnate'] - oov words: 0 de 3\n > OP: [1, 0, 1]\n > OD: [0, 0, 0]\n > Test 212 de 255\n   > Sets originales:\n     ['põlva', 'tapa']\n     ['raión']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['põlva', 'tapa'] - oov words: 0 de 2\n     ['raión'] - oov words: 0 de 1\n > OP: [2]\n > OD: [1]\n > Test 213 de 255\n   > Sets originales:\n     ['movistar', 'astana']\n     ['tas']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['movistar', 'astana'] - oov words: 0 de 2\n     ['tas'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 214 de 255\n   > Sets originales:\n     ['sacramento', 'indianápolis', 'detroit', 'atlanta', 'honolulu', 'minneapolis', 'phoenix']\n     ['chiva', 'alva']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['sacramento', 'indianápolis', 'detroit', 'atlanta', 'honolulu', 'minneapolis', 'phoenix'] - oov words: 0 de 7\n     ['chiva', 'alva'] - oov words: 0 de 2\n > OP: [2, 7]\n > OD: [0, 1]\n > Test 215 de 255\n   > Sets originales:\n     ['instagram', 'siri', 'whatsapp']\n     ['bada', 'túnez']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['instagram', 'siri', 'whatsapp'] - oov words: 0 de 3\n     ['bada', 'túnez'] - oov words: 0 de 2\n > OP: [2, 1]\n > OD: [0, 0]\n > Test 216 de 255\n   > Sets originales:\n     ['safari', 'firefox', 'opera']\n     ['emacs']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['safari', 'firefox', 'opera'] - oov words: 0 de 3\n     ['emacs'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 217 de 255\n   > Sets originales:\n     ['alemania', 'japón', 'austria', 'china', 'finlandia']\n     ['jerarquía', '±']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['alemania', 'japón', 'austria', 'china', 'finlandia'] - oov words: 0 de 5\n     ['jerarquía', '±'] - oov words: 0 de 2\n > OP: [3, 2]\n > OD: [0, 0]\n > Test 218 de 255\n   > Sets originales:\n     ['hérault', 'parís', 'vendée', 'ain', 'aisne', 'gironda']\n     ['líbano']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['hérault', 'parís', 'vendée', 'ain', 'aisne', 'gironda'] - oov words: 0 de 6\n     ['líbano'] - oov words: 0 de 1\n > OP: [6]\n > OD: [1]\n > Test 219 de 255\n   > Sets originales:\n     ['magneto', 'joker']\n     ['superhéroe', 'mago', 'electro', 'bestia']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['magneto', 'joker'] - oov words: 0 de 2\n     ['superhéroe', 'mago', 'electro', 'bestia'] - oov words: 0 de 4\n > OP: [1, 0, 1, 0]\n > OD: [0, 0, 0, 0]\n > Test 220 de 255\n   > Sets originales:\n     ['ariete', 'corvus', 'escorpiones']\n     ['corbata']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ariete', 'corvus', 'escorpiones'] - oov words: 0 de 3\n     ['corbata'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 221 de 255\n   > Sets originales:\n     ['windsor', 'london', 'belleville', 'stratford', 'kingston', 'peterborough']\n     ['kitchener']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['windsor', 'london', 'belleville', 'stratford', 'kingston', 'peterborough'] - oov words: 0 de 6\n     ['kitchener'] - oov words: 0 de 1\n > OP: [3]\n > OD: [0]\n > Test 222 de 255\n   > Sets originales:\n     ['graz', 'salzburgo', 'innsbruck', 'linz', 'klagenfurt']\n     ['maputo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['graz', 'salzburgo', 'innsbruck', 'linz', 'klagenfurt'] - oov words: 0 de 5\n     ['maputo'] - oov words: 0 de 1\n > OP: [4]\n > OD: [0]\n > Test 223 de 255\n   > Sets originales:\n     ['1', 'doce', 'veintidós', 'cinco', 'setenta']\n     ['diez', '220', '20']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['1', 'doce', 'veintidós', 'cinco', 'setenta'] - oov words: 0 de 5\n     ['diez', '220', '20'] - oov words: 0 de 3\n > OP: [1, 3, 1]\n > OD: [0, 0, 0]\n > Test 224 de 255\n   > Sets originales:\n     ['brasil', 'alemania', 'inglaterra', 'argentina', 'francia', 'españa', 'italia']\n     ['letonia', 'tas']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['brasil', 'alemania', 'inglaterra', 'argentina', 'francia', 'españa', 'italia'] - oov words: 0 de 7\n     ['letonia', 'tas'] - oov words: 0 de 2\n > OP: [1, 2]\n > OD: [0, 0]\n > Test 225 de 255\n   > Sets originales:\n     ['cenicienta', 'aladino', 'blancanieves']\n     ['fantasía']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['cenicienta', 'aladino', 'blancanieves'] - oov words: 0 de 3\n     ['fantasía'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 226 de 255\n   > Sets originales:\n     ['madsen', 'bar', 'bren']\n     ['vickers']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['madsen', 'bar', 'bren'] - oov words: 0 de 3\n     ['vickers'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 227 de 255\n   > Sets originales:\n     ['alemania', 'austria', 'eslovaquia', 'colombia', 'sudán', 'albania', 'serbia']\n     ['viterbo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['alemania', 'austria', 'eslovaquia', 'colombia', 'sudán', 'albania', 'serbia'] - oov words: 0 de 7\n     ['viterbo'] - oov words: 0 de 1\n > OP: [0]\n > OD: [0]\n > Test 228 de 255\n   > Sets originales:\n     ['angus', 'fife', 'orcadas', 'glasgow', 'shetland']\n     ['milán']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['angus', 'fife', 'orcadas', 'glasgow', 'shetland'] - oov words: 0 de 5\n     ['milán'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 229 de 255\n   > Sets originales:\n     ['tipografía', 'actor', 'blasón', 'origami']\n     ['gastronomía', 'lingüística', 'marina']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['tipografía', 'actor', 'blasón', 'origami'] - oov words: 0 de 4\n     ['gastronomía', 'lingüística', 'marina'] - oov words: 0 de 3\n > OP: [0, 2, 4]\n > OD: [0, 0, 1]\n > Test 230 de 255\n   > Sets originales:\n     ['nápoles', 'milán', 'palermo', 'roma', 'turín', 'venecia', 'florencia']\n     ['woodstock', 'somme']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['nápoles', 'milán', 'palermo', 'roma', 'turín', 'venecia', 'florencia'] - oov words: 0 de 7\n     ['woodstock', 'somme'] - oov words: 0 de 2\n > OP: [5, 6]\n > OD: [0, 0]\n > Test 231 de 255\n   > Sets originales:\n     ['ruidoso', 'milan', 'tampico', 'lombard', 'wellington']\n     ['borough', 'departamento']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ruidoso', 'milan', 'tampico', 'lombard', 'wellington'] - oov words: 0 de 5\n     ['borough', 'departamento'] - oov words: 0 de 2\n > OP: [4, 4]\n > OD: [0, 0]\n > Test 232 de 255\n   > Sets originales:\n     ['suffolk', 'cumbria', 'northamptonshire', 'oxfordshire', 'berkshire', 'hertfordshire', 'surrey', 'norfolk']\n     ['tarn', 'northumberland']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['suffolk', 'cumbria', 'northamptonshire', 'oxfordshire', 'berkshire', 'hertfordshire', 'surrey', 'norfolk'] - oov words: 0 de 8\n     ['tarn', 'northumberland'] - oov words: 0 de 2\n > OP: [4, 4]\n > OD: [0, 0]\n > Test 233 de 255\n   > Sets originales:\n     ['indiana', 'gettysburg', 'carlisle']\n     ['sanford', 'rota']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['indiana', 'gettysburg', 'carlisle'] - oov words: 0 de 3\n     ['sanford', 'rota'] - oov words: 0 de 2\n > OP: [3, 0]\n > OD: [1, 0]\n > Test 234 de 255\n   > Sets originales:\n     ['wayne', 'edison', 'lakewood']\n     ['sanford', 'departamento']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['wayne', 'edison', 'lakewood'] - oov words: 0 de 3\n     ['sanford', 'departamento'] - oov words: 0 de 2\n > OP: [2, 0]\n > OD: [0, 0]\n > Test 235 de 255\n   > Sets originales:\n     ['broadway', 'whitehall']\n     ['bowery']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['broadway', 'whitehall'] - oov words: 0 de 2\n     ['bowery'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 236 de 255\n   > Sets originales:\n     ['teide', 'chimborazo', 'cotopaxi']\n     ['stack', 'bodega']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['teide', 'chimborazo', 'cotopaxi'] - oov words: 0 de 3\n     ['stack', 'bodega'] - oov words: 0 de 2\n > OP: [2, 3]\n > OD: [0, 1]\n > Test 237 de 255\n   > Sets originales:\n     ['automoción', 'minería', 'shopping', 'horticultura', 'robótica', 'manufactura']\n     ['anime', 'tormenta']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['automoción', 'minería', 'shopping', 'horticultura', 'robótica', 'manufactura'] - oov words: 0 de 6\n     ['anime', 'tormenta'] - oov words: 0 de 2\n > OP: [4, 4]\n > OD: [0, 0]\n > Test 238 de 255\n   > Sets originales:\n     ['limburgo', 'henao', 'amberes']\n     ['somme']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['limburgo', 'henao', 'amberes'] - oov words: 0 de 3\n     ['somme'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 239 de 255\n   > Sets originales:\n     ['blasfemia', 'fraude', 'secuestro', 'violencia', 'desertor', 'chantaje']\n     ['discriminación', 'dumping']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['blasfemia', 'fraude', 'secuestro', 'violencia', 'desertor', 'chantaje'] - oov words: 0 de 6\n     ['discriminación', 'dumping'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 240 de 255\n   > Sets originales:\n     ['ido', 'esperanto', 'glosa']\n     ['occidental', 'erp', 'entendimiento']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ido', 'esperanto', 'glosa'] - oov words: 0 de 3\n     ['occidental', 'erp', 'entendimiento'] - oov words: 0 de 3\n > OP: [2, 1, 0]\n > OD: [0, 0, 0]\n > Test 241 de 255\n   > Sets originales:\n     ['mexica', 'elam', 'vándalos', 'olmeca']\n     ['élite', 'civilización', 'hunos']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['mexica', 'elam', 'vándalos', 'olmeca'] - oov words: 0 de 4\n     ['élite', 'civilización', 'hunos'] - oov words: 0 de 3\n > OP: [4, 2, 3]\n > OD: [1, 0, 0]\n > Test 242 de 255\n   > Sets originales:\n     ['néguev', 'sahara', 'kalahari']\n     ['highlands']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['néguev', 'sahara', 'kalahari'] - oov words: 0 de 3\n     ['highlands'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 243 de 255\n   > Sets originales:\n     ['graz', 'salzburgo', 'innsbruck', 'linz', 'klagenfurt']\n     ['sava']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['graz', 'salzburgo', 'innsbruck', 'linz', 'klagenfurt'] - oov words: 0 de 5\n     ['sava'] - oov words: 0 de 1\n > OP: [2]\n > OD: [0]\n > Test 244 de 255\n   > Sets originales:\n     ['deutschland', 'blücher']\n     ['ballenero', 'uss']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['deutschland', 'blücher'] - oov words: 0 de 2\n     ['ballenero', 'uss'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 245 de 255\n   > Sets originales:\n     ['java', 'lua', 'python', 'ruby', 'dart']\n     ['css', 'sql']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['java', 'lua', 'python', 'ruby', 'dart'] - oov words: 0 de 5\n     ['css', 'sql'] - oov words: 0 de 2\n > OP: [1, 2]\n > OD: [0, 0]\n > Test 246 de 255\n   > Sets originales:\n     ['c', 'java', 'javascript', 'python', 'perl', 'pascal', 'sql']\n     ['rss', 'jpeg']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['c', 'java', 'javascript', 'python', 'perl', 'pascal', 'sql'] - oov words: 0 de 7\n     ['rss', 'jpeg'] - oov words: 0 de 2\n",
      " > OP: [2, 3]\n > OD: [0, 0]\n > Test 247 de 255\n   > Sets originales:\n     ['encarnación', 'luque', 'asunción', 'pilar', 'concepción']\n     ['i']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['encarnación', 'luque', 'asunción', 'pilar', 'concepción'] - oov words: 0 de 5\n     ['i'] - oov words: 0 de 1\n > OP: [4]\n > OD: [0]\n > Test 248 de 255\n   > Sets originales:\n     ['judaísmo', 'cristianismo', 'hinduismo', 'protestante', 'islam', 'sijismo']\n     ['hunos']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['judaísmo', 'cristianismo', 'hinduismo', 'protestante', 'islam', 'sijismo'] - oov words: 0 de 6\n     ['hunos'] - oov words: 0 de 1\n > OP: [4]\n > OD: [0]\n > Test 249 de 255\n   > Sets originales:\n     ['bada', 'ios', 'android']\n     ['instagram', 'túnez', 'comentario']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['bada', 'ios', 'android'] - oov words: 0 de 3\n     ['instagram', 'túnez', 'comentario'] - oov words: 0 de 3\n > OP: [0, 0, 2]\n > OD: [0, 0, 0]\n > Test 250 de 255\n   > Sets originales:\n     ['ceuta', 'melilla']\n     ['malaui', 'níger', 'país']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['ceuta', 'melilla'] - oov words: 0 de 2\n     ['malaui', 'níger', 'país'] - oov words: 0 de 3\n > OP: [2, 2, 2]\n > OD: [1, 1, 1]\n > Test 251 de 255\n   > Sets originales:\n     ['osona', 'barcelonés']\n     ['i']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['osona', 'barcelonés'] - oov words: 0 de 2\n     ['i'] - oov words: 0 de 1\n > OP: [1]\n > OD: [0]\n > Test 252 de 255\n   > Sets originales:\n     ['hamilton', 'christchurch', 'dunedin']\n     ['sirte', 'viterbo']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['hamilton', 'christchurch', 'dunedin'] - oov words: 0 de 3\n     ['sirte', 'viterbo'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 253 de 255\n   > Sets originales:\n     ['miedo', 'amor', 'envidia', 'ira', 'felicidad', 'odio', 'tristeza', 'esperanza']\n     ['adicción', 'revolución']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['miedo', 'amor', 'envidia', 'ira', 'felicidad', 'odio', 'tristeza', 'esperanza'] - oov words: 0 de 8\n     ['adicción', 'revolución'] - oov words: 0 de 2\n > OP: [2, 0]\n > OD: [0, 0]\n > Test 254 de 255\n   > Sets originales:\n     ['cuñada', 'cuñado', 'nuera', 'suegro', 'yerno', 'suegra']\n     ['abuelo', 'abuela']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['cuñada', 'cuñado', 'nuera', 'suegro', 'yerno', 'suegra'] - oov words: 0 de 6\n     ['abuelo', 'abuela'] - oov words: 0 de 2\n > OP: [0, 0]\n > OD: [0, 0]\n > Test 255 de 255\n   > Sets originales:\n     ['hobbit', 'elfos', 'enanos', 'balrog', 'valar', 'maia', 'ents']\n     ['predator', 'quirón']\n>>> Eliminando terminos de mas de una palabra\n > Sets editados:\n     ['hobbit', 'elfos', 'enanos', 'balrog', 'valar', 'maia', 'ents'] - oov words: 0 de 7\n     ['predator', 'quirón'] - oov words: 0 de 2\n > OP: [4, 2]\n > OD: [0, 0]\n>>> Resultados\n['accuraccy', 0.49253492719401804]\n['OPP', 0.19008264462809918]\n['%_main_oov', 0.0]\n['%_outlier_oov', 0.0]\n['omited sets', 0]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_out = OutlierDetectionTest.OutlierDetectionTestClass(use_intersect_dataset=True)\n",
    "test_out.intersectDataset(emb)\n",
    "res = test_out.evaluateWordVector(\"_rand_embedding\", emb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Test de Analogias\nIntersectando datasets...\n > Revisando si existe interseccion previa\n   >  4tupla_google_analogy_AG01 [capital-pais].txt  ya ha sido intersectado anteriormente\n   >  4tupla_google_analogy_AG02 [capital2-pais2].txt  ya ha sido intersectado anteriormente\n   >  4tupla_google_analogy_AG03 [pais-moneda].txt  ya ha sido intersectado anteriormente\n   >  4tupla_google_analogy_AG04 [ciudad-estado EEUU].txt  ya ha sido intersectado anteriormente\n   >  4tupla_google_analogy_AG05 [familia].txt  ya ha sido intersectado anteriormente\n   >  4tupla_google_analogy_AG06 [adj-adv].txt  ya ha sido intersectado anteriormente\n   >  4tupla_google_analogy_AG07 [opuestos].txt  ya ha sido intersectado anteriormente\n   >  4tupla_google_analogy_AG08 [presente-participio].txt  ya ha sido intersectado anteriormente\n   >  4tupla_google_analogy_AG09 [nacionalidad].txt  ya ha sido intersectado anteriormente\n   >  4tupla_google_analogy_AG10 [past-tense].txt  ya ha sido intersectado anteriormente\n   >  4tupla_google_analogy_AG11 [plural].txt  ya ha sido intersectado anteriormente\n   >  4tupla_google_analogy_AG12 [verbos plural].txt  ya ha sido intersectado anteriormente\n   >  _español_D01 [prefijo_anti-].txt  ya ha sido intersectado anteriormente\n   >  _español_D02 [prefijo_des-].txt  ya ha sido intersectado anteriormente\n   >  _español_D03 [prefijo_in-].txt  ya ha sido intersectado anteriormente\n   >  _español_D04 [sufijo_-able].txt  ya ha sido intersectado anteriormente\n   >  _español_D05 [sufijo_-ción].txt  ya ha sido intersectado anteriormente\n   >  _español_D06 [sufijo_-ísimo].txt  ya ha sido intersectado anteriormente\n   >  _español_D07 [sufijo_-ito].txt  ya ha sido intersectado anteriormente\n   >  _español_D08 [sufijo_-mente].txt  ya ha sido intersectado anteriormente\n   >  _español_D09 [sufijo_-miento].txt  ya ha sido intersectado anteriormente\n   >  _español_D10 [pais - gentilicio].txt  ya ha sido intersectado anteriormente\n   >  _español_E01 [pais - capital].txt  ya ha sido intersectado anteriormente\n   >  _español_E02 [pais - idioma].txt  ya ha sido intersectado anteriormente\n   >  _español_E03 [nombre - nacionalidad].txt  ya ha sido intersectado anteriormente\n   >  _español_E04 [nombre - ocupacion].txt  ya ha sido intersectado anteriormente\n   >  _español_E05 [hombre - mujer].txt  ya ha sido intersectado anteriormente\n   >  _español_E06 [ciudad_Chile - provincia_Chile].txt  ya ha sido intersectado anteriormente\n   >  _español_E07 [ciudad_EEUU - estado_EEUU].txt  ya ha sido intersectado anteriormente\n   >  _español_I01 [gerund - parti].txt  ya ha sido intersectado anteriormente\n   >  _español_I02 [inf - gerund].txt  ya ha sido intersectado anteriormente\n   >  _español_I03 [inf - parti].txt  ya ha sido intersectado anteriormente\n   >  _español_I04 [pret_perf__1_sing - futuro_simp__1_sing].txt  ya ha sido intersectado anteriormente\n   >  _español_I05 [presente__1_sing - futuro_simp__1_sing].txt  ya ha sido intersectado anteriormente\n   >  _español_I06 [presente__1_sing - pret_perf__1_sing].txt  ya ha sido intersectado anteriormente\n   >  _español_I07 [presente__1_sing - presente__1_plur].txt  ya ha sido intersectado anteriormente\n   >  _español_I08 [presente__1_sing - presente__3_sing].txt  ya ha sido intersectado anteriormente\n   >  _español_I09 [sustantivo - plural(s)].txt  ya ha sido intersectado anteriormente\n   >  _español_I10 [sustantivo - plural(es)].txt  ya ha sido intersectado anteriormente\n   >  _español_L01 [sinonimos - intensidad].txt  ya ha sido intersectado anteriormente\n   >  _español_L02 [antonimos - grado].txt  ya ha sido intersectado anteriormente\nIntersectando datasets...\n > Revision de archivos en dataset\n > Revisando 4tupla_google_analogy_AG01 [capital-pais].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 420\n > Revisando 4tupla_google_analogy_AG02 [capital2-pais2].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 4369\n > Revisando 4tupla_google_analogy_AG03 [pais-moneda].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 752\n > Revisando 4tupla_google_analogy_AG04 [ciudad-estado EEUU].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 2182\n > Revisando 4tupla_google_analogy_AG05 [familia].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 380\n > Revisando 4tupla_google_analogy_AG06 [adj-adv].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 552",
      "\n > Revisando 4tupla_google_analogy_AG07 [opuestos].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 380",
      "\n > Revisando 4tupla_google_analogy_AG08 [presente-participio].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 930\n > Revisando 4tupla_google_analogy_AG09 [nacionalidad].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 1521\n > Revisando 4tupla_google_analogy_AG10 [past-tense].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 1190\n > Revisando 4tupla_google_analogy_AG11 [plural].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 1332\n > Revisando 4tupla_google_analogy_AG12 [verbos plural].txt\n   Revisando archivo de tipo 4-tupla\n > Lineas eliminadas: 0 de 756\n > Revisando _español_D01 [prefijo_anti-].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_D02 [prefijo_des-].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_D03 [prefijo_in-].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_D04 [sufijo_-able].txt\n > Lineas eliminadas: 0 de 40\n > Revisando _español_D05 [sufijo_-ción].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_D06 [sufijo_-ísimo].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_D07 [sufijo_-ito].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_D08 [sufijo_-mente].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_D09 [sufijo_-miento].txt\n > Lineas eliminadas: 0 de 50",
      "\n > Revisando _español_D10 [pais - gentilicio].txt\n > Lineas eliminadas: 0 de 49\n > Revisando _español_E01 [pais - capital].txt\n > Lineas eliminadas: 0 de 50",
      "\n > Revisando _español_E02 [pais - idioma].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_E03 [nombre - nacionalidad].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_E04 [nombre - ocupacion].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_E05 [hombre - mujer].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_E06 [ciudad_Chile - provincia_Chile].txt\n > Lineas eliminadas: 0 de 17\n > Revisando _español_E07 [ciudad_EEUU - estado_EEUU].txt\n > Lineas eliminadas: 0 de 46\n > Revisando _español_I01 [gerund - parti].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_I02 [inf - gerund].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_I03 [inf - parti].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_I04 [pret_perf__1_sing - futuro_simp__1_sing].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_I05 [presente__1_sing - futuro_simp__1_sing].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_I06 [presente__1_sing - pret_perf__1_sing].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_I07 [presente__1_sing - presente__1_plur].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_I08 [presente__1_sing - presente__3_sing].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_I09 [sustantivo - plural(s)].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_I10 [sustantivo - plural(es)].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_L01 [sinonimos - intensidad].txt\n > Lineas eliminadas: 0 de 50\n > Revisando _español_L02 [antonimos - grado].txt\n > Lineas eliminadas: 0 de 50",
      "\n > Archivos a eliminar: 0\n>>> Buscando archivos sin testear\n>>> Test files encontrados\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG01 [capital-pais].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG02 [capital2-pais2].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG03 [pais-moneda].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG04 [ciudad-estado EEUU].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG05 [familia].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG06 [adj-adv].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG07 [opuestos].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG08 [presente-participio].txt\n    > Ya existe un resultados con este test\n   ",
      " D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG09 [nacionalidad].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG10 [past-tense].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG11 [plural].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\4tupla_google_analogy_AG12 [verbos plural].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_D01 [prefijo_anti-].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_D02 [prefijo_des-].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_D03 [prefijo_in-].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_D04 [sufijo_-able].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_D05 [sufijo_-ción].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_D06 [sufijo_-ísimo].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_D07 [sufijo_-ito].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_D08 [sufijo_-mente].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_D09 [sufijo_-miento].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_D10 [pais - gentilicio].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_E01 [pais - capital].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_E02 [pais - idioma].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_E03 [nombre - nacionalidad].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_E04 [nombre - ocupacion].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_E05 [hombre - mujer].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_E06 [ciudad_Chile - provincia_Chile].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_E07 [ciudad_EEUU - estado_EEUU].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_I01 [gerund - parti].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_I02 [inf - gerund].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_I03 [inf - parti].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_I04 [pret_perf__1_sing - futuro_simp__1_sing].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_I05 [presente__1_sing - futuro_simp__1_sing].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_I06 [presente__1_sing - pret_perf__1_sing].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_I07 [presente__1_sing - presente__1_plur].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_I08 [presente__1_sing - presente__3_sing].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_I09 [sustantivo - plural(s)].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_I10 [sustantivo - plural(es)].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_L01 [sinonimos - intensidad].txt\n    > Ya existe un resultados con este test\n    D:\\Documents\\Memoria - Evaluacion de Word Embeddings\\Memoria\\Datasets\\_intersection_AnalogyDataset\\_español_L02 [antonimos - grado].txt\n    > Ya existe un resultados con este test\nUntested files:\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_analogy = AnalogyTest.AnalogyTestClass(use_intersect_dataset=True)\n",
    "test_analogy.intersectDataset(emb)\n",
    "res = test_analogy.evaluateWordVector(\"_rand_embedding\", emb)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}