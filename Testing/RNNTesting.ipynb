{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Manejo de dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "total: 205357\n",
      "\ngob_concept 183342\ntopic: 1 len: 49155\n['', 'justicia', 'la justicia no solo relacionada con el derecho penal sino relacionada con la justicia social para todos y todas mayores niveles de igualdad ', 'fact']\n['', 'democracia', 'pilar esencial para el diálogo no hay encuentro sin democracia bajo la definición de gobierno del pueblo se subsumen los principios y derechos tales como justicia e igualdad ante la ley separación de poderes derechos humanos libertad entre otros ', 'value']\n['', 'respeto conservación de la naturaleza o medio ambiente', 'todos de acuerdo', 'blank']\n['', 'democracia', 'derecho a una opinión libre y a votar ', 'fact']\n['', 'autonomía libertad', 'se debe asegurar la autodeterminación y el desarrollo individual como a su vez las decisiones populares como un valor que no debe perjudicar a otros ni al entorno la libertad es la capacidad para formar algo diferente del pueblo para generar su autonomía sin afectar a terceros ', 'policy']\ntopic: 2 len: 46887\n['', 'igualdad ante la ley', 'es la forma de resguardar el derecho de cualquiera de los habitantes del pais', 'fact']\n['', 'proteccion judicial de los derechos', ' ', 'undefined']\n['', 'libertad de expresión', 'derecho a expresión conciencia organizarse reunirse y participar sindicalizarse sin ser discriminado por ello y con foco en el bién común', 'policy']\n['', 'a la seguridad social', 'resolver integralmente respecto de la protección en la totalidad de los derechos sociales ', 'policy']\n['', 'a la vivienda digna', 'por vivienda digna se debe entender una de un metraje adecuado para la recreación la intimidad el descanso también debe garantizarse un entorno seguro y conectado a servicios y comercio ', 'policy']\ntopic: 3 len: 44162\n['', 'respeto por la constitución', 'un deber que no se puede dejar de lado según nuestro punto de vista es el respeto por la constitución por que esta tiene las normas derechos y la organización del pais', 'policy']\n['', 'servicio a la comunidad', 'debería existir organizaciones de voluntariado más importantes es necesario ponerse en el lugar del otro', 'policy']\n['', 'de protección y conservación de patrimonio histórico y cultural', 'los órganos del estado y las personas asumen deberes de cuidado del patrimonio común ', 'policy']\n['', 'servicio a la comunidad', 'existencia de lo colectivo y no de lo individual para asegurar derechos y deberes para todos sin una visión asistencial si no de justicia y solidaridad ', 'policy']\n['', 'responsabilidad', 'debemos ser responsables con nosotros mismos y los demás con el medio ambiente y ser responsables con el cumplimientos de las leyes ', 'policy']\ntopic: 4 len: 43138\n['', 'defensor del pueblo ciudadano', 'debe ser una institución autónoma e independiente que se encargue de garantizar los derechos de los ciudadanos ante los abusos que puedan cometer los poderes políticos y administrativos y debe supervisar el pleno cumplimiento de los derechos humanos y fundamentales ', 'policy']\n['', 'cambio o reforma constitucional', 'garantizar cambios constitucionales cuando sea necesario ', 'fact']\n['', 'plebiscitos referendos y consultas', 'porque es necesario conocer periodicamente como las políticas afectan a la comunidad y cuales son sus necesidades específicas se propone hacerlo a través de una obligación de los municipios los que deben reportar a nivel central', 'policy']\n['', 'contraloría general tribunales de cuentas', 'para tener un control de las cuentas de los gobiernos por la transparencia y mantener la probidad en ellos ', 'value']\n['', 'plebiscitos referendos y consultas', ' ', 'blank']\n\nopen_concept 22015\ntopic: 1\nlen: 4625\n['la familia', 'familia', 'la familia es el núcleo oficial y fundamental de la sociedad y el estado debe resguardar su autonomía así como la de las demás formas de asociación de las personas siempre que estas sean entre un hombre y una mujer el estado debe reconocer y apoyar el esfuerzo de las familias en la crianza y educación de los hijos nuestros hijos son el futuro del país y el desarrollo poblacional es importante para sustentar el chile del futuro se debe dejar establecido que el rol de los padres lo define tanto el hombre en su función de padre como la mujer en su papel de madre esto se valida en el tratado internacional de ddhh en su artículo 17 incisos 1 y 2 la adopción es el derecho del ni o a tener una familia conforme a la definición en el punto de los valores ', 'policy']\n['equidad', 'equidad', 'es distinto a la igualdad la equidad tiene que ver con colocar los pelda os necesarios a quien no los tiene para formar un tipo de piso de justicia social ', 'fact']\n['interculturalidad', 'multiculturalidad', 'convivencia en armonía respetando la diversidad y la identidad cultural de todos los pueblos que viven en chile sin absorción de culturas hegemónicas ', 'policy']\n['honradez', 'probidad', 'en una sociedad sumamente individualista hay que pensar en el resto de la sociedad actualmente todos tratan de sacar sus beneficios personales y no pensamos en el resto de la sociedad ', 'policy']\n['bien común comunidad solidaria', 'bien común comunidad', 'asegurar el principio de bien común relevando el sentido de comunidad del pensar en y con el colectivo amparados bajo el concepto de solidaridad entendiéndola como que todas las personas deben colaborar en la medida de sus capacidades para asegurar el bienestar general de la sociedad ', 'policy']\ntopic: 2\nlen: 6173\n['null', 'a sindicalizarse y a la negociación colectiva', ' ', 'blank']\n['null', 'libertad de culto', 'para resguardar los intereses patrimoniales de la iglesia evangélica su idiosincrasia y además el bienestar pastoral ', 'value']\n['voto obligatorio', 'otro', 'la nueva constitución debe incluir la obligatoriedad del voto pues es un deber ', 'policy']\n['derecho a la igualdad y no discriminación', 'igualdad', 'se propone también juntar los dos derechos derecho a la igualdad y no discriminación que incluiría los votados igualdad de género e igualdad ante los tributos y demás vertientes de la igualdad se considera fundamental además consagrar expresamente la no discriminación ', 'policy']\n['igualdad de genero y diversidad sexual', 'igualdad de género', 'derecho fundamental para la sociedad ', 'fact']\ntopic: 3\nlen: 4596\n['deber de pagar los impuestos', 'cumplimiento de obligaciones fiscales', 'es la base para asegurar derechos básicos como educación salud y protección social para todos', 'fact']\n['respeto a las leyes y normas', 'cumplimiento de las leyes y normas', 'que las leyes sean adecuadas a los tiempos y que se respeten ', 'policy']\n['sufragio', 'de voto o sufragio', 'se considera deber dentro de una cultura civica porque todos debemos plasmar nuestra opinion por alguien para una eleccion', 'policy']\n['responsabilidad social', 'responsabilidad', 'responsabilizarnos del entorno social que nos convoca y promover la integración ', 'policy']\n['cultura cívica', 'de responsabilidad social y cívica', 'se debe incluir en el curriculum escolar desde la educación básica para todos los ciudadanos ', 'policy']\ntopic: 4\nlen: 6621\n['democratizacion de las ffaa', 'fuerzas armadas', 'unanimidad 14 acuerdos escalafon unico asencion meritoria fin de la doctrina de seguridad interior del estado y enemigo interno y no envio a escuela de las americas preeminencia del parlamento y la ley sobre las ordenes superiores fin a la institucion de los capellanes estado laico ', 'policy']\n['gobiernos locales', 'gobierno local municipal', 'autonimía transparencia elección popular', 'policy']\n['corfo', 'gobierno nacional estructura y funciones ', 'promoción de emprendimientos privados con carácter estatal y nacional ', 'policy']\n['democracia participativa', 'plebiscitos referendos y consultas', 'instauración de plebiscitos consultas iniciativa popular de ley mandato revocatorio todos vinculantes ', 'policy']\n['estado de derechos', 'otro', 'un estado democrático que garantice el derecho y el cumplimiento de estos mismos para todos los ciudadanos de vivir en una sociedad armónica ', 'policy']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Extraer dataset\n",
    "import ConstitucionUtil\n",
    "import re\n",
    "import random\n",
    "\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dependiendo del task con el que evaluamos, cambiara como se entrena la red.\n",
    "\n",
    "Task A: \n",
    " - Separamos el dataset segun topico, y entrenamos distintas redes para cada topico.\n",
    " - El dataset se separa en 80% train, 10% dev y 10% test.\n",
    " - Eliminamos argumentos que no se relacionen a algun concepto.\n",
    " \n",
    "Task B:\n",
    " - Utilizamos modelo entrenado en A\n",
    " - Input es el concepto propuesto y concepto propuesto + argumento\n",
    " \n",
    "Task C:\n",
    " - Eliminamos argumentos que no se clasifiquen en los modos de argumentacion propuestos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">>> Embeddings a evaluar:\n  > _fasttext_sbwc.vec\n  > _fasttext_suc.vec\n  > _fasttext_wiki.vec\n  > _glove_sbwc.vec\n  > _w2v_sbwc.txt\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Extraer embedding\n",
    "\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import Constant\n",
    "import GlobalTest\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import LongTensor\n",
    "from torch.nn import Embedding, LSTM\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from ConstitucionUtil import ClassifierModel\n",
    "\n",
    "\n",
    "# Path a carpeta principal\n",
    "MAIN_FOLDER = Constant.MAIN_FOLDER\n",
    "\n",
    "# Path a carpeta con los embeddings\n",
    "EMBEDDING_FOLDER = Constant.EMBEDDING_FOLDER\n",
    "\n",
    "# Lista con los nombres de los archivos de los embeddings\n",
    "embedding_name_list = os.listdir(EMBEDDING_FOLDER)\n",
    "\n",
    "print(\">>> Embeddings a evaluar:\")\n",
    "for embedding in embedding_name_list:\n",
    "    print(\"  > \" + embedding)\n",
    "\n",
    "def get_wordvector(file, cant=None):\n",
    "    print(\"Cargando embedding \" + file)\n",
    "    wordvector_file = EMBEDDING_FOLDER / file\n",
    "    word_vector = KeyedVectors.load_word2vec_format(wordvector_file, limit=cant)\n",
    "    print(\"Carga lista\")\n",
    "    return word_vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Crear RNN\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Cargar datasets\n",
    "\n",
    "def accuracy(prediction, concept):\n",
    "    #print(prediction.size())\n",
    "    predict_idx = torch.argmax(prediction, dim=1)\n",
    "    #print(predict_idx.size())\n",
    "    #print(concept.size())\n",
    "    \n",
    "    sum = 0\n",
    "    for i in range(len(concept)):\n",
    "        #print(concept[i])\n",
    "        #print(predict_idx[i])\n",
    "        if concept[i] == predict_idx[i]:\n",
    "            sum += 1\n",
    "            \n",
    "    return sum\n",
    "\n",
    "def line2vecs(word_vector, arguments):\n",
    "    #print(\" > line2vecs\")\n",
    "    tensor = torch.zeros([len(arguments), len(arguments[0])], dtype=torch.long)\n",
    "    \n",
    "    for j in range(len(arguments)):\n",
    "        arg = arguments[j]\n",
    "        for i in range(len(arg)):\n",
    "            word = arg[i]\n",
    "            if word not in word_vector and word != \"<pad>\":\n",
    "                print(\" word not found: \" + word)\n",
    "                word_vector.add(word, np.random.rand(word_vector.vector_size))\n",
    "                \n",
    "            if word == \"<pad>\":\n",
    "                tensor[j][i] = 0\n",
    "            else:\n",
    "                #t = torch.zeros(1, len(word_vector.vocab))\n",
    "                #t[0][word_vector.vocab[word].index] = 1\n",
    "                tensor[j][i] = word_vector.vocab[word].index + 1\n",
    "            \n",
    "    return tensor\n",
    "\n",
    "\n",
    "def getTrainExample(arguments, concepts, concepts_list, word_vector):\n",
    "    #print(\" > get train example\")\n",
    "    # TODO: cambiar por creacion de batch\n",
    "    argument_vectors = line2vecs(word_vector, arguments)\n",
    "    concept_vector = torch.tensor([torch.tensor([concepts_list.index(concept)], dtype=torch.long) for concept in concepts])\n",
    "    \n",
    "    return argument_vectors, concept_vector\n",
    "\n",
    "\n",
    "def categoryFromOutput(output, concepts):\n",
    "    name = []\n",
    "    id = []\n",
    "    for i in range(len(output)):\n",
    "        top_n, top_i = output[i].topk(1)\n",
    "        category_i = top_i[0].item()\n",
    "        name.append(concepts[category_i])\n",
    "        id.append(category_i)\n",
    "        \n",
    "    return name, id\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "\n",
    "def ltmsTrain(concept_tensor, argument_tensor, lstm):\n",
    "    learning_rate = 0.005\n",
    "    \n",
    "    lstm.zero_grad()\n",
    "\n",
    "    output, hidden = lstm(argument_tensor)\n",
    "    #print(\" > lstm output \", end='')\n",
    "    #print(output.size())\n",
    "    #print(\" > lstm output[-1] \", end='')\n",
    "    #print(output[-1].size())\n",
    "    #print(\" > concept_tensor \", end='')\n",
    "    #print(concept_tensor.size())\n",
    "\n",
    "    loss = criterion(output[-1], concept_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in lstm.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output[-1], loss.item()\n",
    "\n",
    "\n",
    "def train(concept_tensor, argument_tensor, rnn):\n",
    "    learning_rate = 0.005\n",
    "    \n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(argument_tensor.size()[0]):\n",
    "        output, hidden = rnn(argument_tensor[i], hidden)\n",
    "        \n",
    "    print(output.size())\n",
    "    print(output[-1].size())\n",
    "    print(concept_tensor.size())\n",
    "\n",
    "    loss = criterion(output[-1], concept_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output[-1], loss.item()\n",
    "\n",
    "\n",
    "def predict(concept_tensor, argument_tensor, rnn):\n",
    "    for i in range(argument_tensor.size()[0]):\n",
    "        output, hidden = rnn(argument_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, concept_tensor)\n",
    "    return output, loss.item()\n",
    "\n",
    "\n",
    "def padding(batch):\n",
    "    pad = \"<pad>\"\n",
    "    args = [x[0] for x in batch]\n",
    "    cons = [x[1] for x in batch]\n",
    "    \n",
    "    seq_lengths = list(map(len, args))\n",
    "    max_lengths = max(seq_lengths)\n",
    "    for i in range(len(args)):\n",
    "        args[i] = (args[i] + [pad for i in range(max_lengths - len(args[i]))]) if len(args[i]) < max_lengths else args[i]\n",
    "        \n",
    "    return [args, seq_lengths, cons]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def generateBatch(data, batch_size):\n",
    "    shuffle(data)\n",
    "    batches = []\n",
    "    aux_batch = []\n",
    "    for pair in data:\n",
    "        argument = pair[0]\n",
    "        concept = pair[1]\n",
    "        \n",
    "        if argument == []:\n",
    "            continue\n",
    "            \n",
    "        aux_batch.append([argument, concept])\n",
    "        if len(aux_batch) == batch_size:\n",
    "            batches.append(aux_batch)\n",
    "            aux_batch = []\n",
    "            \n",
    "    if len(aux_batch) != 0:\n",
    "        batches.append(aux_batch)\n",
    "    \n",
    "    for i in range(len(batches)):\n",
    "        args, len_seq, cons = padding(batches[i])\n",
    "        batches[i] = [args, len_seq, cons]\n",
    "            \n",
    "    return batches\n",
    "\n",
    "\n",
    "def getEmbedding(word_vector):\n",
    "    vocab = []\n",
    "    for i in range(len(word_vector.index2word)):\n",
    "        word = word_vector.index2word[i]\n",
    "        vocab.append(word_vector[word])\n",
    "    \n",
    "    vocab = torch.tensor(vocab)\n",
    "    emb = nn.Embedding.from_pretrained(vocab)\n",
    "    \n",
    "    return emb\n",
    "\n",
    "\n",
    "def cleanDataVocab(data, word_vector, replace_oov=False):\n",
    "    revised_data = {}\n",
    "    \n",
    "    for key in data.keys():\n",
    "        revised_data[key] = []\n",
    "        new_pair = []\n",
    "        \n",
    "        for pair in data[key]:\n",
    "            for i in range(len(pair)-1):\n",
    "                try:\n",
    "                    l = pair[i].strip().split()\n",
    "                    r = []\n",
    "                except:\n",
    "                    print(pair)\n",
    "                    raise Exception\n",
    "                \n",
    "                for word in l:\n",
    "                    if word not in word_vector:\n",
    "                        if replace_oov:\n",
    "                            word_vector.add(word, np.random.rand(word_vector.vector_size))\n",
    "                        else:\n",
    "                            continue\n",
    "                    \n",
    "                    r.append(word)\n",
    "                    \n",
    "                if len(r) == 0:\n",
    "                    new_pair = []\n",
    "                    break\n",
    "                    \n",
    "                new_pair.append(r)\n",
    "                \n",
    "            if len(new_pair) == 0:\n",
    "                continue\n",
    "                \n",
    "            new_pair.append(pair[-1])\n",
    "            revised_data[key].append(new_pair)\n",
    "            \n",
    "            new_pair = []\n",
    "        print(key + \" \" + str(len(revised_data[key])))\n",
    "            \n",
    "    return revised_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "train_task_A\n1 37508\n2 36346\n3 33173\n4 32780\ndev_task_A\n1 4690\n2 4541\n3 4145\n4 4097\ntest_task_A\n1 4705\n2 4565\n3 4154\n4 4107\ndata_taskB",
      "\n1 1964\n2 3356\n3 1820\n4 3084\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import io\n",
    "from random import shuffle\n",
    "\n",
    "# Get datasets from files\n",
    "\n",
    "_DATASET = Constant.DATA_FOLDER / \"_Constitucion\"\n",
    "\n",
    "train_task_A = {}\n",
    "dev_task_A = {}\n",
    "test_task_A = {}\n",
    "data_taskB = {}\n",
    "\n",
    "with io.open(_DATASET / \"task_A_train.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        tupla = line.strip().split('/')\n",
    "        topic = tupla[0]\n",
    "        gob_concept = tupla[1]\n",
    "        argument = tupla[2]\n",
    "        \n",
    "        if topic not in train_task_A:\n",
    "            train_task_A[topic] = []\n",
    "            \n",
    "        train_task_A[topic].append([argument, gob_concept])\n",
    "            \n",
    "print(\"train_task_A\")\n",
    "for topic in train_task_A.keys():\n",
    "    print(topic + \" \" + str(len(train_task_A[topic])))\n",
    "            \n",
    "            \n",
    "with io.open(_DATASET / \"task_A_dev.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        tupla = line.strip().split('/')\n",
    "        topic = tupla[0]\n",
    "        gob_concept = tupla[1]\n",
    "        argument = tupla[2]\n",
    "        \n",
    "        if topic not in dev_task_A:\n",
    "            dev_task_A[topic] = []\n",
    "            \n",
    "        dev_task_A[topic].append([argument, gob_concept])\n",
    "            \n",
    "print(\"dev_task_A\")\n",
    "for topic in dev_task_A.keys():\n",
    "    print(topic + \" \" + str(len(dev_task_A[topic])))\n",
    "    \n",
    "            \n",
    "with io.open(_DATASET / \"task_A_test.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        tupla = line.strip().split('/')\n",
    "        topic = tupla[0]\n",
    "        gob_concept = tupla[1]\n",
    "        argument = tupla[2]\n",
    "        \n",
    "        if topic not in test_task_A:\n",
    "            test_task_A[topic] = []\n",
    "            \n",
    "        test_task_A[topic].append([argument, gob_concept])\n",
    "            \n",
    "print(\"test_task_A\")\n",
    "for topic in test_task_A.keys():\n",
    "    print(topic + \" \" + str(len(test_task_A[topic])))\n",
    "    \n",
    "            \n",
    "with io.open(_DATASET / \"task_B_dataset.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        tupla = line.strip().split('/')\n",
    "        topic = tupla[0]\n",
    "        gob_concept = tupla[1]\n",
    "        open_concept = tupla[2]\n",
    "        argument = tupla[3]\n",
    "        \n",
    "        if topic not in data_taskB:\n",
    "            data_taskB[topic] = []\n",
    "            \n",
    "        data_taskB[topic].append([argument, open_concept, gob_concept])\n",
    "            \n",
    "print(\"data_taskB\")\n",
    "for topic in data_taskB.keys():\n",
    "    print(topic + \" \" + str(len(data_taskB[topic])))\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Test de embedding _fasttext_sbwc.vec\nCargando embedding _fasttext_sbwc.vec\n",
      "Carga lista\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Entrenar RNN\n",
    "#for embedding_name in embedding_name_list:\n",
    "embedding_name = embedding_name_list[0]\n",
    "print(\"Test de embedding \" + embedding_name)\n",
    "\n",
    "word_vector = get_wordvector(embedding_name, cant=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "10.2\nTrue\n0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1 37442\n",
      "2 36156\n",
      "3 33002\n",
      "4 32615\n1 4684\n2 4520\n3 4125\n4 4067\n1 4700\n",
      "2 4535\n3 4131\n4 4084\n1 37442 37508\n > [['la', 'justicia', 'no', 'solo', 'relacionada', 'con', 'el', 'derecho', 'penal', 'sino', 'relacionada', 'con', 'la', 'justicia', 'social', 'para', 'todos', 'y', 'todas', 'mayores', 'niveles', 'de', 'igualdad'], 'justicia']\n > [['todo', 'el', 'funcionamiento', 'del', 'país', 'sus', 'actividades', 'en', 'general', 'deben', 'estar', 'de', 'justicia'], 'justicia']\n > [['que', 'exista', 'igualdad', 'ante', 'todo'], 'justicia']\n > [['justicia', 'no', 'solo', 'en', 'el', 'ámbito', 'jurídico', 'sino', 'a', 'la', 'que', 'a', 'la', 'sociedad', 'lo', 'laboral', 'y', 'oportunidades', 'no', 'más', 'distinción', 'de', 'ningún', 'tipo'], 'justicia']\n > [['el', 'acceso', 'a', 'una', 'igualdad', 'ante', 'la', 'ley', 'debe', 'ser', 'asegurado', 'y', 'con', 'equidad', 'los', 'delitos', 'contra', 'las', 'personas', 'o', 'llamados', 'de', 'cuello', 'y', 'deben', 'tener', 'sanciones'], 'justicia']\n2 36156 36346\n > [['es', 'la', 'forma', 'de', 'el', 'derecho', 'de', 'cualquiera', 'de', 'los', 'habitantes', 'del'], 'igualdad ante la ley']\n > [['fundamentos', 'en', 'acta', 'adjunta'], 'igualdad ante la ley']\n > [['actualmente', 'hay', 'un', 'sentimiento', 'de', 'frente', 'a', 'este', 'derecho', 'ya', 'que', 'hay', 'una', 'desigualdad', 'al', 'acceso', 'a', 'un', 'sistema', 'de', 'ley', 'justo'], 'igualdad ante la ley']\n > [['sabemos', 'que', 'es', 'un', 'derecho', 'que', 'no', 'se', 'cumple', 'lo', 'diariamente', 'debemos', 'respetar', 'y', 'exigir', 'que', 'así', 'sea'], 'igualdad ante la ley']\n > [['la', 'igualdad', 'debe', 'ser', 'un', 'principio', 'jurídico', 'fundamental'], 'igualdad ante la ley']\n3 33002 33173\n > [['un', 'deber', 'que', 'no', 'se', 'puede', 'dejar', 'de', 'lado', 'según', 'nuestro', 'punto', 'de', 'vista', 'es', 'el', 'respeto', 'por', 'la', 'constitución', 'por', 'que', 'esta', 'tiene', 'las', 'normas', 'derechos', 'y', 'la', 'organización', 'del'], 'respeto por la constitución']\n > [['es', 'de', 'vital', 'que', 'la', 'sea', 'es', 'un', 'deber', 'que', 'las', 'personas', 'deben', 'cumplir'], 'respeto por la constitución']\n > [['la', 'constitución', 'es', 'la', 'ley', 'fundamental', 'que', 'define', 'la', 'organización', 'política', 'del', 'estado', 'y', 'contiene', 'los', 'derechos', 'y', 'deberes', 'de', 'la', 'ciudadanía', 'e', 'instituciones', 'establece', 'el', 'marco', 'legal', 'básico', 'para', 'vivir', 'en', 'paz', 'armonía', 'y', 'justicia', 'por', 'lo', 'que', 'el', 'respeto', 'a', 'la', 'constitución', 'se', 'como', 'un', 'deber', 'esencial', 'y', 'una', 'responsabilidad', 'de', 'todos'], 'respeto por la constitución']\n > [['en', 'la', 'medida', 'de', 'que', 'sea', 'legítima', 'aprobada', 'a', 'través', 'de', 'una', 'votación', 'ciudadana'], 'respeto por la constitución']\n > [['debe', 'respetar', 'las', 'personas', 'sus', 'familias', 'y', 'su', 'entorno'], 'respeto por la constitución']\n4 32615 32780\n > [['debe', 'ser', 'una', 'institución', 'autónoma', 'e', 'independiente', 'que', 'se', 'de', 'garantizar', 'los', 'derechos', 'de', 'los', 'ciudadanos', 'ante', 'los', 'abusos', 'que', 'puedan', 'cometer', 'los', 'poderes', 'políticos', 'y', 'administrativos', 'y', 'debe', 'supervisar', 'el', 'pleno', 'cumplimiento', 'de', 'los', 'derechos', 'humanos', 'y', 'fundamentales'], 'defensor del pueblo ciudadano']\n > [['que', 'se', 'cree', 'un', 'organismo', 'que', 'este', 'mas', 'cerca', 'de', 'las', 'personas', 'y', 'pueda'], 'defensor del pueblo ciudadano']\n > [['que', 'la', 'constitución', 'esta', 'figura', 'para', 'la', 'defensa', 'de', 'derechos', 'colectivos', 'las', 'instancias', 'de', 'acceso', 'a', 'la', 'justicia'], 'defensor del pueblo ciudadano']\n > [['debe', 'existir', 'un', 'organismo', 'que', 'los', 'derechos', 'ciudadanos', 'de', 'forma', 'real', 'que', 'sea', 'entre', 'las', 'personas', 'y', 'los', 'poderes', 'del', 'estado', 'que', 'se', 'cumplan', 'de', 'verdad', 'los', 'derechos', 'ciudadanos', 'que', 'existen', 'en', 'nuestra', 'constitución'], 'defensor del pueblo ciudadano']\n > [['para', 'defender', 'a', 'los', 'ciudadanos', 'de', 'los', 'abusos', 'del', 'sistema'], 'defensor del pueblo ciudadano']\n",
      "torch.Size([10001, 300])\nTraining topic 1\namount of pairs: 37442\n\nnum_concept: 37\n > amistad cívica\n > autonomía libertad\n > bien común comunidad\n > ciudadanía\n > democracia\n > desarrollo\n > descentralización\n > dignidad\n > diversidad\n > emprendimiento libre\n > equidad de género\n > estado de derecho\n > estado laico\n > identidad cultural\n > igualdad\n > inclusión\n > innovación creatividad\n > integración\n > justicia\n > multiculturalidad\n > participación\n > patriotismo\n > paz convivencia pacífica\n > pluralismo\n > plurinacionalismo\n > probidad\n > república\n > respeto\n > respeto conservación de la naturaleza o medio ambiente\n > responsabilidad\n > seguridad\n > soberanía\n > solidaridad\n > subsidiaridad\n > tolerancia\n > transparencia y publicidad\n > unidad\nEmbedding(10001, 300)\nLSTM(300, 37, batch_first=True, dropout=0.5)\nLogSoftmax()\n",
      "ClassifierModel(\n  (embedding): Embedding(10001, 300)\n  (lstm): LSTM(300, 37, batch_first=True, dropout=0.5)\n  (logsoftmax): LogSoftmax()\n)\nParameter containing:\ntensor([[-7.0740e-01,  3.9066e-01, -5.6366e-01,  ...,  1.8312e-01,\n          2.1365e-01,  2.3578e+00],\n        [ 7.0612e-01,  4.8166e-01, -1.0050e+00,  ...,  5.8327e-01,\n          4.9777e-02, -2.3244e-01],\n        [ 2.1584e-03, -1.0686e+00,  3.1192e-01,  ..., -9.8269e-01,\n          2.5471e+00,  1.5075e-01],\n        ...,\n        [-1.7257e+00,  1.2460e+00,  6.7471e-01,  ..., -2.7105e+00,\n          7.4602e-01, -4.2485e-01],\n        [ 3.7800e-01, -4.1441e-01,  8.5661e-01,  ..., -1.5113e+00,\n          2.4649e-01,  3.3655e-01],\n        [ 3.8711e-01, -1.4772e+00,  2.3318e-01,  ...,  9.6566e-01,\n         -1.4009e+00,  7.2075e-01]], device='cuda:0', requires_grad=True)\nParameter containing:\ntensor([[ 0.0381, -0.1076,  0.0639,  ..., -0.0094, -0.0804,  0.1423],\n        [-0.0764,  0.0234,  0.0649,  ..., -0.1048, -0.1271,  0.1162],\n        [-0.0772, -0.1206, -0.1442,  ..., -0.0210, -0.0663,  0.0620],\n        ...,\n        [ 0.1474, -0.1371,  0.1607,  ...,  0.1545, -0.0857,  0.1049],\n        [-0.0111, -0.0846,  0.0540,  ...,  0.0435, -0.1416, -0.1019],\n        [ 0.1211, -0.1408,  0.0792,  ...,  0.1507, -0.0081, -0.1607]],\n       device='cuda:0', requires_grad=True)\nParameter containing:\ntensor([[-0.1229, -0.1643,  0.1163,  ...,  0.1282, -0.0799, -0.1441],\n        [-0.0730, -0.0589,  0.1110,  ..., -0.0317, -0.1019, -0.0717],\n        [-0.1342, -0.1469,  0.1223,  ...,  0.1157, -0.1206,  0.0923],\n        ...,\n        [-0.0450,  0.0747, -0.1641,  ...,  0.0950,  0.1460, -0.0164],\n        [-0.0878,  0.0055,  0.0919,  ..., -0.1447, -0.0681, -0.1304],\n        [ 0.1564,  0.1153,  0.1282,  ..., -0.0229,  0.1306,  0.0144]],\n       device='cuda:0', requires_grad=True)\nParameter containing:\ntensor([ 0.1591, -0.0331,  0.0231,  0.1523, -0.0840, -0.0290, -0.1223,  0.1225,\n         0.0134,  0.0965, -0.0558,  0.1428,  0.1312,  0.0713, -0.0630, -0.0188,\n        -0.0077, -0.0676, -0.1178,  0.0884,  0.1634, -0.0049, -0.0667,  0.1112,\n         0.0014,  0.0552,  0.1507,  0.0294,  0.0395,  0.0743, -0.0541,  0.1230,\n         0.1022,  0.0822,  0.1015,  0.0739, -0.0674,  0.0729, -0.0415,  0.0893,\n         0.1479, -0.1469, -0.0366, -0.1338,  0.1101, -0.0762,  0.0201,  0.1322,\n         0.1347,  0.1482,  0.0525, -0.1216, -0.0681,  0.0868, -0.1337,  0.1326,\n        -0.0581, -0.0221,  0.1592,  0.0946, -0.0771,  0.0986,  0.0900, -0.0927,\n        -0.0719, -0.1605,  0.0696, -0.0441,  0.0297,  0.1028,  0.1226,  0.1244,\n        -0.1074, -0.0810,  0.0014, -0.0662,  0.0865, -0.0916, -0.1095,  0.1619,\n         0.0354,  0.0533,  0.1310, -0.1304, -0.0855, -0.0757, -0.1385,  0.1524,\n        -0.0377, -0.1285, -0.0954, -0.1326, -0.0824, -0.0869,  0.1116,  0.0191,\n        -0.1507,  0.1332,  0.0740, -0.0504, -0.0379,  0.0907,  0.1581,  0.1097,\n        -0.0139,  0.0666,  0.0628, -0.0984, -0.1534,  0.0350, -0.1363,  0.0113,\n        -0.0707, -0.1213, -0.1290,  0.1072, -0.1630,  0.0147,  0.1256,  0.0833,\n         0.0916,  0.1122, -0.0095, -0.0238, -0.0558,  0.0499, -0.0468,  0.0584,\n        -0.0779,  0.0714, -0.0189,  0.0365,  0.0716,  0.0422, -0.0393,  0.0062,\n        -0.1519, -0.1254,  0.1257, -0.0928, -0.1278,  0.0448, -0.1408, -0.0384,\n        -0.0836,  0.0910, -0.1061, -0.1092], device='cuda:0',\n       requires_grad=True)\nParameter containing:\ntensor([-0.0008,  0.1577,  0.0775, -0.1150,  0.0715,  0.1255,  0.1175, -0.0114,\n        -0.0323, -0.1167,  0.0312,  0.1342, -0.0010, -0.1101,  0.0412, -0.0112,\n        -0.0253, -0.1494,  0.1273, -0.0668, -0.1025,  0.0882,  0.0769,  0.1196,\n         0.1412,  0.0721, -0.1240, -0.0538, -0.0470,  0.1499, -0.0992, -0.0727,\n        -0.1092, -0.1015,  0.0103,  0.0472, -0.0980,  0.0270, -0.0545,  0.0383,\n         0.1518,  0.0629,  0.1218, -0.1545,  0.0148,  0.1437, -0.0462,  0.0339,\n        -0.0467, -0.0829,  0.0487,  0.1525, -0.0221, -0.1042, -0.0987,  0.0432,\n         0.0966, -0.1585,  0.0374, -0.1380,  0.0266,  0.0103,  0.0141, -0.0511,\n        -0.1072, -0.0607, -0.0010, -0.1202,  0.1193, -0.0475, -0.1120,  0.1027,\n         0.0241, -0.1593,  0.0686, -0.0848,  0.1549,  0.1000,  0.1462,  0.0755,\n         0.0638, -0.1531,  0.0701, -0.0269,  0.0681,  0.1535,  0.1572,  0.1641,\n        -0.1107, -0.0757,  0.1533,  0.0664, -0.1142,  0.1110, -0.0975, -0.0720,\n        -0.0495, -0.0702, -0.1265, -0.0791, -0.0836, -0.1436,  0.0357, -0.1231,\n        -0.0561,  0.1372, -0.1122,  0.0937, -0.0497, -0.0854,  0.0556, -0.1581,\n         0.0663,  0.1214,  0.1056,  0.0794, -0.0640,  0.0781,  0.1138,  0.1468,\n        -0.0006,  0.1472, -0.0768, -0.0395, -0.0340,  0.0527, -0.1306, -0.0559,\n         0.1043,  0.0168,  0.1243,  0.0789, -0.0746,  0.0191, -0.0209,  0.0568,\n         0.0867, -0.0146, -0.1118,  0.0592,  0.0762,  0.1557,  0.0811, -0.1277,\n         0.1206, -0.1519, -0.1469,  0.1022], device='cuda:0',\n       requires_grad=True)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "d:\\documents\\memoria - eval. word embeddings\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n  \"num_layers={}\".format(dropout, num_layers))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# tamaño de input y hidden layer\n",
    "n_input = word_vector.vector_size\n",
    "n_hidden = 128\n",
    "\n",
    "\n",
    "# Revisar palabras oov\n",
    "clean_train_task_A = cleanDataVocab(train_task_A, word_vector)\n",
    "clean_dev_task_A = cleanDataVocab(dev_task_A, word_vector)\n",
    "clean_test_task_A = cleanDataVocab(test_task_A, word_vector)\n",
    "#word_vector.add(\"<pad>\", np.random.rand(word_vector.vector_size))\n",
    "pad = torch.FloatTensor([np.random.rand(word_vector.vector_size)])\n",
    "for topic in clean_train_task_A.keys():\n",
    "    print(topic + \" \" + str(len(clean_train_task_A[topic])) + \" \" + str(len(train_task_A[topic])))\n",
    "    \n",
    "    for i in range(5):\n",
    "        print(\" > \", end='')\n",
    "        print(clean_train_task_A[topic][i])\n",
    "        \n",
    "weight = torch.FloatTensor(word_vector.vectors)\n",
    "weight = torch.cat([pad, weight])\n",
    "weight.cuda()\n",
    "print(weight.size())\n",
    "\n",
    "\n",
    "# Train set\n",
    "topic = list(clean_train_task_A.keys())[0]\n",
    "print(\"Training topic \" + topic)\n",
    "\n",
    "train_topic = clean_train_task_A[topic]\n",
    "dev_topic = clean_dev_task_A[topic]\n",
    "test_topic = clean_test_task_A[topic]\n",
    "print(\"amount of pairs: \" + str(len(train_topic)) + \"\\n\")\n",
    "\n",
    "\n",
    "# Define concepts\n",
    "concept_list = []\n",
    "for pair in train_topic:\n",
    "    concept = pair[1]\n",
    "    if concept not in concept_list:\n",
    "        concept_list.append(concept)\n",
    "        \n",
    "concept_list.sort()\n",
    "n_output = len(concept_list)\n",
    "print(\"num_concept: \" + str(n_output))\n",
    "for c in concept_list:\n",
    "    print(\" > \" + c)\n",
    "\n",
    "\n",
    "# Get RNN\n",
    "mylstm = ClassifierModel(n_output, weight)\n",
    "mylstm.cuda()\n",
    "#mylstm.cuda()\n",
    "optimizer = torch.optim.Adam(mylstm.parameters())\n",
    "\n",
    "print(mylstm)\n",
    "for p in mylstm.parameters():\n",
    "    print(p)\n",
    "\n",
    "all_losses = []\n",
    "epoch = 100\n",
    "learning_rate = 0.01\n",
    "batch_size = 1000\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoca: 1\n",
      "Number of batchs: 38\nbatch 1\n",
      " >> forward\n > max_len\ntensor(101, device='cuda:0')\n > emb\ntorch.Size([1000, 101, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 101, 37])\n > out(reshape)\ntorch.Size([101000, 37])\n",
      " > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.653965711593628\n > accuracy: 32 / 1000\n\nbatch 2\n",
      " >> forward\n > max_len\ntensor(135, device='cuda:0')\n > emb\ntorch.Size([1000, 135, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 135, 37])\n > out(reshape)\ntorch.Size([135000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.644725799560547\n",
      " > accuracy: 32 / 1000\n\nbatch 3\n",
      " >> forward\n > max_len\ntensor(162, device='cuda:0')\n > emb\ntorch.Size([1000, 162, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 162, 37])\n > out(reshape)\ntorch.Size([162000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.6319103240966797\n",
      " > accuracy: 28 / 1000\n\nbatch 4\n",
      " >> forward\n > max_len\ntensor(158, device='cuda:0')\n > emb\ntorch.Size([1000, 158, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 158, 37])\n > out(reshape)\ntorch.Size([158000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.606098175048828\n",
      " > accuracy: 44 / 1000\n\nbatch 5\n",
      " >> forward\n > max_len\ntensor(166, device='cuda:0')\n > emb\ntorch.Size([1000, 166, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 166, 37])\n > out(reshape)\ntorch.Size([166000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.607773780822754\n",
      " > accuracy: 35 / 1000\n\nbatch 6\n",
      " >> forward\n > max_len\ntensor(149, device='cuda:0')\n > emb\ntorch.Size([1000, 149, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 149, 37])\n > out(reshape)\ntorch.Size([149000, 37])\n",
      " > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.621279001235962\n > accuracy: 29 / 1000\n\nbatch 7\n",
      " >> forward\n > max_len\ntensor(142, device='cuda:0')\n > emb\ntorch.Size([1000, 142, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 142, 37])\n > out(reshape)\ntorch.Size([142000, 37])\n",
      " > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.6119492053985596\n > accuracy: 40 / 1000\n\nbatch 8\n",
      " >> forward\n > max_len\ntensor(133, device='cuda:0')\n > emb\ntorch.Size([1000, 133, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 133, 37])\n > out(reshape)\ntorch.Size([133000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.589489221572876\n > accuracy: 44 / 1000\n\nbatch 9\n",
      " >> forward\n > max_len\ntensor(192, device='cuda:0')\n > emb\ntorch.Size([1000, 192, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 192, 37])\n > out(reshape)\ntorch.Size([192000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.5863842964172363\n > accuracy: 53 / 1000\n\nbatch 10\n",
      " >> forward\n > max_len\ntensor(164, device='cuda:0')\n > emb\ntorch.Size([1000, 164, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 164, 37])\n > out(reshape)\ntorch.Size([164000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.5792105197906494\n",
      " > accuracy: 48 / 1000\n\n",
      " >> forward\n > max_len\ntensor(103, device='cuda:0')\n > emb\ntorch.Size([1000, 103, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 103, 37])\n > out(reshape)\ntorch.Size([103000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 3.569798469543457\n",
      " > accuracy: 46 / 1000\n\nbatch 11\n",
      " >> forward\n > max_len\ntensor(132, device='cuda:0')\n > emb\ntorch.Size([1000, 132, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 132, 37])\n > out(reshape)\ntorch.Size([132000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.5685858726501465\n",
      " > accuracy: 57 / 1000\n\nbatch 12\n",
      " >> forward\n > max_len\ntensor(132, device='cuda:0')\n > emb\ntorch.Size([1000, 132, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 132, 37])\n > out(reshape)\ntorch.Size([132000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.5664637088775635\n",
      " > accuracy: 54 / 1000\n\nbatch 13\n",
      " >> forward\n > max_len\ntensor(154, device='cuda:0')\n > emb\ntorch.Size([1000, 154, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 154, 37])\n > out(reshape)\ntorch.Size([154000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.550694465637207\n > accuracy: 65 / 1000\n\nbatch 14\n",
      " >> forward\n > max_len\ntensor(175, device='cuda:0')\n > emb\ntorch.Size([1000, 175, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 175, 37])\n > out(reshape)\ntorch.Size([175000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.5524611473083496\n",
      " > accuracy: 53 / 1000\n\nbatch 15\n",
      " >> forward\n > max_len\ntensor(157, device='cuda:0')\n > emb\ntorch.Size([1000, 157, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 157, 37])\n > out(reshape)\ntorch.Size([157000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: ",
      "3.5444324016571045\n > accuracy: 60 / 1000\n\nbatch 16\n",
      " >> forward\n > max_len\ntensor(136, device='cuda:0')\n > emb\ntorch.Size([1000, 136, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 136, 37])\n > out(reshape)\ntorch.Size([136000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.5223770141601562\n",
      " > accuracy: 75 / 1000\n\nbatch 17\n",
      " >> forward\n > max_len\ntensor(73, device='cuda:0')\n > emb\ntorch.Size([1000, 73, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 73, 37])\n > out(reshape)\ntorch.Size([73000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.53658127784729\n > accuracy: 57 / 1000\n\nbatch 18\n",
      " >> forward\n > max_len\ntensor(114, device='cuda:0')\n > emb\ntorch.Size([1000, 114, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 114, 37])\n > out(reshape)\ntorch.Size([114000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.5407094955444336\n",
      " > accuracy: 68 / 1000\n\nbatch 19\n",
      " >> forward\n > max_len\ntensor(117, device='cuda:0')\n > emb\ntorch.Size([1000, 117, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 117, 37])\n > out(reshape)\ntorch.Size([117000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.500814914703369\n",
      " > accuracy: 86 / 1000\n\nbatch 20\n",
      " >> forward\n > max_len\ntensor(328, device='cuda:0')\n > emb\ntorch.Size([1000, 328, 300])\n",
      " > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 328, 37])\n > out(reshape)\ntorch.Size([328000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.5111818313598633\n",
      " > accuracy: 73 / 1000\n\n",
      " >> forward\n > max_len\ntensor(103, device='cuda:0')\n > emb\ntorch.Size([1000, 103, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 103, 37])\n > out(reshape)\ntorch.Size([103000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 3.502047300338745\n",
      " > accuracy: 81 / 1000\n\nbatch 21\n",
      " >> forward\n > max_len\ntensor(91, device='cuda:0')\n > emb\ntorch.Size([1000, 91, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 91, 37])\n > out(reshape)\ntorch.Size([91000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.5185327529907227\n > accuracy: 70 / 1000\n\nbatch 22\n",
      " >> forward\n > max_len\ntensor(120, device='cuda:0')\n > emb\ntorch.Size([1000, 120, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 120, 37])\n > out(reshape)\ntorch.Size([120000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.499600887298584\n",
      " > accuracy: 80 / 1000\n\nbatch 23\n",
      " >> forward\n > max_len\ntensor(87, device='cuda:0')\n > emb\ntorch.Size([1000, 87, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 87, 37])\n > out(reshape)\ntorch.Size([87000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.5134832859039307\n",
      " > accuracy: 91 / 1000\n\nbatch 24\n",
      " >> forward\n > max_len\ntensor(94, device='cuda:0')\n > emb\ntorch.Size([1000, 94, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 94, 37])\n > out(reshape)\ntorch.Size([94000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.502810478210449\n",
      " > accuracy: 81 / 1000\n\nbatch 25\n",
      " >> forward\n > max_len\ntensor(124, device='cuda:0')\n > emb\ntorch.Size([1000, 124, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 124, 37])\n > out(reshape)\ntorch.Size([124000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.4823288917541504\n",
      " > accuracy: 95 / 1000\n\nbatch 26\n",
      " >> forward\n > max_len\ntensor(86, device='cuda:0')\n > emb\ntorch.Size([1000, 86, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 86, 37])\n > out(reshape)\ntorch.Size([86000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.472747325897217\n",
      " > accuracy: 108 / 1000\n\nbatch 27\n",
      " >> forward\n > max_len\ntensor(90, device='cuda:0')\n > emb\ntorch.Size([1000, 90, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 90, 37])\n > out(reshape)\ntorch.Size([90000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.4633257389068604\n",
      " > accuracy: 106 / 1000\n\nbatch 28\n",
      " >> forward\n > max_len\ntensor(128, device='cuda:0')\n > emb\ntorch.Size([1000, 128, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 128, 37])\n > out(reshape)\ntorch.Size([128000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.487762451171875\n",
      " > accuracy: 91 / 1000\n\nbatch 29\n",
      " >> forward\n > max_len\ntensor(113, device='cuda:0')\n > emb\ntorch.Size([1000, 113, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 113, 37])\n > out(reshape)\ntorch.Size([113000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.4747474193573\n",
      " > accuracy: 107 / 1000\n\nbatch 30\n",
      " >> forward\n > max_len\ntensor(105, device='cuda:0')\n > emb\ntorch.Size([1000, 105, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 105, 37])\n > out(reshape)\ntorch.Size([105000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.466827869415283\n",
      " > accuracy: 98 / 1000\n\n",
      " >> forward\n > max_len\ntensor(103, device='cuda:0')\n > emb\ntorch.Size([1000, 103, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 103, 37])\n > out(reshape)\ntorch.Size([103000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 3.445735454559326\n",
      " > accuracy: 106 / 1000\n\nbatch 31\n",
      " >> forward\n > max_len\ntensor(106, device='cuda:0')\n > emb\ntorch.Size([1000, 106, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 106, 37])\n > out(reshape)\ntorch.Size([106000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.47039794921875\n",
      " > accuracy: 89 / 1000\n\nbatch 32\n",
      " >> forward\n > max_len\ntensor(108, device='cuda:0')\n > emb\ntorch.Size([1000, 108, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 108, 37])\n > out(reshape)\ntorch.Size([108000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.455679416656494\n",
      " > accuracy: 95 / 1000\n\nbatch 33\n",
      " >> forward\n > max_len\ntensor(123, device='cuda:0')\n > emb\ntorch.Size([1000, 123, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 123, 37])\n > out(reshape)\ntorch.Size([123000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.436195135116577\n",
      " > accuracy: 117 / 1000\n\nbatch 34\n",
      " >> forward\n > max_len\ntensor(100, device='cuda:0')\n > emb\ntorch.Size([1000, 100, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 100, 37])\n > out(reshape)\ntorch.Size([100000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.4252123832702637\n",
      " > accuracy: 119 / 1000\n\nbatch 35\n",
      " >> forward\n > max_len\ntensor(97, device='cuda:0')\n > emb\ntorch.Size([1000, 97, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 97, 37])\n > out(reshape)\ntorch.Size([97000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.4223499298095703\n",
      " > accuracy: 144 / 1000\n\nbatch 36\n",
      " >> forward\n > max_len\ntensor(152, device='cuda:0')\n > emb\ntorch.Size([1000, 152, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 152, 37])\n > out(reshape)\ntorch.Size([152000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.4307971000671387\n",
      " > accuracy: 117 / 1000\n\nbatch 37\n",
      " >> forward\n > max_len\ntensor(89, device='cuda:0')\n > emb\ntorch.Size([1000, 89, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 89, 37])\n > out(reshape)\ntorch.Size([89000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.4383063316345215\n",
      " > accuracy: 116 / 1000\n\nbatch 38\n",
      " >> forward\n > max_len\ntensor(58, device='cuda:0')\n > emb\ntorch.Size([442, 58, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([442, 58, 37])\n > out(reshape)\ntorch.Size([25636, 37])\n > last_out\ntorch.Size([442, 37])\n > logits\ntorch.Size([442, 37])\n > loss: 3.4280669689178467\n > accuracy: 49 / 442\n\nEpoca: 2\n",
      "Number of batchs: 38\nbatch 1\n",
      " >> forward\n > max_len\ntensor(136, device='cuda:0')\n > emb\ntorch.Size([1000, 136, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 136, 37])\n > out(reshape)\ntorch.Size([136000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.40801739692688\n > accuracy: 123 / 1000\n\nbatch 2\n",
      " >> forward\n > max_len\ntensor(152, device='cuda:0')\n > emb\ntorch.Size([1000, 152, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 152, 37])\n > out(reshape)\ntorch.Size([152000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.3813793659210205\n",
      " > accuracy: 121 / 1000\n\nbatch 3\n",
      " >> forward\n > max_len\ntensor(89, device='cuda:0')\n > emb\ntorch.Size([1000, 89, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 89, 37])\n > out(reshape)\ntorch.Size([89000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.389467477798462\n",
      " > accuracy: 121 / 1000\n\nbatch 4\n",
      " >> forward\n > max_len\ntensor(114, device='cuda:0')\n > emb\ntorch.Size([1000, 114, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 114, 37])\n > out(reshape)\ntorch.Size([114000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.385620594024658\n",
      " > accuracy: 128 / 1000\n\nbatch 5\n",
      " >> forward\n > max_len\ntensor(132, device='cuda:0')\n > emb\ntorch.Size([1000, 132, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 132, 37])\n > out(reshape)\ntorch.Size([132000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.3958752155303955\n",
      " > accuracy: 127 / 1000\n\nbatch 6\n",
      " >> forward\n > max_len\ntensor(128, device='cuda:0')\n > emb\ntorch.Size([1000, 128, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 128, 37])\n > out(reshape)\ntorch.Size([128000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.3763155937194824\n",
      " > accuracy: 143 / 1000\n\nbatch 7\n",
      " >> forward\n > max_len\ntensor(142, device='cuda:0')\n > emb\ntorch.Size([1000, 142, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 142, 37])\n > out(reshape)\ntorch.Size([142000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.354501962661743\n",
      " > accuracy: 144 / 1000\n\nbatch 8\n",
      " >> forward\n > max_len\ntensor(192, device='cuda:0')\n > emb\ntorch.Size([1000, 192, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 192, 37])\n > out(reshape)\ntorch.Size([192000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.377136468887329\n",
      " > accuracy: 127 / 1000\n\nbatch 9\n",
      " >> forward\n > max_len\ntensor(328, device='cuda:0')\n > emb\ntorch.Size([1000, 328, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 328, 37])\n > out(reshape)\ntorch.Size([328000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.3515732288360596\n",
      " > accuracy: 154 / 1000\n\nbatch 10\n",
      " >> forward\n > max_len\ntensor(104, device='cuda:0')\n > emb\ntorch.Size([1000, 104, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 104, 37])\n > out(reshape)\ntorch.Size([104000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.3425326347351074\n",
      " > accuracy: 153 / 1000\n\n",
      " >> forward\n > max_len\ntensor(144, device='cuda:0')\n > emb\ntorch.Size([1000, 144, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 144, 37])\n > out(reshape)\ntorch.Size([144000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 3.3596980571746826\n",
      " > accuracy: 125 / 1000\n\nbatch 11\n",
      " >> forward\n > max_len\ntensor(148, device='cuda:0')\n > emb\ntorch.Size([1000, 148, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 148, 37])\n > out(reshape)\ntorch.Size([148000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.342052459716797\n",
      " > accuracy: 153 / 1000\n\nbatch 12\n",
      " >> forward\n > max_len\ntensor(162, device='cuda:0')\n > emb\ntorch.Size([1000, 162, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 162, 37])\n > out(reshape)\ntorch.Size([162000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.35977840423584\n",
      " > accuracy: 142 / 1000\n\nbatch 13\n",
      " >> forward\n > max_len\ntensor(158, device='cuda:0')\n > emb\ntorch.Size([1000, 158, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 158, 37])\n > out(reshape)\ntorch.Size([158000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.3241987228393555\n",
      " > accuracy: 152 / 1000\n\nbatch 14\n",
      " >> forward\n > max_len\ntensor(114, device='cuda:0')\n > emb\ntorch.Size([1000, 114, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 114, 37])\n > out(reshape)\ntorch.Size([114000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.3289613723754883\n",
      " > accuracy: 155 / 1000\n\nbatch 15\n",
      " >> forward\n > max_len\ntensor(154, device='cuda:0')\n > emb\ntorch.Size([1000, 154, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 154, 37])\n > out(reshape)\ntorch.Size([154000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.297585964202881\n",
      " > accuracy: 164 / 1000\n\nbatch 16\n",
      " >> forward\n > max_len\ntensor(82, device='cuda:0')\n > emb\ntorch.Size([1000, 82, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 82, 37])\n > out(reshape)\ntorch.Size([82000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.332571029663086\n",
      " > accuracy: 149 / 1000\n\nbatch 17\n",
      " >> forward\n > max_len\ntensor(132, device='cuda:0')\n > emb\ntorch.Size([1000, 132, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 132, 37])\n > out(reshape)\ntorch.Size([132000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.310185194015503\n",
      " > accuracy: 144 / 1000\n\nbatch 18\n",
      " >> forward\n > max_len\ntensor(106, device='cuda:0')\n > emb\ntorch.Size([1000, 106, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 106, 37])\n > out(reshape)\ntorch.Size([106000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.32118821144104\n",
      " > accuracy: 149 / 1000\n\nbatch 19\n",
      " >> forward\n > max_len\ntensor(89, device='cuda:0')\n > emb\ntorch.Size([1000, 89, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 89, 37])\n > out(reshape)\ntorch.Size([89000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.306575298309326\n",
      " > accuracy: 134 / 1000\n\nbatch 20\n",
      " >> forward\n > max_len\ntensor(164, device='cuda:0')\n > emb\ntorch.Size([1000, 164, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 164, 37])\n > out(reshape)\ntorch.Size([164000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.3091704845428467\n",
      " > accuracy: 144 / 1000\n\n",
      " >> forward\n > max_len\ntensor(144, device='cuda:0')\n > emb\ntorch.Size([1000, 144, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 144, 37])\n > out(reshape)\ntorch.Size([144000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 3.3011763095855713\n > accuracy: 136 / 1000\n\nbatch 21\n",
      " >> forward\n > max_len\ntensor(166, device='cuda:0')\n > emb\ntorch.Size([1000, 166, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 166, 37])\n > out(reshape)\ntorch.Size([166000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.293877124786377\n",
      " > accuracy: 170 / 1000\n\nbatch 22\n",
      " >> forward\n > max_len\ntensor(96, device='cuda:0')\n > emb\ntorch.Size([1000, 96, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 96, 37])\n > out(reshape)\ntorch.Size([96000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.303450584411621\n",
      " > accuracy: 142 / 1000\n\nbatch 23\n",
      " >> forward\n > max_len\ntensor(113, device='cuda:0')\n > emb\ntorch.Size([1000, 113, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 113, 37])\n > out(reshape)\ntorch.Size([113000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.2673773765563965\n",
      " > accuracy: 152 / 1000\n\nbatch 24\n",
      " >> forward\n > max_len\ntensor(99, device='cuda:0')\n > emb\ntorch.Size([1000, 99, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 99, 37])\n > out(reshape)\ntorch.Size([99000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.243695020675659\n",
      " > accuracy: 191 / 1000\n\nbatch 25\n",
      " >> forward\n > max_len\ntensor(101, device='cuda:0')\n > emb\ntorch.Size([1000, 101, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 101, 37])\n > out(reshape)\ntorch.Size([101000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n",
      " > loss: 3.250579357147217\n > accuracy: 173 / 1000\n\nbatch 26\n",
      " >> forward\n > max_len\ntensor(124, device='cuda:0')\n > emb\ntorch.Size([1000, 124, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 124, 37])\n > out(reshape)\ntorch.Size([124000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.307969570159912\n",
      " > accuracy: 137 / 1000\n\nbatch 27\n",
      " >> forward\n > max_len\ntensor(137, device='cuda:0')\n > emb\ntorch.Size([1000, 137, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 137, 37])\n > out(reshape)\ntorch.Size([137000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.2272958755493164\n",
      " > accuracy: 179 / 1000\n\nbatch 28\n",
      " >> forward\n > max_len\ntensor(158, device='cuda:0')\n > emb\ntorch.Size([1000, 158, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 158, 37])\n > out(reshape)\ntorch.Size([158000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.242608070373535\n > accuracy: 155 / 1000\n\nbatch 29\n",
      " >> forward\n > max_len\ntensor(175, device='cuda:0')\n > emb\ntorch.Size([1000, 175, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 175, 37])\n > out(reshape)\ntorch.Size([175000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.2377281188964844\n",
      " > accuracy: 165 / 1000\n\nbatch 30\n",
      " >> forward\n > max_len\ntensor(119, device='cuda:0')\n > emb\ntorch.Size([1000, 119, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 119, 37])\n > out(reshape)\ntorch.Size([119000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.238300085067749\n",
      " > accuracy: 159 / 1000\n\n",
      " >> forward\n > max_len\ntensor(144, device='cuda:0')\n > emb\ntorch.Size([1000, 144, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 144, 37])\n > out(reshape)\ntorch.Size([144000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 3.244365692138672\n",
      " > accuracy: 148 / 1000\n\nbatch 31\n",
      " >> forward\n > max_len\ntensor(93, device='cuda:0')\n > emb\ntorch.Size([1000, 93, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 93, 37])\n > out(reshape)\ntorch.Size([93000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.219607353210449\n",
      " > accuracy: 170 / 1000\n\nbatch 32\n",
      " >> forward\n > max_len\ntensor(157, device='cuda:0')\n > emb\ntorch.Size([1000, 157, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 157, 37])\n > out(reshape)\ntorch.Size([157000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.209048271179199\n",
      " > accuracy: 191 / 1000\n\nbatch 33\n",
      " >> forward\n > max_len\ntensor(104, device='cuda:0')\n > emb\ntorch.Size([1000, 104, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 104, 37])\n > out(reshape)\ntorch.Size([104000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.2224924564361572\n",
      " > accuracy: 153 / 1000\n\nbatch 34\n",
      " >> forward\n > max_len\ntensor(157, device='cuda:0')\n > emb\ntorch.Size([1000, 157, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 157, 37])\n > out(reshape)\ntorch.Size([157000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.243382453918457\n",
      " > accuracy: 136 / 1000\n\nbatch 35\n",
      " >> forward\n > max_len\ntensor(133, device='cuda:0')\n > emb\ntorch.Size([1000, 133, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 133, 37])\n > out(reshape)\ntorch.Size([133000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.2530951499938965\n",
      " > accuracy: 143 / 1000\n\nbatch 36\n",
      " >> forward\n > max_len\ntensor(106, device='cuda:0')\n > emb\ntorch.Size([1000, 106, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 106, 37])\n > out(reshape)\ntorch.Size([106000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.207839250564575\n",
      " > accuracy: 158 / 1000\n\nbatch 37\n",
      " >> forward\n > max_len\ntensor(114, device='cuda:0')\n > emb\ntorch.Size([1000, 114, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 114, 37])\n > out(reshape)\ntorch.Size([114000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.2008564472198486\n",
      " > accuracy: 140 / 1000\n\nbatch 38\n",
      " >> forward\n > max_len\ntensor(166, device='cuda:0')\n > emb\ntorch.Size([442, 166, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([442, 166, 37])\n > out(reshape)\ntorch.Size([73372, 37])\n > last_out\ntorch.Size([442, 37])\n > logits\ntorch.Size([442, 37])\n > loss: 3.2075235843658447\n > accuracy: 65 / 442\n\nEpoca: 3\n",
      "Number of batchs: 38\nbatch 1\n",
      " >> forward\n > max_len\ntensor(114, device='cuda:0')\n > emb\ntorch.Size([1000, 114, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 114, 37])\n > out(reshape)\ntorch.Size([114000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.201355218887329\n",
      " > accuracy: 142 / 1000\n\nbatch 2\n",
      " >> forward\n > max_len\ntensor(108, device='cuda:0')\n > emb\ntorch.Size([1000, 108, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 108, 37])\n > out(reshape)\ntorch.Size([108000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.172292947769165\n",
      " > accuracy: 167 / 1000\n\nbatch 3\n",
      " >> forward\n > max_len\ntensor(94, device='cuda:0')\n > emb\ntorch.Size([1000, 94, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 94, 37])\n > out(reshape)\ntorch.Size([94000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1628243923187256\n",
      " > accuracy: 161 / 1000\n\nbatch 4\n",
      " >> forward\n > max_len\ntensor(117, device='cuda:0')\n > emb\ntorch.Size([1000, 117, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 117, 37])\n > out(reshape)\ntorch.Size([117000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.127777099609375\n",
      " > accuracy: 163 / 1000\n\nbatch 5\n",
      " >> forward\n > max_len\ntensor(120, device='cuda:0')\n > emb\ntorch.Size([1000, 120, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 120, 37])\n > out(reshape)\ntorch.Size([120000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1633150577545166\n",
      " > accuracy: 151 / 1000\n\nbatch 6\n",
      " >> forward\n > max_len\ntensor(96, device='cuda:0')\n > emb\ntorch.Size([1000, 96, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 96, 37])\n > out(reshape)\ntorch.Size([96000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1635446548461914\n",
      " > accuracy: 167 / 1000\n\nbatch 7\n",
      " >> forward\n > max_len\ntensor(66, device='cuda:0')\n > emb\ntorch.Size([1000, 66, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 66, 37])\n > out(reshape)\ntorch.Size([66000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: ",
      "3.1369950771331787\n > accuracy: 203 / 1000\n\nbatch 8\n",
      " >> forward\n > max_len\ntensor(106, device='cuda:0')\n > emb\ntorch.Size([1000, 106, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 106, 37])\n > out(reshape)\ntorch.Size([106000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1605513095855713\n",
      " > accuracy: 166 / 1000\n\nbatch 9\n",
      " >> forward\n > max_len\ntensor(128, device='cuda:0')\n > emb\ntorch.Size([1000, 128, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 128, 37])\n > out(reshape)\ntorch.Size([128000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.155585289001465\n",
      " > accuracy: 155 / 1000\n\nbatch 10\n",
      " >> forward\n > max_len\ntensor(119, device='cuda:0')\n > emb\ntorch.Size([1000, 119, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 119, 37])\n > out(reshape)\ntorch.Size([119000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1548619270324707\n",
      " > accuracy: 159 / 1000\n\n",
      " >> forward\n > max_len\ntensor(65, device='cuda:0')\n > emb\ntorch.Size([1000, 65, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 65, 37])\n > out(reshape)\ntorch.Size([65000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 3.1813619136810303\n",
      " > accuracy: 164 / 1000\n\nbatch 11\n",
      " >> forward\n > max_len\ntensor(158, device='cuda:0')\n > emb\ntorch.Size([1000, 158, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 158, 37])\n > out(reshape)\ntorch.Size([158000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.122943639755249\n",
      " > accuracy: 178 / 1000\n\nbatch 12\n",
      " >> forward\n > max_len\ntensor(142, device='cuda:0')\n > emb\ntorch.Size([1000, 142, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 142, 37])\n > out(reshape)\ntorch.Size([142000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1709723472595215\n",
      " > accuracy: 159 / 1000\n\nbatch 13\n",
      " >> forward\n > max_len\ntensor(106, device='cuda:0')\n > emb\ntorch.Size([1000, 106, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 106, 37])\n > out(reshape)\ntorch.Size([106000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.147155284881592\n > accuracy: 190 / 1000\n\nbatch 14\n",
      " >> forward\n > max_len\ntensor(113, device='cuda:0')\n > emb\ntorch.Size([1000, 113, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 113, 37])\n > out(reshape)\ntorch.Size([113000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.112257480621338\n",
      " > accuracy: 175 / 1000\n\nbatch 15\n",
      " >> forward\n > max_len\ntensor(109, device='cuda:0')\n > emb\ntorch.Size([1000, 109, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 109, 37])\n > out(reshape)\ntorch.Size([109000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1638474464416504\n",
      " > accuracy: 183 / 1000\n\nbatch 16\n",
      " >> forward\n > max_len\ntensor(137, device='cuda:0')\n > emb\ntorch.Size([1000, 137, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 137, 37])\n > out(reshape)\ntorch.Size([137000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.143181085586548\n",
      " > accuracy: 178 / 1000\n\nbatch 17\n",
      " >> forward\n > max_len\ntensor(103, device='cuda:0')\n > emb\ntorch.Size([1000, 103, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 103, 37])\n > out(reshape)\ntorch.Size([103000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1699233055114746\n",
      " > accuracy: 180 / 1000\n\nbatch 18\n",
      " >> forward\n > max_len\ntensor(149, device='cuda:0')\n > emb\ntorch.Size([1000, 149, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 149, 37])\n > out(reshape)\ntorch.Size([149000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1428823471069336\n",
      " > accuracy: 171 / 1000\n\nbatch 19\n",
      " >> forward\n > max_len\ntensor(79, device='cuda:0')\n > emb\ntorch.Size([1000, 79, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 79, 37])\n > out(reshape)\ntorch.Size([79000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0869526863098145\n",
      " > accuracy: 187 / 1000\n\nbatch 20\n",
      " >> forward\n > max_len\ntensor(192, device='cuda:0')\n > emb\ntorch.Size([1000, 192, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 192, 37])\n > out(reshape)\ntorch.Size([192000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0902605056762695\n",
      " > accuracy: 181 / 1000\n\n",
      " >> forward\n > max_len\ntensor(65, device='cuda:0')\n > emb\ntorch.Size([1000, 65, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 65, 37])\n > out(reshape)\ntorch.Size([65000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 3.1454274654388428\n > accuracy: 172 / 1000\n\nbatch 21\n",
      " >> forward\n > max_len\ntensor(96, device='cuda:0')\n > emb\ntorch.Size([1000, 96, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 96, 37])\n > out(reshape)\ntorch.Size([96000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.078212261199951\n",
      " > accuracy: 184 / 1000\n\nbatch 22\n",
      " >> forward\n > max_len\ntensor(106, device='cuda:0')\n > emb\ntorch.Size([1000, 106, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 106, 37])\n > out(reshape)\ntorch.Size([106000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1321120262145996\n",
      " > accuracy: 168 / 1000\n\nbatch 23\n",
      " >> forward\n > max_len\ntensor(328, device='cuda:0')\n > emb\ntorch.Size([1000, 328, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 328, 37])\n > out(reshape)\ntorch.Size([328000, 37])\n",
      " > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1093387603759766\n > accuracy: 207 / 1000\n\nbatch 24\n",
      " >> forward\n > max_len\ntensor(124, device='cuda:0')\n > emb\ntorch.Size([1000, 124, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 124, 37])\n > out(reshape)\ntorch.Size([124000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0838706493377686\n",
      " > accuracy: 214 / 1000\n\nbatch 25\n",
      " >> forward\n > max_len\ntensor(112, device='cuda:0')\n > emb\ntorch.Size([1000, 112, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 112, 37])\n > out(reshape)\ntorch.Size([112000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1196000576019287\n",
      " > accuracy: 189 / 1000\n\nbatch 26\n",
      " >> forward\n > max_len\ntensor(89, device='cuda:0')\n > emb\ntorch.Size([1000, 89, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 89, 37])\n > out(reshape)\ntorch.Size([89000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.099370002746582\n",
      " > accuracy: 180 / 1000\n\nbatch 27\n",
      " >> forward\n > max_len\ntensor(79, device='cuda:0')\n > emb\ntorch.Size([1000, 79, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 79, 37])\n > out(reshape)\ntorch.Size([79000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0942437648773193\n",
      " > accuracy: 193 / 1000\n\nbatch 28\n",
      " >> forward\n > max_len\ntensor(157, device='cuda:0')\n > emb\ntorch.Size([1000, 157, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 157, 37])\n > out(reshape)\ntorch.Size([157000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0912463665008545\n",
      " > accuracy: 194 / 1000\n\nbatch 29\n",
      " >> forward\n > max_len\ntensor(83, device='cuda:0')\n > emb\ntorch.Size([1000, 83, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 83, 37])\n > out(reshape)\ntorch.Size([83000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.085402250289917\n",
      " > accuracy: 186 / 1000\n\nbatch 30\n",
      " >> forward\n > max_len\ntensor(162, device='cuda:0')\n > emb\ntorch.Size([1000, 162, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 162, 37])\n > out(reshape)\ntorch.Size([162000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.1099703311920166\n",
      " > accuracy: 186 / 1000\n\n",
      " >> forward\n > max_len\ntensor(65, device='cuda:0')\n > emb\ntorch.Size([1000, 65, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 65, 37])\n > out(reshape)\ntorch.Size([65000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 3.1052756309509277\n > accuracy: 173 / 1000\n\nbatch 31\n",
      " >> forward\n > max_len\ntensor(154, device='cuda:0')\n > emb\ntorch.Size([1000, 154, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 154, 37])\n > out(reshape)\ntorch.Size([154000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0691041946411133\n",
      " > accuracy: 196 / 1000\n\nbatch 32\n",
      " >> forward\n > max_len\ntensor(166, device='cuda:0')\n > emb\ntorch.Size([1000, 166, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 166, 37])\n > out(reshape)\ntorch.Size([166000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0703413486480713\n",
      " > accuracy: 198 / 1000\n\nbatch 33\n",
      " >> forward\n > max_len\ntensor(166, device='cuda:0')\n > emb\ntorch.Size([1000, 166, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 166, 37])\n > out(reshape)\ntorch.Size([166000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0885589122772217\n",
      " > accuracy: 195 / 1000\n\nbatch 34\n",
      " >> forward\n > max_len\ntensor(132, device='cuda:0')\n > emb\ntorch.Size([1000, 132, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 132, 37])\n > out(reshape)\ntorch.Size([132000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.049839496612549\n",
      " > accuracy: 215 / 1000\n\nbatch 35\n",
      " >> forward\n > max_len\ntensor(164, device='cuda:0')\n > emb\ntorch.Size([1000, 164, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 164, 37])\n > out(reshape)\ntorch.Size([164000, 37])\n",
      " > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0552806854248047\n > accuracy: 197 / 1000\n\nbatch 36\n",
      " >> forward\n > max_len\ntensor(158, device='cuda:0')\n > emb\ntorch.Size([1000, 158, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 158, 37])\n > out(reshape)\ntorch.Size([158000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.044461250305176\n",
      " > accuracy: 209 / 1000\n\nbatch 37\n",
      " >> forward\n > max_len\ntensor(157, device='cuda:0')\n > emb\ntorch.Size([1000, 157, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 157, 37])\n > out(reshape)\ntorch.Size([157000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.073007822036743\n",
      " > accuracy: 189 / 1000\n\nbatch 38\n",
      " >> forward\n > max_len\ntensor(77, device='cuda:0')\n > emb\ntorch.Size([442, 77, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([442, 77, 37])\n > out(reshape)\ntorch.Size([34034, 37])\n > last_out\ntorch.Size([442, 37])\n > logits\ntorch.Size([442, 37])\n > loss: 2.999128580093384\n > accuracy: 93 / 442\n\nEpoca: 4\n",
      "Number of batchs: 38\nbatch 1\n",
      " >> forward\n > max_len\ntensor(82, device='cuda:0')\n > emb\ntorch.Size([1000, 82, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 82, 37])\n > out(reshape)\ntorch.Size([82000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.034935474395752\n",
      " > accuracy: 216 / 1000\n\nbatch 2\n",
      " >> forward\n > max_len\ntensor(114, device='cuda:0')\n > emb\ntorch.Size([1000, 114, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 114, 37])\n > out(reshape)\ntorch.Size([114000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0486159324645996\n",
      " > accuracy: 201 / 1000\n\nbatch 3\n",
      " >> forward\n > max_len\ntensor(97, device='cuda:0')\n > emb\ntorch.Size([1000, 97, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 97, 37])\n > out(reshape)\ntorch.Size([97000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0266165733337402\n",
      " > accuracy: 223 / 1000\n\nbatch 4\n",
      " >> forward\n > max_len\ntensor(95, device='cuda:0')\n > emb\ntorch.Size([1000, 95, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 95, 37])\n > out(reshape)\ntorch.Size([95000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9997122287750244\n",
      " > accuracy: 230 / 1000\n\nbatch 5\n",
      " >> forward\n > max_len\ntensor(120, device='cuda:0')\n > emb\ntorch.Size([1000, 120, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 120, 37])\n > out(reshape)\ntorch.Size([120000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.0048463344573975\n",
      " > accuracy: 225 / 1000\n\nbatch 6\n",
      " >> forward\n > max_len\ntensor(87, device='cuda:0')\n > emb\ntorch.Size([1000, 87, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 87, 37])\n > out(reshape)\ntorch.Size([87000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9888734817504883\n",
      " > accuracy: 232 / 1000\n\nbatch 7\n",
      " >> forward\n > max_len\ntensor(104, device='cuda:0')\n > emb\ntorch.Size([1000, 104, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 104, 37])\n > out(reshape)\ntorch.Size([104000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9752984046936035\n",
      " > accuracy: 245 / 1000\n\nbatch 8\n",
      " >> forward\n > max_len\ntensor(158, device='cuda:0')\n > emb\ntorch.Size([1000, 158, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 158, 37])\n > out(reshape)\ntorch.Size([158000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.012460708618164\n > accuracy: 235 / 1000\n\nbatch 9\n",
      " >> forward\n > max_len\ntensor(166, device='cuda:0')\n > emb\ntorch.Size([1000, 166, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 166, 37])\n > out(reshape)\ntorch.Size([166000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.982123613357544\n",
      " > accuracy: 226 / 1000\n\nbatch 10\n",
      " >> forward\n > max_len\ntensor(83, device='cuda:0')\n > emb\ntorch.Size([1000, 83, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 83, 37])\n > out(reshape)\ntorch.Size([83000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 3.008779764175415\n",
      " > accuracy: 253 / 1000\n\n",
      " >> forward\n > max_len\ntensor(162, device='cuda:0')\n > emb\ntorch.Size([1000, 162, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 162, 37])\n > out(reshape)\ntorch.Size([162000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 3.047994375228882\n",
      " > accuracy: 205 / 1000\n\nbatch 11\n",
      " >> forward\n > max_len\ntensor(166, device='cuda:0')\n > emb\ntorch.Size([1000, 166, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 166, 37])\n > out(reshape)\ntorch.Size([166000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.99979305267334\n",
      " > accuracy: 221 / 1000\n\nbatch 12\n",
      " >> forward\n > max_len\ntensor(99, device='cuda:0')\n > emb\ntorch.Size([1000, 99, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 99, 37])\n > out(reshape)\ntorch.Size([99000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9855520725250244\n",
      " > accuracy: 243 / 1000\n\nbatch 13\n",
      " >> forward\n > max_len\ntensor(119, device='cuda:0')\n > emb\ntorch.Size([1000, 119, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 119, 37])\n > out(reshape)\ntorch.Size([119000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9537363052368164\n",
      " > accuracy: 228 / 1000\n\nbatch 14\n",
      " >> forward\n > max_len\ntensor(164, device='cuda:0')\n > emb\ntorch.Size([1000, 164, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 164, 37])\n > out(reshape)\ntorch.Size([164000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9730947017669678\n",
      " > accuracy: 241 / 1000\n\nbatch 15\n",
      " >> forward\n > max_len\ntensor(148, device='cuda:0')\n > emb\ntorch.Size([1000, 148, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 148, 37])\n > out(reshape)\ntorch.Size([148000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9611105918884277\n",
      " > accuracy: 265 / 1000\n\nbatch 16\n",
      " >> forward\n > max_len\ntensor(83, device='cuda:0')\n > emb\ntorch.Size([1000, 83, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 83, 37])\n > out(reshape)\ntorch.Size([83000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9474878311157227\n",
      " > accuracy: 256 / 1000\n\nbatch 17\n",
      " >> forward\n > max_len\ntensor(175, device='cuda:0')\n > emb\ntorch.Size([1000, 175, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 175, 37])\n > out(reshape)\ntorch.Size([175000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9838688373565674\n",
      " > accuracy: 254 / 1000\n\nbatch 18\n",
      " >> forward\n > max_len\ntensor(132, device='cuda:0')\n > emb\ntorch.Size([1000, 132, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 132, 37])\n > out(reshape)\ntorch.Size([132000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9710543155670166\n",
      " > accuracy: 237 / 1000\n\nbatch 19\n",
      " >> forward\n > max_len\ntensor(106, device='cuda:0')\n > emb\ntorch.Size([1000, 106, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 106, 37])\n > out(reshape)\ntorch.Size([106000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9658870697021484\n",
      " > accuracy: 241 / 1000\n\nbatch 20\n",
      " >> forward\n > max_len\ntensor(149, device='cuda:0')\n > emb\ntorch.Size([1000, 149, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 149, 37])\n > out(reshape)\ntorch.Size([149000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.988481283187866\n",
      " > accuracy: 235 / 1000\n\n",
      " >> forward\n > max_len\ntensor(162, device='cuda:0')\n > emb\ntorch.Size([1000, 162, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 162, 37])\n > out(reshape)\ntorch.Size([162000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 3.0147478580474854\n",
      " > accuracy: 229 / 1000\n\nbatch 21\n",
      " >> forward\n > max_len\ntensor(84, device='cuda:0')\n > emb\ntorch.Size([1000, 84, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 84, 37])\n > out(reshape)\ntorch.Size([84000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.960184097290039\n > accuracy: 251 / 1000\n\nbatch 22\n",
      " >> forward\n > max_len\ntensor(109, device='cuda:0')\n > emb\ntorch.Size([1000, 109, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 109, 37])\n > out(reshape)\ntorch.Size([109000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9530715942382812\n",
      " > accuracy: 254 / 1000\n\nbatch 23\n",
      " >> forward\n > max_len\ntensor(104, device='cuda:0')\n > emb\ntorch.Size([1000, 104, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 104, 37])\n > out(reshape)\ntorch.Size([104000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.976242780685425\n",
      " > accuracy: 237 / 1000\n\nbatch 24\n",
      " >> forward\n > max_len\ntensor(192, device='cuda:0')\n > emb\ntorch.Size([1000, 192, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 192, 37])\n > out(reshape)\ntorch.Size([192000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.955562114715576\n",
      " > accuracy: 248 / 1000\n\nbatch 25\n",
      " >> forward\n > max_len\ntensor(77, device='cuda:0')\n > emb\ntorch.Size([1000, 77, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 77, 37])\n > out(reshape)\ntorch.Size([77000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.949441909790039\n",
      " > accuracy: 269 / 1000\n\nbatch 26\n",
      " >> forward\n > max_len\ntensor(133, device='cuda:0')\n > emb\ntorch.Size([1000, 133, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 133, 37])\n > out(reshape)\ntorch.Size([133000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.933257818222046\n",
      " > accuracy: 244 / 1000\n\nbatch 27\n",
      " >> forward\n > max_len\ntensor(82, device='cuda:0')\n > emb\ntorch.Size([1000, 82, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 82, 37])\n > out(reshape)\ntorch.Size([82000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9134573936462402\n",
      " > accuracy: 277 / 1000\n\nbatch 28\n",
      " >> forward\n > max_len\ntensor(157, device='cuda:0')\n > emb\ntorch.Size([1000, 157, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 157, 37])\n > out(reshape)\ntorch.Size([157000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9310402870178223\n",
      " > accuracy: 269 / 1000\n\nbatch 29\n",
      " >> forward\n > max_len\ntensor(157, device='cuda:0')\n > emb\ntorch.Size([1000, 157, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 157, 37])\n > out(reshape)\ntorch.Size([157000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.909553289413452\n",
      " > accuracy: 293 / 1000\n\nbatch 30\n",
      " >> forward\n > max_len\ntensor(114, device='cuda:0')\n > emb\ntorch.Size([1000, 114, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 114, 37])\n > out(reshape)\ntorch.Size([114000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9260237216949463\n",
      " > accuracy: 266 / 1000\n\n",
      " >> forward\n > max_len\ntensor(162, device='cuda:0')\n > emb\ntorch.Size([1000, 162, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 162, 37])\n > out(reshape)\ntorch.Size([162000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n >> Comparing with dev\n > loss: 2.9726943969726562\n",
      " > accuracy: 252 / 1000\n\nbatch 31\n",
      " >> forward\n > max_len\ntensor(121, device='cuda:0')\n > emb\ntorch.Size([1000, 121, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 121, 37])\n > out(reshape)\ntorch.Size([121000, 37])\n > last_out",
      "\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9265754222869873\n > accuracy: 272 / 1000\n\nbatch 32\n",
      " >> forward\n > max_len\ntensor(112, device='cuda:0')\n > emb\ntorch.Size([1000, 112, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 112, 37])\n > out(reshape)\ntorch.Size([112000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.905080795288086\n",
      " > accuracy: 270 / 1000\n\nbatch 33\n",
      " >> forward\n > max_len\ntensor(106, device='cuda:0')\n > emb\ntorch.Size([1000, 106, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 106, 37])\n > out(reshape)\ntorch.Size([106000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.8891048431396484\n",
      " > accuracy: 298 / 1000\n\nbatch 34\n",
      " >> forward\n > max_len\ntensor(162, device='cuda:0')\n > emb\ntorch.Size([1000, 162, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 162, 37])\n > out(reshape)\ntorch.Size([162000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.906646966934204\n",
      " > accuracy: 292 / 1000\n\nbatch 35\n",
      " >> forward\n > max_len\ntensor(137, device='cuda:0')\n > emb\ntorch.Size([1000, 137, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 137, 37])\n > out(reshape)\ntorch.Size([137000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.9276657104492188\n",
      " > accuracy: 286 / 1000\n\nbatch 36\n",
      " >> forward\n > max_len\ntensor(328, device='cuda:0')\n > emb\ntorch.Size([1000, 328, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 328, 37])\n > out(reshape)\ntorch.Size([328000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.8756825923919678\n",
      " > accuracy: 283 / 1000\n\nbatch 37\n",
      " >> forward\n > max_len\ntensor(154, device='cuda:0')\n > emb\ntorch.Size([1000, 154, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 154, 37])\n > out(reshape)\ntorch.Size([154000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.920698642730713\n",
      " > accuracy: 284 / 1000\n\nbatch 38\n",
      " >> forward\n > max_len\ntensor(89, device='cuda:0')\n > emb\ntorch.Size([442, 89, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([442, 89, 37])\n > out(reshape)\ntorch.Size([39338, 37])\n > last_out\ntorch.Size([442, 37])\n > logits\ntorch.Size([442, 37])\n > loss: 2.8743767738342285\n > accuracy: 126 / 442\n\nEpoca: 5\n",
      "Number of batchs: 38\nbatch 1\n",
      " >> forward\n > max_len\ntensor(137, device='cuda:0')\n > emb\ntorch.Size([1000, 137, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 137, 37])\n > out(reshape)\ntorch.Size([137000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.8700339794158936\n",
      " > accuracy: 315 / 1000\n\nbatch 2\n",
      " >> forward\n > max_len\ntensor(158, device='cuda:0')\n > emb\ntorch.Size([1000, 158, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 158, 37])\n > out(reshape)\ntorch.Size([158000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.8781955242156982\n",
      " > accuracy: 316 / 1000\n\nbatch 3\n",
      " >> forward\n > max_len\ntensor(119, device='cuda:0')\n > emb\ntorch.Size([1000, 119, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 119, 37])\n > out(reshape)\ntorch.Size([119000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.8761706352233887\n",
      " > accuracy: 296 / 1000\n\nbatch 4\n",
      " >> forward\n > max_len\ntensor(73, device='cuda:0')\n > emb\ntorch.Size([1000, 73, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 73, 37])\n > out(reshape)\ntorch.Size([73000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.833130121231079\n",
      " > accuracy: 328 / 1000\n\nbatch 5\n",
      " >> forward\n > max_len\ntensor(90, device='cuda:0')\n > emb\ntorch.Size([1000, 90, 300])\n > out(max_len_seq x batch_len x output_size)\ntorch.Size([1000, 90, 37])\n > out(reshape)\ntorch.Size([90000, 37])\n > last_out\ntorch.Size([1000, 37])\n > logits\ntorch.Size([1000, 37])\n > loss: 2.842608690261841\n",
      " > accuracy: 314 / 1000\n\nbatch 6\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in range(1, epoch+1):\n",
    "    print(\"Epoca: \" + str(i))\n",
    "    \n",
    "    # Generate batchs\n",
    "    train_batch = generateBatch(train_topic, batch_size)\n",
    "    dev_batch = generateBatch(dev_topic, batch_size)\n",
    "    test_batch = generateBatch(test_topic, batch_size)\n",
    "    print(\"Number of batchs: \" + str(len(train_batch)))\n",
    "    \n",
    "    count = 0\n",
    "    for b in train_batch:\n",
    "        count += 1\n",
    "        print(\"batch \" + str(count))\n",
    "        \n",
    "        arg = b[0]\n",
    "        size = b[1]\n",
    "        con = b[2]\n",
    "        \n",
    "        arg, con = getTrainExample(arg, con, concept_list, word_vector)\n",
    "        size = torch.tensor(size, dtype=torch.long)\n",
    "        \n",
    "        mylstm.zero_grad()\n",
    "        output = mylstm(arg.cuda(), size.cuda())\n",
    "        \n",
    "        loss = criterion(output, con.cuda())\n",
    "        print(\" > loss: \", end='')\n",
    "        print(loss.item())\n",
    "        \n",
    "        correct_pred = accuracy(output, con)\n",
    "        print(\" > accuracy: \", end='')\n",
    "        print(str(correct_pred) + \" / \" + str(len(con)), end='\\n\\n')\n",
    "        \n",
    "        loss.backward()\n",
    "        all_losses.append(loss)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if count % 10 == 0:\n",
    "            arg = dev_batch[0][0]\n",
    "            size = dev_batch[0][1]\n",
    "            con = dev_batch[0][2]\n",
    "            \n",
    "            arg, con = getTrainExample(arg, con, concept_list, word_vector)\n",
    "            size = torch.tensor(size, dtype=torch.long)\n",
    "            \n",
    "            learning_rate = 0.01\n",
    "            mylstm.zero_grad()\n",
    "            \n",
    "            output = mylstm(arg.cuda(), size.cuda())\n",
    "            \n",
    "            print(\" >> Comparing with dev\")\n",
    "            \n",
    "            loss = criterion(output, con.cuda())\n",
    "            print(\" > loss: \", end='')\n",
    "            print(loss.item())\n",
    "        \n",
    "            correct_pred = accuracy(output, con)\n",
    "            print(\" > accuracy: \", end='')\n",
    "            print(str(correct_pred) + \" / \" + str(len(con)), end='\\n\\n')\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5zU1bnH8c8D0kQUhAUBQRQFVJq4QUVRQaOIBTVYE6LGBLHEaPRGYzSxJBqvV2MwGoOF6I09gg01osFobAhKW8FYsFBUBEGwUM/945nf/c3MzjZ2Z6d936/Xvn5lzs4+zAuePZzfOc+xEAIiIlL4muQ6ABERaRhK6CIiRUIJXUSkSCihi4gUCSV0EZEisUWufnCHDh1Cjx49cvXjRUQK0syZMz8PIZRlei1nCb1Hjx7MmDEjVz9eRKQgmdmHVb2mIRcRkSKhhC4iUiSU0EVEioQSuohIkVBCFxEpEkroIiJFQgldRKRIFF5CX7AAzj8f1q3LdSQiInml8BL6++/DjTfC44/nOhIRkbxSeAn90EOha1e4445cRyIiklcKL6E3bQo/+AH84x+waBGsX5/riERE8kLhJXTwXvqmTdCtG1xwQa6jERHJCzUmdDNraWbTzWy2mVWY2RVVtDvQzGYl2vyr4UNNss8+8fnEibB6dVZ/nIhIIahND30tMDyEMAAYCIwws72TG5hZW+AW4KgQwu7AcQ0eabKWLWG33fx8zRqYNCmrP05EpBDUmNCDW5O4bJb4CmnNTgYmhRA+SnzPZw0aZSavvgpffAHt28Pzz2f9x4mI5LtajaGbWVMzmwV8BkwNIbyW1qQX0M7MnjezmWb2w4YOtJI2baBtW9hvP3jxxaz/OBGRfFerhB5C2BhCGAhsDww2s75pTbYA9gQOBw4FLjOzXunvY2ZjzWyGmc1YtmxZPUNP2H9/eO89MIOxYyGk/+dBRKQ01GnHohDCSjN7HhgBzEt6aRHweQjhK+ArM3sBGAD8J+37JwATAMrLyxsm8550EsydC99+C7fdBgMGwNlnN8hbi4gUktrMcilLPPTEzFoBBwML0po9Cgw1sy3MbEtgL2B+QwebUefOPtPl3nth8GC4885G+bEiIvmmNkMunYFpZjYHeB0fQ3/CzMaZ2TiAEMJ84GlgDjAduD2EMK/Kd8wGMzj2WHjjDV9wJCJSYizkaMy5vLw8NPgm0QsWwK67wh//COee27DvLSKSB8xsZgihPNNrhblStCp9+sDAgXD33bmORESk0RVXQgc45RSYORP22gu+/jrX0YiINJriS+hnngm/+AVMnw5XX53raEREGk3xJfQWLeDaa2H0aLj5Zli7NtcRiYg0iuJL6JHTToOVK73MLsDDD8Mtt+Q2JhGRLKrTwqKCcvDB0LEjnHwy9OvntV+aN/eFSO3a5To6EZEGV7w99ObNvWjXmDGezMH3IZ04MadhiYhkS/EmdPA56X/+Mzz3HJxzDgwdChdeCFOm5DoyEZEGV7xDLsmGD/evr7+Gnj19nvp3v+u9eBGRIlHcPfR0W24JI0fCgw96HfV5jVudQEQkm0oroQMcfbQf16zxzaZD8HMRkQJXegn9yCOhosLH1mfPht//3jfLeOWVXEcmIlIvpZfQwfcjPfFEX4R0ySV+74UXchuTiEg9lWZCB9++7pRT4ut334VVq3yjDBGRAlS6CR3g0kvj82ee8Qelp56as3BEROqjtBN6t24+lfGCC+Cjj2DjRnjgAT0kFZGCVNoJHaBVKzj9dDjrLC/qBfD447mNSURkMyihg68ovflmX0W6zTZeMmD+fD8uWgRXXqleu4jkvdJYKVpbTZr4xhivvuozYaJ7mzb58Mxpp+U2PhGRaqiHnm6ffWDOnPh60yY/alqjiOQ5JfR0++5b+d4RR8CLLzZ+LCIidaAhl3QHHwzPPgt77unb2e20E3ToAE88AUuWQJcuuY5QRCQjJfR0ZnDQQX5+331+nDHDjy++CCeckJu4RERqUOOQi5m1NLPpZjbbzCrM7Ipq2n7HzDaa2eiGDTPHBg6ErbbSsIuI5LXa9NDXAsNDCGvMrBnwbzN7KoTwanIjM2sKXAv8Iwtx5tYWW8CQIXowKiJ5rcYeenDRJOxmia+QoelPgYeBzxouvDwydCjMnesld19+OdfRiIhUUqtZLmbW1Mxm4cl6agjhtbTXuwLHALfW8D5jzWyGmc1YtmzZ5sacG/vv78d77vGZMCHT7zQRkdypVUIPIWwMIQwEtgcGm1nftCY3AheFEDbW8D4TQgjlIYTysrKyzYs4VwYPTr3+17/g44/h009zE4+ISJo6zXIJIaw0s+eBEUDy/m3lwP1mBtABGGlmG0IIjzRUoDnXsqXXfGnb1rewu+ACeOMN35d07dpcRyciUnNCN7MyYH0imbcCDsYffv6/EMKOSe3/CjxRVMk8cvvtfuzdG8aO9fN167yGesuWuYtLRITaDbl0BqaZ2RzgdXwM/QkzG2dm47IbXp4aNSr1+rLLvPSuiEgOWcjRw73y8vIwI1qwU4h8eCl2771w0km5iUVESoaZzQwhlGd6TbVcNtddd/mwy+uv+/W0abmNR0RKnpb+b64f/tC/AI48Em67DTp39rIBy5bB6NE+A6Zjx9zGKSIlQwm9IQwb5rscXXml7026fr3fnzPHi32JiDQCDbk0hHHj4LHHfAOMt96Cb77x+xUVvmepiEgjUEJvCK1a+bBLeTl8+aUndYDzzvN7IiKNQAm9IUXb1iWbP7/x4xCRkqSE3pB23z3z/QMPhPfea9RQRKT0KKE3pLIy+PnP4W9/g8svj+//619w1VU5C0tESoNmuTS066+Pz886K562WFGRm3hEpGSoh55NZWU+V33PPX0bu/POy3VEIlLElNCz7a67fG56ly5w002wYUOuIxKRIqWE3hi23RZ+8xvYtMlLBXz7ba4jEpEipITeWLbf3o9DhsB++8EHH8CTT+Y0JBEpLnoo2liihA4wcybsmCgh//TTcOihuYlJRIqKeuiNpVu31OsowZ92Gixf3vjxiEjRUUJvLG3bxuerVvl+pG+84ZUZr7sud3GJSNFQQm8syRtibL21H/fYAwYNgunTYdGi3MQlIkVDCb0xHXMMHHVU6r3+/X1zjG7dYMGC3MQlIkVBD0Ub06RJle/17x+fL1wIffo0XjwiUlTUQ8+15AqNixd7T/2yy3IXj4gULCX0XBsyBEaN8vN//9vH0n/729zGJCIFSQk911q1gkcegU6d4N574/sbN+YuJhEpSDUmdDNraWbTzWy2mVWY2RUZ2nzfzOYkvl42swHZCbeIbb99vBcpwKWXQgi5i0dECk5teuhrgeEhhAHAQGCEme2d1mYhcEAIoT9wFTChYcMsAdE89WjLut//Hl57LXfxiEjBqTGhB7cmcdks8RXS2rwcQvgicfkqsD1SN18kPr7x4+HOO/387bdzF4+IFJxajaGbWVMzmwV8BkwNIVTXdTwdeKqK9xlrZjPMbMayZcvqHm0xu+02+N3vYO+94Qc/gKZN4T//yXVUIlJAajUPPYSwERhoZm2ByWbWN4QwL72dmQ3DE/p+VbzPBBLDMeXl5RogTjZokH8BNGvmxbuU0EWkDuo0yyWEsBJ4HhiR/pqZ9QduB0aFEFRtqr569YJ33omv161TeQARqVZtZrmUJXrmmFkr4GBgQVqb7sAkYEwIQd3KhtCrl/fQox2Ovv99X3S0YQOsXKkZMCJSSW166J2BaWY2B3gdH0N/wszGmdm4RJtfA+2BW8xslpnNyFK8pWOvveCbb7wiI8Df/+7Hl16Cdu3iB6ePPBK3EZGSVuMYeghhDrBHhvu3Jp3/GPhxw4ZW4oYP9+Nzz8HgwfH9Sy7x48svw+mne8EvUI9dRLRSNG917AgDBvjsl1mz4vsvv+zHe+6Bvn3j+1pZKlLylNDz2Q03wFdfed30dGvXQkVFfD13buPFJSJ5SQk9nw0fnrnkbiavvJLdWEQk7ymh57t99/Xpim++Gd9LrqEeee+9xotJRPKSEnoh6NoVBg6Mr3v1Sn29WTPfHCPds8/C7bdnNzYRyRtK6IWoW7fU67339qGZZs18AVLkuuvgF7/QDBiREqGEXoguuwzOOSe+7tfPjxs2wFtv+TZ2V1/txb2++MIfnh51FHz6aW7iFZFGoYReiNq1g5tuiq+7d4/PH3rIE/mvfgUffuj3Tj0VHn8cJk5s1DBFpHFpk+hCsnSpT1eMPPAAfPJJapv776/8fTNn+rFdu+zFJiI5p4ReSLbbLvX6+OP9+PXXsHq1D7O8/z60bw/LM9RHW706+zGKSM5oyKUYbLmlD7H06ePXgwbBLbfAFlvEJQQAnnrKV5gmC8EfnM5Q+R2RQmchRzMgysvLwwwlkYZ1zTVw333w5z/7/HXwbez2TtsxcN482H13P1+50odiWrSAb79NbRf93TDLbtwiUmtmNjOEUJ7pNfXQi8kvfwlz5sTJHLxq4/PPQ5cu8b3jjvM9S/v0iRckJY/NR8aMgSb6KyJSKDSGXgoOOMB3QFqyBHbeGRYv9uQP8OijVX9fNDwTgnrpIgVA3a9SseWWfjztNLjrrvj+I4/E51EvfeFCr8Ue+frr7McnIvWmHnqp+OorP3bvDkcf7Ul60KDUKo3z5nlv/DvfieusA6xYAa1bN268IlJn6qGXijVr/BgtQmrVCoYMSW1z9NGezAEmT47vr1iR/fhEpN6U0EvFFon/jHXqFN8bNiw+32abqjehXrHC9zc96aTMD09FJC8ooZeK++7zB6G77BLfS56jHp3feaeXCQB/kAqe0E8/3Vehvvpq48QrInWmhF4qevXylaTJ0xCjqYw77+zFu1q0gEMOgREj4I9/jBP7ihWwfn3jxywidaKHoqXus8+geXPYems4/HAoK/P7554bz25ZscIrOYIvRBKRvKSEXuqiBJ5+Dv7gtEULuPji+J4ekIrkLQ25SNXMKj8EVUIXyVs1JnQza2lm081stplVmNkVGdqYmY03s3fNbI6ZDcpOuJJzmao4ikheqE0PfS0wPIQwABgIjDCztGpPHAbskvgaC/y5QaOU3LnmmtTr6nromzZlNxYRqVaNCT24xKoUmiW+0ks0jgLuTrR9FWhrZp0bNlTJiYsvhiuvjK+rSuh33w1Nm1becENEGk2txtDNrKmZzQI+A6aGEF5La9IV+DjpelHiXvr7jDWzGWY2Y9myZZsbszS29u3j86oS+imn+PGdd7Ifj4hkVKuEHkLYGEIYCGwPDDazvmlNMpXiq1RoPYQwIYRQHkIoL0ufUSH56/jjvSRAr16ZE3q0dynooalIDtVplksIYSXwPDAi7aVFQLek6+2BJfWKTPJHhw4wfTrss0/qQ9FoA4zkXrn+5yWSM7WZ5VJmZm0T562Ag4EFac0eA36YmO2yN7AqhLC0waOV3Cor84VIIcBjj/n1XXfBRx/FbZTQRXKmNj30zsA0M5sDvI6PoT9hZuPMbFyizZPA+8C7wG3AWVmJVnKre3ffpq6iAi680HvrP/mJF+4y8xWntUnoX37p5QaefTb7MYuUkBpXioYQ5gB7ZLh/a9J5AM5u2NAk7+ywgx/79fMZLWecAX/5i+961KULNGsWJ/TqdjmaNcu3vnvqKTj44MaJXaQEaKWo1F6U0AHGj4df/9rPFyzw18rKPKEvXAjbbQfTpmV+n4oKP86ald14RUqMErrUXnJC32sv75V3SzwL7949TujXXutj7a+lz25NiBL67Nnxg1URqTcldKm9tm3j876JmasXX+z7le63nyf02bNh4kR/7Zln4vNk8+b5cfly37BaRBqEErpsnhYt/HjWWb5f6dlnw047wcaNsG4ddO3qQy4/+pE/SI2sXQtvvgk9e/r1e+81fuwiRUrlc6Vunn463s4u3QUX+MKiTp1g5kx4+GG//9FHvlPSO+/4ptRffglXXAHnn69SASINSD10qZtDD4WDDsr8WuvWcOONvtVd56RSPi++6EMvvXv7EE2XLvD97/trS5OWKyxbBk8+6ePqv/996gpUEamReuiSHWvWxOc//nF8/u678F//5atPmzVL7aGfcQZMngxTpvgvhUmTfIWqiNSKeuiSHT/6UdWvjRnjc9S32y41oUe99T/9yY/a7k6kTtRDl+wYOjR1cdFVV/m9mTN9YRL4sMzSpXDeeV78a9Uqv//UU36saqxeRDLSvxjJrmbNYP16uPRSvz7ggPi17bbzh6zPPBO3Tda0aePEKFIkNOQi2fXBB6nFu5J17OhTHCPr18e9d4Am+uspUhf6FyPZlbyaNF3v3n48/vj43tFHx+cbN2YvLpEipIQuuXPOOfD22/DAA17/5eOPfVpkRJtliNSJxtAld1q29F2QAHr08GPyRtPLl1dftVFEUqiHLvmlS5f4fN06n7cuIrWihC75JX2qYq9esHp1bmIRKTBK6JJ/FiyAG26Ir1U3XaRWlNAl//TuDd/7Hmy/vV+/+WZu4xEpEErokp+6d/dZL506+SyYr77KdUQieU8JXfLbnnvCyy/DmWfmOhKRvKeELvntD3+ArbbyEgFTpvjCoy+/zHVUInlJCV3yW69ecNNNXiv9iCPg0Ue9tO7jj8Prr/trIXiST57DLlKCakzoZtbNzKaZ2XwzqzCzn2Vos42ZPW5msxNtTstOuFKShg+Pz489Fm69FY46CgYPhnPPhWefhW22icvupvvPf7ymjEiRs1DDrutm1hnoHEJ4w8zaADOBo0MIbyW1uQTYJoRwkZmVAW8D24UQ1mV+VygvLw8zZsxokD+ElICXXvLZL8uXQ58+qa+1bOn7lu63n++OlC5aaVrD33WRQmBmM0MI5Zleq7GHHkJYGkJ4I3G+GpgPdE1vBrQxMwO2AlYAG+oVtUiyfff1XY5694af/tS3uouSd7QJ9aJFcfsQvOeuAl9SQupUy8XMegB7AK+lvfQn4DFgCdAGOCGEUGlA08zGAmMBunfvXvdoRQDGj/dj8sPRHXbwYZXly6F9e5g2Db77XbjnnpyEKJILtX4oamZbAQ8D54UQ0qcZHArMAroAA4E/mdnW6e8RQpgQQigPIZSXlZXVI2wRYOukv2InneTHaBgv2vXosccaNyaRHKpVQjezZngyvyeEMClDk9OAScG9CywE+mRoJ5IdY8b4DkcvvODX0S5IU6bEbaKhGZEiVZtZLgbcAcwPIdxQRbOPgIMS7TsBvYH3GypIkRr16eOLkK6+Gk48EebM8UJfa9bEbZYvr/l9li7N/GBVpADUpoe+LzAGGG5msxJfI81snJmNS7S5ChhiZnOB54CLQgifZylmkdi998LFF/t2deWJB/8PPODHH/wgte2dd/o2d5G1a/3BabLycth//+zFK5JFNU5bzBZNW5QG9+67cPnl8YPQZcsg/VnNH/4Au+0GW24Jkyb59Qkn+Jz2n/88nuL49dfQqlWjhi9SG/WatihSMHbeGf72Nxg9Gi66yKc5TpkCP/xh3GbJEt/mbuhQX3AE3qO/4ILU9/rii8aLW6SBaAs6KT4PPRSfjxzpwyh33+3Xd9wRv9a8eer3ffppfL58eeruSSIFQD10KX7bbhufJ288/eGHqe2mT8/cTqRAKKFL8dtiC/j3v6F/f7/eZRc/vvFGarvXktbLKaFLAVJCl9Kw775eNgDgmGO8/ku6mTPjcyV0KUBK6FI6ol2P+vWLt7eL9OyZ2mNXQpcCpIQupaNdOz/uuCN06xbfb9kSBg2Czz6L70WLkNasgfe1Rk4KgxK6lI7x4+GWW2DIkDihH3QQ3H+/72GaLOqhX3edz5JR6V0pAEroUjq23db3JjWLE/qee8KoUalDMD17xgl94UKfk75qVePHK1JHSuhSmqLhl7Vr/Rgl9A4doGvXuLb6smV+/OSTxo1PZDMooUtp2morP0bFu9q39+OAATBsmM9JX7pUCV0KihK6lKbBg/14wAF+HDIEzjgDJk6E447zMfOLL4bFi/316hL6+vXe049m0YjkiJb+S2naYw9f6h8V72rRwjefjpx8clwuACon9EWLfNimdWs45BBfuNS0qY/H339/XORLpBGphy6lq2PHqhPv//5v6nWU0KOpjd26wT77+Pnzz8OGDd5Lf/BBePPN+PvuvNMT/boq90sXaTBK6CKZNGmSWnr32mvh3HOhUyf4+9/93ty5qRtTR5Yujc8vvRQ2bYIFC+J7H38MFRXZiVtKmhK6SFU6dky9vukmPx53XHzvv//bj61awTnn+Hn0IBVgu+38OHt2fG/XXaFvX98mT2V6pQEpoYtUpWtXP44aFQ+vdO6c2uamm3zYZulS3/4O4POkzbratvVjckKPHp4eemjlOuwi9aCELlKVCRN8G7v77oOXX/ak/Mgj8esXXeTH88+HbbbxqZDNm6cm9KiEwPXXw9SpsHFj6s9I3vNUpJ6U0EWqssMO/nA02oquf38YODB+/Xe/gxde8PIA4D31Dh1Sh1ySN8245ZbKNdgnTfLyvt98k50/wyuv+Gycz7XFbylQQhepi+Rdjpo29a3smiT9M+rQIU6eGzd6cr/0UjjsMH8YGm17F423b9zoX9kqAHbddbBypc/EkaKnhC5SV/Pnw5w5mV8rK4sT+vLlPsOlUyef5vjhh/D44/7aZZf5GHrkgw+yE2vr1n7UoqeSoIVFInXVp0/Vr3XoENdVj4ZbOnXy4l6ff+7DLmec4TNokqdFZquHnl7iQIqaErpIQ2rXDt55x6czRvPVO3dOHSOPxtwbMqH/9a8+1n/CCan3ox76ypX1e38pCDUmdDPrBtwNbAdsAiaEEP6Yod2BwI1AM+DzEMIBDRuqSAHYeWc/RjNgLroI9trLV5JG2rTxY4cO8b2FC+v3c087zY/pCT36uckPZ6Vo1WYMfQNwQQhhV2Bv4Gwz2y25gZm1BW4Bjgoh7A4cV/ltRErA2Wf7A8hmzbxezDXX+HlUnjeq6gg+uyXy5JP+y+DZZ/0haVTWtzaqmyETDbUk78YkRavGhB5CWBpCeCNxvhqYD3RNa3YyMCmE8FGinf72SGlq2dIrOD76KPztb3GtmB139F701Klx26i+y/Dh8JOf+OKkyZNh7FjvxW/Y4MM2US974cLMif7tt+Pz9etTX4sehqqHXhLqNMvFzHoAewCvpb3UC2hnZs+b2Uwz+2EV3z/WzGaY2YxlyXN1RYrNYYfBbkn/kW3a1At17bFHfG/0aD+OHw833+xz3OfO9Xbr1/uCpeOO8zK+q1bBTjvFQyvJ3norPk+uIwNK6CWm1gndzLYCHgbOCyF8mfbyFsCewOHAocBlZtYr/T1CCBNCCOUhhPKy5AdCIqWoTx+vu7777n7drx+89FL8+l//6se77vKhGPBVqxdemNpTnz8/Pv/449SfESV0bdBREmqV0M2sGZ7M7wkhTMrQZBHwdAjhqxDC58ALwICGC1OkBPTr5/PWI9H49+efwwMPxPevv96Hdvr29TH5aG47VE7o0Xt88YUn9b59vYyBFKUaE7qZGXAHMD+EcEMVzR4FhprZFma2JbAXPtYuIrUV7aIEcNBBqa899BAceST84Q/xatWKCt/MevZs2GUXv/f++/Dii97z79/ft9KLTJ7s33PWWZl//tdfexGy5O+RglKbHvq+wBhguJnNSnyNNLNxZjYOIIQwH3gamANMB24PIczLWtQixeg73/Hhk+XL4+mPyQ45BM47z9s8+aQn4EjPnr6A6Ve/gv339x2U5s7113bc0Y/RgqfkXvzy5Z78wVervvpq6rCPFJQa56GHEP4N1LifVgjhOuC6hghKpGRFq1CjZ0zJtWH239+PO+3kX+CzYVav9vb77+89eUgdhtl1V58hEw21rFjhM2dOOsln0Uye7GPtTz0Vvy4FSbVcRPJRtOiofft4DnvfvpXbderkx7KyeMNr8GmTkV69fJZN8myYm26KV7K+9pqXCb7nHr9WQi9YSugi+SjqoW+7Lbz+uhcDa5Lhn2tyQj/0UF/EBHFVR/Ba7V3Tlo78/Of+i6Jnz9RZMhDXcJeCo4Quko+iHvq22/o2dv36ZW4XJfSOHX3cfflyGDMmtc3atfEQTXJhsQMP9Aenr7yS2l499IKlhC6Sj5ITenWifU+jHn2bNnDqqaltVq6M7yXvYdqnj4+vp5cFqCqhjx8PU6bUFLn72c9g2LDatZUGo4Quko+Sh1yqkzzkEhk+HK64wouCgc9FP/lkGDDAd1mK9O7tCT3dihVeHya55O6GDV5obPTo1P1RqzJ+fPWbanz9tVavZoESukg+6tDBx8O32676dl26+DG93a9/DdOm+fDL737n7zVrFpx+etymTx846qjK77lsmc+JHzzYpzR+/DFcdRV8+60P3xx7bPX11Vetis9Xr87cZtgwjzmaMikNQvXQRfJRq1a+QKi6zTTAe95t20KPHpnf4+67K9/v1s2T9M47+4rT11/3kgI3JNYNrlkD8xLLSP75T+/tv/iiX//2tz7X/ZZbfFVr9EuhSROfKtm5c+qQzeLF8Z/h7bdhyy39AW20eGnJksoPbGWzWcjRb8jy8vIwY8aMnPxskZL2wQfw5ptwzDHxvY0bU8v5brutT3Xs18+TezTO/sknlf838Mc/wrnnxpUlr7kGfvlLP3/sMXjvPfjxj+M68AMH+v8WAB55BEaNavA/YjEzs5khhPJMr6mHLlJqevSo3KNv2jT1evRorxZ53nnxvbIyH7Pv2NET/Kmn+nTKe+/1hB5J3n0pGtJJLvE7a5b/8tiwAWbMqD6hjxzpw0b9+8dFzKRKGkMXEReCb2R95JE+7j5uXFzud9q0OFFH8+EPOAC+9z1fmHTSSfH7LFxYeZrlrbfC1lv7atQlS3xl6u67V73ZNvjsnKee8mGlvn09+S9e7P8TmDy56u/79lsfairB8XkldBGJde/uwyQdOkCLFj6+XlHhc9ajDacjgwfHc97vvz++/+abmXvTgwbBiBE+zt68uY+df/KJJ+2NG+N2UanfDz9M/f5//tNjAR/Wqcpll8Epp8A//lGrP3IxUUIXkao1bZq6UQfAww/7Rht9+vgD1vTe8vLlXhBsyBA44oj4+9OnSJaV+cPRkSM9qX/yie/o1GbuZMkAAAnpSURBVLmzJ+RLLkltP3VqvIo1SvqLF8O++3rhseiXQrTyNaoFX0KU0EWkboYM8V2VoqGXTLNUdtzRqzY+9pjPtoHKM3aiRVHgCblzZ68oCT5k8uSTqe2ffRbOPNPPP/nEZ9mccooXHdtzTx+X37gxTuSrVnnFyRNOgAUL/N6YMfFsniKkhC4i9ZMpoffu7UezeBPrTD30yG9+U/3PuPBCn7sezXFfv973Xn3uudR2FRVxQn/rLf/l8+CDXngsBN/n9YILinZ8XQldROonWq0K8Je/wNNPw9Ch8b2oSmS0CUckfRvKAQP84eqTT1ZekNSvn4/jJ5s40UsGJ5cYeOmleDjm+uvjmvHXX+8PcCNRrfhsWLy48mbdjUQJXUTqJ3nK42mnedVHS9pC4bbbfIw8fapk8pALeJnfe+/1Dba32sqHdHr29O33TjjBpy4m27TJvyf5F8o//wmLFsXXI0Z4aeBvvkkd6586dbP+qBktWuQPk2fPhmuv9SqWV1zRcO9fB0roItJwovK9ybbe2hNruvQeelQRMrJypSfJ44/3GTcDMmxT3KVL/MujeXOYNCl1OGWPPXxsPl1FBbz7rv9voK696c8/93n30YrYKVN85e0vfwlXXun3br/dx/PPP99X1ka++ML/XFmihC4iuVFTQm/TBlq3jq932MGP48bFq1q7dPE586NH+/Z5Zt6Tj2rcDBzoq1ST36drV0/o558Phx/uRceiGTLz5sF++8ELL/jQTfKCqMjRR/sGIdGuUFGRsaee8iGeM8/0e1Onwo03wtVX+0yf2bN9+KlLl6yN4Suhi0j9vfeeL/ypi/QhlyhhV6VJE180dPPN8TBLly4+o+ahh7w3/uyz3mNetsxfHzDAh2WicXWA737XE3q0UGriRP8FccQRPlb/0kv+ELVz58ozc95+O95zdeFCPyZvENKlC/zP//h0znHj4vvz53uJhCVLfPgn2g6wgSmhi0j97bSTTx2sizZtfNphtIl1tNVedVq08MQeDaOkD6cceKC/z+WX+3XPnn5MXhS1zz4+EyaayhgNgUyZ4iWHu3WDCRPi9ocdBs884+e33+7Jv3XruPe+YIH/zNGjfdbNllv6MEv6wqgHH8x83oBUnEtEcuurr7x2+uGH1/57jjrKhzwWL46HV2oSjbW/9JIvRsrkued81ettt1V+7Ztv/OHn0KFxPffJk70Xf+aZqfPbv/oq/iUyfjw88UT8S+GFF/znZ9pSsFZ/jKqLc6mHLiK51bp13ZI5eM+8SZPKwzbVueEGuPTS1JWvyTNnzjnHe/iZShGDL5Batsxryvfp4yUOhg3zEsTpu0S1bg0nnuhVK3/607h42bBh/gthM5N5TWp8VzPrZmbTzGy+mVWY2c+qafsdM9toZqMbNkwRkSSnn+5TBLeoQ8HY88/3jTrato2Hd/bZx4+dO/uDziZN4OCD/d6ll1Z+j5128mmZ0Tz7hQt9Zk36lErwcfio7PDhh8O6dT6tMotq82tiA3BBCGFXYG/gbDPbLb2RmTUFrgVKryKOiDSuwYN99ejmioqHRQk9ebrl4MGefI8/Pr532WXeO3/jDZ93f+yxXtbg7rur3ju1SZPUOfqZpnQ2sBp/vYUQlgJLE+erzWw+0BV4K63pT4GHge80dJAiIg2qb1+vxjh4sF8nr2yFytv/RfPLkx15ZPbi20x12uDCzHoAewCvpd3vChwDDKeahG5mY4GxAN27d69bpCIiDeXcc31K4667+kPKTDN02rdv/LjqqdYj82a2Fd4DPy+E8GXayzcCF4UQNlb+zlgIYUIIoTyEUF6WvqhARKSxdO8e13IfOtSnGqbL0oPLbKpVD93MmuHJ/J4QwqQMTcqB+82nBXUARprZhhDCIw0WqYhIY5s40eelF4gaE7p5lr4DmB9CyFhIOISwY1L7vwJPKJmLSMFLn46Y52rTQ98XGAPMNbPEVt1cAnQHCCHcmqXYRESkDmozy+XfgNXULqn9qfUJSERENk/hjfqLiEhGSugiIkVCCV1EpEgooYuIFAkldBGRIqGELiJSJHK2wYWZLQM+rLFhZh2AzxswnGzI9xgVX/0ovvpRfJtvhxBCxtopOUvo9WFmM6rasSNf5HuMiq9+FF/9KL7s0JCLiEiRUEIXESkShZrQJ9TcJOfyPUbFVz+Kr34UXxYU5Bi6iIhUVqg9dBERSaOELiJSJAouoZvZCDN728zeNbOLcx0PgJl9YGZzzWyWmc1I3NvWzKaa2TuJY7tGjOdOM/vMzOYl3asyHjP7ZeLzfNvMDs1RfJeb2eLEZzjLzEbmML5uZjbNzOabWYWZ/SxxPy8+w2riy6fPsKWZTTez2YkYr0jcz5fPsKr48uYz3CwhhIL5ApoC7wE7Ac2B2cBueRDXB0CHtHv/DVycOL8YuLYR49kfGATMqykeYLfE59gC2DHx+TbNQXyXAxdmaJuL+DoDgxLnbYD/JOLIi8+wmvjy6TM0YKvEeTN8Y/m98+gzrCq+vPkMN+er0Hrog4F3QwjvhxDWAfcDo3IcU1VGAXclzu8Cjm6sHxxCeAFYUct4RgH3hxDWhhAWAu/in3Njx1eVXMS3NITwRuJ8NTAf6EqefIbVxFeVXHyGIYSwJnHZLPEVyJ/PsKr4qtLon+HmKLSE3hX4OOl6EdX/RW4sAXjGzGaa2djEvU4hhKXg/wCBjjmLrvp48ukzPcfM5iSGZKL/iuc0PjPrAeyB9+Dy7jNMiw/y6DM0s6aJbSs/A6aGEPLqM6wiPsijz7CuCi2hZ9oKLx/mXe4bQhgEHAacbWb75zqgOsiXz/TPQE9gILAUuD5xP2fxmdlWwMPAeSGEL6trmuFe1mPMEF9efYYhhI0hhIHA9sBgM+tbTfNGj7GK+PLqM6yrQkvoi4BuSdfbA0tyFMv/CyEsSRw/Aybj/xX71Mw6AySOn+UuQqgmnrz4TEMInyb+gW0CbiP+72xO4jOzZniyvCeEMClxO28+w0zx5dtnGAkhrASeB0aQR59hpvjy9TOsrUJL6K8Du5jZjmbWHDgReCyXAZlZazNrE50DhwDzEnGdkmh2CvBobiL8f1XF8xhwopm1MLMdgV2A6Y0dXPSPPOEY/DPMSXxmZsAdwPwQwg1JL+XFZ1hVfHn2GZaZWdvEeSvgYGAB+fMZZowvnz7DzZLrp7J1/QJG4k/13wN+lQfx7IQ//Z4NVEQxAe2B54B3EsdtGzGm+/D/Lq7HexanVxcP8KvE5/k2cFiO4vtfYC4wB//H0zmH8e2H/3d6DjAr8TUyXz7DauLLp8+wP/BmIpZ5wK8T9/PlM6wqvrz5DDfnS0v/RUSKRKENuYiISBWU0EVEioQSuohIkVBCFxEpEkroIiJFQgldRKRIKKGLiBSJ/wP2lgIxfjMjWQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testear RNN\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses, 'r')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Test de embedding _fasttext_sbwc.vec\nCargando embedding _fasttext_sbwc.vec\n",
      "Carga lista\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "embedding_name = embedding_name_list[0]\n",
    "print(\"Test de embedding \" + embedding_name)\n",
    "\n",
    "word_vector = get_wordvector(embedding_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Constitucion test class\n",
      "Size of dataset: 205357\n",
      "20000 Que esté presente la libertad de cada individuo, entendiendo esta como la capacidad de ejercer sus derechos sin perjudicar a otros, con autonomía.\noov: 1505\n",
      "40000 El Estado debe garantizar una convivencia pacífica entre los habitantes de nuestro país como con el resto del mundo.\noov: 2949\n",
      "60000 Tener el mismo sueldo sin importar de donde vienes, sin importar tu apellido, el sexo u otro origen es un derecho constitucional.  Que una persona gane lo mismo que otra haciendo lo mismo.\noov: 4430\n",
      "80000 Es parte fundamental de la formación personal y humana. Debe ser digna.\noov: 6000\n",
      "100000 La vivienda, la educación, una previsión social adecuada, de calidad  y sin distinción; deben ser entre otros, derechos sociales priorizados en la nueva constitución.\noov: 7509\n",
      "120000 Tener una constitución con un origen democrático a través de un plebiscito, la cual sea conocida y respetada por todos.\noov: 8876\n",
      "140000 un representante publico no seas corrupto y que sirva a la gente y no abuse de su calidad de representante legal.\noov: 10162\n",
      "160000 Por elección ciudadana (votado) y no designado.\noov: 11507\n",
      "180000 es parte de un poder del estado, encargado de confeccionar las leyes que el país necesita.\noov: 13404\n",
      "200000 que se cree solo una cámara para no tramitar tanto las leyes\noov: 15485\n",
      " > Dataset sorted\nConceptos de gobierno por topico\n1: 37\n2: 44\n3: 12\n4: 21\nArgumentos para conceptos de gobierno\n1: 49155\n2: 46887\n3: 44162\n4: 43138\nArgumentos para conceptos abiertos\n1: 4625\n2: 6173\n3: 4596\n4: 6621\nModos de argumentacion\npolicy: 300\nvalue: 300\nfact: 300\n\nTask A\nTopico 1, cantidad de conceptos: 37\nTopico 2, cantidad de conceptos: 44\nTopico 3, cantidad de conceptos: 12\nTopico 4, cantidad de conceptos: 21\nTopico 1: cantidad de vectores 49155\nTopico 2: cantidad de vectores 46887",
      "\nTopico 3: cantidad de vectores 44162\nTopico 4: cantidad de vectores 43138\n",
      "Topico 1: cantidad de vectores 48784\n",
      " > 4877: 577 1820\n",
      " > 9755: 1129 3681\n",
      " > 14633: 1688 5558\n",
      " > 19511: 2237 7427\n",
      " > 24389: 2840 9312\n",
      " > 29267: 3380 11122\n",
      " > 34145: 4023 13051\n",
      " > 39023: 4658 14927\n",
      " > 43901: 5225 16784\n",
      " > 48779: 5826 18664\nResultados: 0.1194244014430961 0.3826254509675303\nTopico 2: cantidad de vectores 46452\n",
      " > 4644: 914 2122\n",
      " > 9289: 1846 4289\n",
      " > 13934: 2754 6437\n",
      " > 18579: 3655 8590\n",
      " > 23224: 4543 10779\n",
      " > 27869: 5447 12976\n",
      " > 32514: 6352 15114\n",
      " > 37159: 7246 17300\n",
      " > 41804: 8137 19430\n",
      " > 46449: 9055 21591\nResultados: 0.1949539309394644 0.4648239042452424\nTopico 3: cantidad de vectores 43416\n",
      " > 4340: 1844 3463\n",
      " > 8681: 3644 6890\n",
      " > 13022: 5503 10345\n",
      " > 17363: 7363 13841\n",
      " > 21704: 9238 17321\n",
      " > 26045: 11062 20777\n",
      " > 30386: 12859 24230\n",
      " > 34727: 14681 27647\n",
      " > 39068: 16574 31179\n",
      " > 43409: 18429 34669\nResultados: 0.42452091394877467 0.7985765616362631\nTopico 4: cantidad de vectores 42544\n",
      " > 4253: 695 1759\n",
      " > 8507: 1381 3528\n",
      " > 12761: 2078 5279\n",
      " > 17015: 2741 7021\n",
      " > 21269: 3437 8773\n",
      " > 25523: 4109 10519\n",
      " > 29777: 4778 12305\n",
      " > 34031: 5421 14036\n",
      " > 38285: 6093 15781\n",
      " > 42539: 6765 17504\nResultados: 0.15901184655885672 0.4114798796540053\nTopico 1, cantidad de conceptos: 37\nTopico 2, cantidad de conceptos: 44\nTopico 3, cantidad de conceptos: 12\nTopico 4, cantidad de conceptos: 21\nTopico 1: cantidad de vectores 4625\nTopico 2: cantidad de vectores 6173\nTopico 3: cantidad de vectores 4596\nTopico 4: cantidad de vectores 6621\n\nTask B\nTopico 1: cantidad de vectores 1873\n > 186: 109 167\n > 373: 229 331",
      "\n > 560: 359 503\n > 747: 477 673\n > 934: 594 842",
      "\n > 1121: 718 1003\n > 1308: 835 1169\n",
      " > 1495: 958 1340\n > 1682: 1077 1507\n > 1869: 1193 1674\nResultados: 0.6390816871329418 0.8958889482114255\nTopico 2: cantidad de vectores 3160\n",
      " > 315: 187 257\n > 631: 373 504",
      "\n > 947: 560 750\n",
      " > 1263: 751 1003\n > 1579: 933 1245\n",
      " > 1895: 1122 1500\n > 2211: 1317 1751\n",
      " > 2527: 1491 1993\n > 2843: 1660 2232\n",
      " > 3159: 1846 2479\nResultados: 0.584493670886076 0.7848101265822784\nTopico 3: cantidad de vectores 1685\n > 167: 103 145\n > 335: 206 286\n > 503: 308 429",
      "\n > 671: 403 563\n > 839: 513 706\n > 1007: 619 845\n > 1175: 718 980\n",
      " > 1343: 819 1115\n > 1511: 924 1261\n > 1679: 1030 1405\nResultados: 0.6136498516320474 0.8367952522255193\nTopico 4: cantidad de vectores 2886\n",
      " > 287: 115 233\n > 575: 251 479\n > 863: 392 715\n",
      " > 1151: 536 964\n > 1439: 670 1215\n > 1727: 803 1456\n",
      " > 2015: 943 1705\n > 2303: 1062 1956\n > 2591: 1191 2200\n",
      " > 2879: 1337 2440\nResultados: 0.46465696465696466 0.8475398475398476\nTopico 1: cantidad de vectores 4625\nTopico 2: cantidad de vectores 6173\n",
      "Topico 3: cantidad de vectores 4596\nTopico 4: cantidad de vectores 6621\n\nTask C\nTopico m: cantidad de vectores 184796\n",
      " > 18478: 9696 18478\n",
      " > 36957: 19300 36957\n",
      " > 55436: 28760 55436\n",
      " > 73915: 37354 73915\n",
      " > 92394: 45901 92394\n",
      " > 110873: 54835 110873\n",
      " > 129352: 63367 129352\n",
      " > 147831: 73345 147831\n",
      " > 166310: 84876 166310\n",
      " > 184789: 96338 184789\nResultados: 0.521342453299855 1.0\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "({'1': [0.1194244014430961, 0.3826254509675303],\n  '2': [0.1949539309394644, 0.4648239042452424],\n  '3': [0.42452091394877467, 0.7985765616362631],\n  '4': [0.15901184655885672, 0.4114798796540053]},\n {'1': [0.6390816871329418, 0.8958889482114255],\n  '2': [0.584493670886076, 0.7848101265822784],\n  '3': [0.6136498516320474, 0.8367952522255193],\n  '4': [0.46465696465696466, 0.8475398475398476]},\n {'m': [0.521342453299855, 1.0]})"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "import ConstitucionUtil\n",
    "\n",
    "mean_vec_test = ConstitucionUtil.ConstitucionTestClass()\n",
    "mean_vec_test.MeanVectorEvaluation(word_vector, embedding_name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}